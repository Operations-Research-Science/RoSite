<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>多阶段问题与线性决策规则（Multi-stage problem and linear decision rule） - 鲁棒优化电子书 —— 运筹OR帷幄</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="运筹OR帷幄" />
  <meta name="description" content="汤勤深，陈植 第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（Single stage）的问题" />

  <meta name="keywords" content="Hugo, theme, jane" />






<meta name="generator" content="Hugo 0.89.4" />


<link rel="canonical" href="https://allenz-me.github.io/RoSite/post/5.%E5%A4%9A%E9%98%B6%E6%AE%B5%E9%97%AE%E9%A2%98%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99/" />





<link rel="icon" href="/RoSite/favicon.ico" />











<link rel="stylesheet" href="/RoSite/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">





<meta property="og:title" content="多阶段问题与线性决策规则（Multi-stage problem and linear decision rule）" />
<meta property="og:description" content="汤勤深，陈植 第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（Single stage）的问题" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://allenz-me.github.io/RoSite/post/5.%E5%A4%9A%E9%98%B6%E6%AE%B5%E9%97%AE%E9%A2%98%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-01-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-01-05T00:00:00+00:00" />

<meta itemprop="name" content="多阶段问题与线性决策规则（Multi-stage problem and linear decision rule）">
<meta itemprop="description" content="汤勤深，陈植 第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（Single stage）的问题"><meta itemprop="datePublished" content="2022-01-05T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-01-05T00:00:00+00:00" />
<meta itemprop="wordCount" content="9014">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="多阶段问题与线性决策规则（Multi-stage problem and linear decision rule）"/>
<meta name="twitter:description" content="汤勤深，陈植 第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（Single stage）的问题"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/RoSite/" class="logo">主页</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/post/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/tags/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/categories/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite"></a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/RoSite/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/RoSite/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/RoSite/" class="logo">
    
      主页
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/post/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/tags/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/categories/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite"></a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">多阶段问题与线性决策规则（Multi-stage problem and linear decision rule）</h1>
      
      <div class="post-meta">
        <time datetime="2022-01-05" class="post-time">
          2022-01-05
        </time>
        
        <span class="more-meta"> 9014 words </span>
          <span class="more-meta"> 18 min read </span>

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Table of Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#随机规划stochastic-programming">随机规划（Stochastic programming）</a></li>
    <li><a href="#动态鲁棒优化dynamic-robust-optimization">动态鲁棒优化（Dynamic robust optimization）</a></li>
    <li><a href="#线性决策规则linear-decision-rule">线性决策规则（Linear decision rule）</a></li>
    <li><a href="#拓展式线性决策规则extended-linear-decision-rule">拓展式线性决策规则(Extended linear decision rule)</a></li>
    <li><a href="#事件式近似法则event-wise-affine-recourse-approximation">事件式近似法则(Event-wise affine recourse approximation)</a>
      <ul>
        <li><a href="#事件式近似法则">事件式近似法则</a></li>
        <li><a href="#事件式分布模糊集">事件式分布模糊集</a></li>
      </ul>
    </li>
    <li><a href="#经典鲁棒优化转化">经典鲁棒优化转化</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>汤勤深，陈植</p>
<p>第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（Single stage）的问题。而企业或者决策者面对的问题中，很大一部分都是多阶段的（Multi-stage）。也即，决策者需要在一定的时间内，按时间顺序进行多个决策，且决策时只知过去已发生的随机变量（Random variable）而无法预知未来的。多阶段问题的这些特性，使得对相应问题的建模和求解特别复杂。在优化领域，一般是用随机规划或者动态规划进行建模和求解。然而，随机规划和动态规划都遭受“维度诅咒”（Curse of dimensionality）。</p>
<p>针对随机规划和动态规划的这个致命缺点，鲁棒优化用一些决策规则（decision rule）进行规避。现有的决策规则已经可以达到很好的近似效果，甚至在某些条件下有一些决策规则可以达到最优。</p>
<p>在这一章，我们将聚焦于如何用这些决策规则对多阶段问题（主要是两阶段问题）进行求解。在此之前，我们先着重介绍两阶段的随机规划问题。</p>
<p><strong>注</strong>：正如后面会讨论，决策规则近来越来越多地被改称为近似规则（Recourse approximation）。如若称为决策规则，则有后面阶段的决策将根据规则直接得到之嫌。而实际上，如果直接使用决策规则对后面阶段决策进行决策，其效果非常不可控。大多时候，模型会表现非常差。在模型的实施过程中，往往都是用滚动法（Rolling horizon），也即，在知道这一期的不确定性之后，将现在系统的状态当成初始状态，重新对模型进行求解，以获得下一期的最优决策。从这个角度来说，我们使用一定的规则去\textit{近似}未来的决策和不确定性之间的关系，从而达到简化模型的效果。</p>
<h2 id="随机规划stochastic-programming">随机规划（Stochastic programming）</h2>
<p>\label{sp_intro}
为了更好地理解随机规划，我们举例如下。</p>
<p><strong>示例1</strong>
单阶段库存管理模型 \label{example::single period inventory management}</p>
<p>小王前不久在小区开了一个小卖部。他发现，小区对苹果的需求$\tilde{d}$满足分布$F(\cdot)$。他每天需要决定向20里外小张定$x$斤苹果。每斤苹果的进货单价为$c$，销售价格为$p$。若库存不足,也即真实需求$d$大于订货量$x$，居民可以先下单，等有货了再送过去。针对这种情况，小王一般会给一定的折扣。折算下来，每一斤苹果将增加$b$的成本。而如果订货量太多，也即$x - d \geq 0$，苹果可能会变质，折算下来一斤苹果将增加$h$的成本。小王的利润为：
$$
\pi(x, d) = p\min\{x, d\} - cx - b(d- x)^+ - h(x - d)^+.
$$</p>
<p>小王想最大化他的期望利润，也即他将要解以下问题:
$$
\begin{align}
\max\ &amp; \mathbb{E}_{\mathbb{P}}{\pi(x,\tilde{d})} \label{model::inventory management}\\\
\mathrm{s.t.}\ &amp; x \geq 0\notag \notag
\end{align}
$$</p>
<p>示例$\ref{example::single period inventory management}$就是一个在商业环境中随处可见的随机规划问题：在已知随机分布和满足一定的约束的情况下，进行决策使得期望利润最大化。一般地，随机规划关注以下问题:
$$
\begin{align}
\min\ &amp; \mathbb{E}_{\mathbb{P}}{g(\pmb x,\tilde{\pmb  \xi})}, \label{model::SP model1}\\\
\mathbf{s.t.}\ &amp;  \mathbb{E}_{\mathbb{P}}{f_i(\pmb x,\tilde{\pmb \xi})} \leq 0,  i\in[I].\notag
\end{align}
$$
其中，$\tilde{\pmb{\xi}}$为随机变量。</p>
<p>示例$\ref{example::single period inventory management}$是一个单阶段的问题。但是，如果我们把卖多少苹果，$\min\{x,d\}$，当成决策$y$，那示例$\ref{example::single period inventory management}$就变成了一个两阶段的问题：第一阶段，决定定多少苹果，之后观测到需求；第二阶段，决定卖多少苹果。也即，模型$\eqref{model::inventory management}$可以写成
$$
\begin{align*}
\max\ &amp; -c x - b\mathbb{E}_{\mathbb{P}}{\tilde{d}} - h x + \mathbb{E}_{\mathbb{P}}{g(x,\tilde{d})}\\\
\mathrm{s.t.}\ &amp; x \geq 0
\end{align*}
$$
其中，
$$
\begin{align*}
g(x, d) = \max\ &amp; (p + b + h)y\\\
\mathrm{s.t.}\ &amp; y \geq x,\\\
&amp; y \geq d\notag.
\end{align*}
$$
此模型可归类于由<a href="https://www.jstor.org/stable/2627159">Dantzig, 1995</a>首先引入的经典的（线性）两阶段随机规划问题（two stage stochastic programming）： 第一阶段的决策变量为$\pmb x\in \mathbb{R}^{N_1}$，也称为“现时决策（Here-and-now decision）”。不失一般性，假设$\pmb x$的可行集为$\mathcal{X} = \{\pmb x:\pmb{Ax} = \pmb b,  \pmb x \geq \pmb 0\}$。与$\pmb x$相关的成本参数$\pmb c \in \mathbb{R}^{N_1}$。之后，随机量$\tilde{\pmb  \xi}\in \mathcal{W} \in \mathbb{R}^{I_1}$实现为$\pmb \xi$。其中$\mathcal{W}$为$ \tilde{\pmb \xi}$的支撑集。第二阶段决策变量为$\pmb y$，也称“等待决策（Wait-and-see decision）”。其相应的成本参数为$\pmb q\in \mathbb{R}^{N_2}$。此两阶段随机规划问题模型如下：
$$
\begin{align}
\min\ &amp; \pmb c^{\top} \pmb x + \mathbb{E}_{\mathbb{P}}{g(\pmb x,\tilde{\pmb  \xi})},\label{model::Two Stage SP model1} \\\
\mathbf{s.t.}\ &amp;  \pmb{A}\pmb x = \pmb b;\notag \\\
&amp; \pmb x \geq \pmb 0,\notag
\end{align}
$$
其中
$$
\begin{align}
g(\pmb x,\pmb \xi) = \min\ &amp; \pmb q^{\top}\pmb{y},\label{model::Two Stage SP model&ndash;dependent} \\\
\mathbf{s.t.}\ &amp;  \pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y = \pmb h(\pmb \xi);\notag\\\
&amp; \pmb y \geq \pmb 0.\notag
\end{align}
$$
模型$\eqref{model::Two Stage SP model&ndash;dependent}$中，$\pmb{T} \in \mathcal{R}^{I_1, M\times N_1}, \pmb h \in \mathcal{R}^{I_1,M}$是$\pmb \xi \in \mathcal{W}$的函数。在接下来的讨论中，我们假设他们仿射依赖于$\pmb \xi \in \mathbb{R}^{I_1}$：
$$
\pmb{T}(\pmb \xi) = \pmb T^0 + \sum_{i\in[I_1]}\pmb T^i\pmb \xi_i, \quad \pmb{b}(\pmb \xi) = \pmb b^0 + \sum_{i\in[I_1]}\pmb b^i\pmb \xi_i,
$$
其中，$\pmb T^0,\ldots,\pmb T^{I_1} \in \mathbb{R}^{M \times N_1}$，$\pmb b^0,\ldots,\pmb b^{I_1} \in \mathbb{R}^{M}$。</p>
<p>另外，矩阵$\pmb W$称为递归矩阵（Recourse matrix）。第二阶段的模型$\eqref{model::Two Stage SP model&ndash;dependent}$不一定总是有可行解。但是如果$\pmb W$是完全递归的（Complete recourse）&mdash;对任意的$\pmb z \in \mathbb{R}^M$，存在$\pmb y\in \mathbb{R}^{N_2}$使得$\pmb W \pmb y \geq \pmb z$&mdash;那么可以保证对于所有$\pmb x\in \mathbb{R}^{N_1}$和$\pmb \xi \in \mathbb{R}^{I_1}$，模型$\eqref{model::Two Stage SP model&ndash;dependent}$都有可行解。然而完全递归的假设过于苛刻，有些问题不一定具有这个性质。通常情况下，我们会假设模型$\eqref{model::Two Stage SP model&ndash;dependent}$对于所有的$\pmb x\in \mathcal{X}$和$\pmb \xi \in \mathcal{W}$都有可行解，也即模型$\eqref{model::Two Stage SP model&ndash;dependent}$具有相对完全递归（Relatively complete recourse）。</p>
<p>然而，两阶段随机模型具有以下难点:</p>
<ol>
<li>大量变量和约束。</li>
<li>难以获得$\tilde{\pmb \xi}$的集中分布。</li>
<li>难以评估（Evaluate）目标函数。尤其当$\tilde{\pmb\xi}$的维度较大时。</li>
<li>难以获得一个第一阶段的可行解$\pmb x$能够保证第二阶段的解$\pmb y$也是可行的。</li>
</ol>
<p>以上难点，使得最简单的两阶段随机规划问题是一个$\# P$-难的问题；而如果阶段大于2，这个问题则是一个$\mathrm{PSPACE}$-难的问题<a href="https://link.springer.com/article/10.1007/s10107-005-0597-0">(Dyer and Stougie, 2006)</a>。为了部分解决以上的这些问题，我们接下来介绍动态鲁棒优化和近似决策规则。</p>
<h2 id="动态鲁棒优化dynamic-robust-optimization">动态鲁棒优化（Dynamic robust optimization）</h2>
<p>在两阶段随机规划问题\eqref{model::Two Stage SP model1}中，假如$ \tilde{\pmb \xi}$的分布$\mathbb{P}$的具体分布未知，但是可以构建某个模糊集$\mathcal{P}$使得真实的分布在这个集合中，那么我们可以得到以下动态鲁棒优化模型：
$$
\begin{align}
\min\ &amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{g(\pmb x,\tilde{\pmb  \xi})}, \label{model::Two Stage Robust model}\\\
\mathbf{s.t.}\ &amp;  \pmb{A}\pmb x = \pmb b;\notag \\\
&amp; \pmb x \geq \pmb 0,\notag
\end{align}
$$
其中
$$
\begin{align*}
g(\pmb x,\pmb \xi) = \min\ &amp; \pmb q^{\top}\pmb{y},\\\
\mathbf{s.t.}\ &amp;  \pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y = \pmb h(\pmb \xi);\\\
&amp; \pmb y \geq \pmb 0.
\end{align*}
$$
我们可以等价地把模型$\eqref{model::Two Stage Robust model}$写成：
$$
\begin{align}
Z^* = \min\ &amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{\pmb q^{\top}\pmb{y}(\tilde{\pmb  \xi})}, \label{model::Two Stage Robust model1} \\\
\mathbf{s.t.}\ &amp;  \pmb A \pmb x = \pmb b;\notag\\\
&amp;\pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y(\pmb \xi) = \pmb h(\pmb \xi)  \forall \pmb \xi \in \mathcal{W};\notag\\\
&amp;\pmb y \in \mathcal{R}^{I_1, N_2};\notag\\\
&amp;\pmb x \geq \pmb 0.\notag
\end{align}
$$
然而，模型$\eqref{model::Two Stage Robust model1}$一般来说是不可解的，因为$\pmb y$是$\pmb \xi $的任意一个函数。如果我们假设$\pmb y$和$\pmb\xi$之间的映射是可知的，比如是仿射或者二次的，那么模型$\eqref{model::Two Stage Robust model1}$是否可能有解呢？答案是肯定的。</p>
<p><strong>注</strong>：
模型$\eqref{model::Two Stage SP model1}$是一个分布式鲁棒优化的两阶段模型。由第三章和第四章可知，当模糊集只包含随机量的支撑集时，分布式鲁棒优化模型退化成传统的鲁棒优化模型。因此，这一章节只讨论分布式鲁棒优化下的多阶段问题和线性决策规则。</p>
<h2 id="线性决策规则linear-decision-rule">线性决策规则（Linear decision rule）</h2>
<p>线性决策规则（LDR）是一种在动态优化模型中，假设当前阶段的决策\textbf{线性}依赖于（之前阶段）随机量的决策机制。也即，这是对决策量和随机量之间复杂关系的一种近似。相对应的，也有非线性的决策规则，比如二次决策规则（Quadratic decision rule, <a href="https://www2.isye.gatech.edu/~nemirovs/FullBookDec11.pdf">Ben-tal et al. 2009</a>）和多项式决策规则（Polynomial decision rules, <a href="https://ieeexplore.ieee.org/document/5986692">Bertsimas et al., 2011</a>）。</p>
<p>决策规则的提出旨在降低随机规划问题中的维度。有关于早期决策规则和随机规划结合的文献可参考<a href="https://link.springer.com/article/10.1007%2FBF01585511">Garstka and Wets</a>等人1974年写的综述。然而，由于此近似所得模型过于保守而被弃用。
之后，<a href="https://link.springer.com/article/10.1007/s10107-003-0454-y">Ben-tal et al., 2004</a>创造性地将LDR和鲁棒优化相结合，使得线性决策规则焕发出勃勃生机。 具体地，对于模型$\eqref{model::Two Stage Robust model1}$我们可以假设$\pmb y$是$\pmb \xi$的仿射函数，
$$
\pmb{y}(\pmb \xi) = \pmb y^0 + \sum_{i\in[I_1]}\pmb y_i^1\xi_i.
$$
不失一般性，我们定义以下集合
$$
\mathcal{L}^{I,N} = \bigg\{\pmb y \in \mathcal{R}^{I,N} \Big| \begin{array}{l}
\exists \pmb y^0, \pmb y_i^1, i \in [I_1]:\\\
\pmb y (\pmb \xi) = \pmb y^0 + \sum_{i\in[I_1]} \pmb y_i^1 \xi_i
\end{array}\bigg\}.
$$
在线性规则下，模型$\eqref{model::Two Stage Robust model1}$可以写成
$$
\begin{align}
Z^L = \min\ &amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{\pmb q^{\top}\pmb{y}(\tilde{\pmb  \xi})},\label{model::Two Stage Robust model LDR}\\\
\mathbf{s.t.}\ &amp;  \pmb A \pmb x = \pmb b;\notag\\\
&amp;\pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y(\pmb \xi) = \pmb h(\pmb \xi)  \forall \pmb \xi \in \mathcal{W};\notag\\\
&amp;\pmb y \in \mathcal{L}^{I_1,N_2},\pmb x \geq \pmb 0.\notag
\end{align}
$$</p>
<p>由此，我们可以得到模型$\eqref{model::Two Stage Robust model1}$的一个上界。</p>
<p><strong>定理</strong> {theorem}\label{theorem::upper bound}
$$
Z^{*} \leq Z^L.
$$</p>
<p>既然是上界，那么很自然的问题是，这个近似的效果如何？近似之后的问题和原问题的差距多大？什么条件下这两个问题是一样的，也即，什么条件可以保证线性决策规则是最优的？对于前两个问题，据笔者所知，暂时没有一般性的结论。而对于第三个问题，<a href="https://pubsonline.informs.org/doi/10.1287/opre.2013.1172">Iancu, Sharma, and Sviridenko, 2013</a>给出了模糊集中只包含随机量的支撑集时，线性决策规则最优的条件和技术性假设。 <a href="https://pubsonline.informs.org/doi/10.1287/moor.1100.0444">Bertsimas, Iancu, and Parrilo, 2010</a>和<a href="https://link.springer.com/article/10.1007/s10107-011-0444-4">Bertsimas and Goyal, 2012</a>探讨了某几种特殊的多阶段问题中LDR最优的条件。 而对于下一小节要介绍的拓展式线性决策规则（ELDR），<a href="https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952">Bertsimas, Sim, and Zhang, 2019</a>证明了当第二阶段的决策变量为一维时，ELDR为最优。而<a href="https://pubsonline.informs.org/doi/10.1287/msom.2018.0734">He, Hu, Zhang, 2020</a>证明了ELDR对于车辆调度问题（Vehicle repositioning problem)在满足一定的技术性假设条件下，对于任意维度的递归决策都是最优的。对于第五小节要介绍的情景仿射递归近似规则，<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3305039">Perakis et al., 2020</a>证明了在三阶段的定价和库存模型中，当只考虑一个产品时，
事件式近似法则是最优的。而对于多个产品的情况，从数值例子来看，也接近于最优。</p>
<p>LDR的运用使得多阶段的鲁棒优化问题受到了越来越多的学者的关注。然而，线性决策规则有一个很明显的缺点，近似模型太保守或者容易使得模型不可解。比如，<a href="https://pubsonline.informs.org/doi/10.1287/opre.1070.0457">Chen et al., 2008</a>指出，当$\pmb \xi$的支撑集$\mathcal{W} = (-\infty, + \infty)$时，
$$
\pmb{y}(\pmb \xi) = \pmb y^0 + \sum_{i\in[I_1]}\pmb y_i^1\xi_i \geq \pmb 0,
$$
可以得到$\pmb y_i^1 = \pmb 0, \forall i \in [I_1]$。此时，$\pmb y(\pmb \xi ) = \pmb y^0$是静态的（Static policy），而不是动态地依赖于$\pmb \xi$。 这就很容易导致所得的解过于保守或者模型不可解。比如考虑如下的随机优化问题：
$$
\begin{align*}
\min &amp; \mathbb{E}_{\mathbb{P}}{y_1(\pmb \xi) + y_2(\pmb \xi)}\\\
\textrm{s.t.} &amp; y_1(\pmb \xi) - y_2(\pmb \xi) = h(\pmb \xi);\\\
&amp; y_1(\pmb \xi) \geq 0, y_2(\pmb \xi) \geq 0.
\end{align*}
$$
如果$\pmb \xi$的支撑集$\mathcal{W} = (-\infty, + \infty)$，那么$y_1(\pmb \xi) = y_1^0, y_2(\pmb \xi) = y_2^0$。而此时，等式$y_1(\pmb \xi) - y_2(\pmb \xi) = h(\pmb \xi)$将无法被满足。有鉴于此，<a href="https://pubsonline.informs.org/doi/10.1287/opre.1070.0457">Chen et al., 2008</a>提出了偏转线性决策规则（Deflected linear decision rule, DLDR）和分离线性决策规则（Segregated linear decision rule,SLDR）。<a href="https://pubsonline.informs.org/doi/10.1287/opre.1090.0746">See and Sim, 2010</a>提出了截断线性决策规则（Truncated linear decision rule），<a href="https://pubsonline.informs.org/doi/10.1287/opre.1090.0795">Goh and Sim, 2010</a>则将DLDR和SLDR扩展到双偏转线性决策规则（Bideflected linear decision rule）和广义分离线性决策规则（Generalized segregated linear decision rule）。</p>
<p>对于LDR在多阶段问题中的更多的运用，读者可以阅读<a href="https://pubsonline.informs.org/doi/10.1287/educ.2015.0139">Delage and Iancu, 2015</a>和 <a href="https://link.springer.com/article/10.1007/s10287-018-0338-5">Georghiou, Kuhn, and Wiesemann</a>。</p>
<p>下面，我们举个LDR在多阶段鲁棒库存管理中的例子<a href="https://pubsonline.informs.org/doi/10.1287/opre.1090.0746">(See and Sim, 2010</a>,<a href="https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952">Bertsimas, Sim, and Zhang, 2019)</a>。</p>
<p>** 例2** 多阶段库存管理模型
假如示例$\ref{example::single period inventory management}$中的小王每天都要定苹果。总共要定$T$天。所有的成本以都是波动的，也即都跟$t\in [T]$相关。假如第$t$天期早上的库存水平（inventory level）为$y_t$，那么第$t + 1$天的库存水平$y_{t + 1}$可以通过$y_t, x_t$和$d_t$得到：
$$
y_{t+1} = y_{t} + x_t - d_t.
$$</p>
<p>假设需求是随机因子$\tilde{\pmb z}$的函数
$$
d_t(\tilde{\pmb z}_t) = \tilde{z}_t + \alpha \tilde{z}_{t - 1} + \cdots + \alpha \tilde{z}_1 + \mu,
$$
其中，$\alpha \in [0,1], \tilde{\pmb z}_t := (\tilde{z}_1, \ldots, \tilde{z}_t)$，$\tilde{z}_t$为第$t$天的期望为零且两两互不相关(uncorrelated)的随机因子。那么，我们可以把小王这$T$天的问题写成如下鲁棒优化模型:
$$
\begin{array}{lll}
\min, &amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{P}} \mathbb{E}_{\mathbb{P}}{\sum_{t \in [T]} c_t x_t(\tilde{\pmb z}_{t - 1}) + v_{t}(\tilde{\pmb z}_{t}))}&amp;\\\
\textrm{s.t.}  &amp; y_{t+1}(\pmb z_t) = y_{t}(\pmb z_{t - 1}) + x_t(\pmb z_{t - 1}) - d_t(\pmb z_{t}) &amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;v_t(\pmb z_t) \geq h_t y_{t + 1}(\pmb z_{t}) &amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;v_t(\pmb z_t) \geq -b_ty_{t + 1}(\pmb z_{t}) &amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;0 \leq x(\pmb z_{t - 1}) \leq \bar{x}_t &amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;x_t \in \mathcal{L}^{t - 1,1}, y_{t + 1} \in \mathcal{L}^{t,1}, v_t \in \mathcal{L}^{t,1} &amp; \forall t \in [T].
\end{array}
$$</p>
<h2 id="拓展式线性决策规则extended-linear-decision-rule">拓展式线性决策规则(Extended linear decision rule)</h2>
<p>在第.1.1中，我们介绍了基于广义矩信息的模糊集。其中，<a href="https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre">Wiesemann, Kuhn and Sim, 2014</a>巧妙地引入了辅助随机变量$\tilde{\pmb u}$使得升维之后的模糊集（Lifted ambiguity set）中的约束皆化为线性约束，而将非线性部分转移到了支撑集中。相应地，在模型$\eqref{model::Two Stage Robust model1}$,如果假设$\pmb y$是$\pmb \xi$和$\pmb u$的仿射函数，也即
$$
\mathcal{L}^{I + J,N} = \bigg\{\pmb y \in \mathcal{R}^{I + J,N} \Big| \begin{array}{l}
\exists \pmb y^0, \pmb y_i^1, \pmb y_j^2 \in \mathbb{R}^N, \forall i \in [I], j \in [J]:\\\
\pmb y (\pmb \xi, \pmb u) = \pmb y^0 + \sum_{i\in[I]} \pmb y_i^1 \xi_i + \sum_{j\in[J]} \pmb y_j^2 u_j
\end{array}\bigg\}.
$$</p>
<p>在线性规则下，模型$\eqref{model::Two Stage Robust model1}$可以写成
$$
\begin{align}
Z^E = \min\ &amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{\pmb q^{\top}\pmb{y}(\tilde{\pmb  \xi},  \tilde{\pmb u})},\label{model::Two Stage Robust model ELDR}\\\
\mathbf{s.t.}\ &amp;  \pmb A \pmb x = \pmb b;\notag\\\
&amp;\pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y(\pmb \xi,  \tilde{\pmb u}) = \pmb h(\pmb \xi)  \forall \pmb \xi \in \mathcal{W};\notag\\\
&amp;\pmb y \in \mathcal{L}^{I_1 + I_2,N_2},\pmb x \geq \pmb 0.\notag
\end{align}
$$
由此，我们可以得到一个比LED更好的近似模型。</p>
<p><strong>定理</strong> {theorem}
$$
Z^{*} \leq Z^E \leq Z^L$. \label{theorem::tighter upper bound}
$$</p>
<p>详细的证明请参考<a href="https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952">Bertsimas, Sim, and Zhang, 2019</a>.</p>
<h2 id="事件式近似法则event-wise-affine-recourse-approximation">事件式近似法则(Event-wise affine recourse approximation)</h2>
<p><a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603">Chen, Sim, and Xiong, 2020</a>提出的鲁棒随机优化（Robust Stochastic Optimization, RSO）模型的统一框架。</p>
<p>定义静态决策$\pmb{w} \in \mathbb{R}^{J_w}$，连续随机变量$\tilde{\pmb z}$， 和离散随机变量$\tilde{s}$。定义只取决于离散随机变量$\tilde{s}$的动态决策$\pmb{x}(s):[S] \mapsto \mathbb{R}^{J_x}$,以及同时取决于连续随机变量$\tilde{\pmb z}$和离散随机变量$\tilde{s}$的动态决策$\pmb{y}(s,\pmb{z}): [S] \times \mathbb{R}^{I_z} \mapsto \mathbb{R}^{J_y}$。与线性近似法则类似，对应离散随机变量的不同取值，动态决策$\pmb{y}(s,\pmb{z})$为连续随机变量$\tilde{\pmb z}$的不同的线性函数：
$$
\pmb{y}(s,\pmb{z})  := \pmb{y}^0(s) + \sum_{i \in [I_z]} \pmb{y}^i(s) z_i.
$$
其中，系数$\pmb{y}^0(s),\dots,\pmb{y}^{I_z}(s)$是最终模型的实际决策变量。</p>
<p>定义线性映射
$$
\left\{
\begin{array}{rll}
\pmb{a}_m(s,\pmb{z})   &amp;:=&amp;   \pmb{a}_{ms}^0 + \sum_{i \in [I_z]} \pmb{a}_{ms}^i z_i \\\
\pmb{b}_m(s,\pmb{z})   &amp;:=&amp;   \pmb{b}_{ms}^0 + \sum_{i \in [I_z]} \pmb{b}_{ms}^i z_i \\\
\pmb{c}_m(s)   &amp;:= &amp;   \pmb{c}_{ms} \\\
d_m(s,\pmb{z})  &amp;:= &amp;  d_{ms}^0 + \sum_{i \in [I_z]} d_{ms}^i z_i
\end{array}
\right. \forall m \in [M] \cup \{0\}.
$$
其中，参数维度如下
$$
\pmb{a}_{ms}^i \in \mathbb{R}^{J_w}, \pmb{b}_{ms}^i \in \mathbb{R}^{J_x}, \pmb{c}_{ms} \in \mathbb{R}^{J_y},  d_{ms}^i \in \mathbb{R} \forall i \in [I_z] \cup \{0\},  s \in [S].
$$
RSO模型的目标函数取分布集合$\mathcal{F}$（稍后介绍）下的最坏期望
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_0(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_0(\tilde{s},\tilde{\pmb z})}.
$$
RSO模型主要包含两类约束。第一类“硬”线性约束($m \in \mathcal{M}_1$)为一般鲁棒约束，需要在随机变量任意可能的取值下均满足：
$$
\pmb{a}^\prime_m(s,\pmb{z})\pmb{w} + \pmb{b}^\prime_m(s,\pmb{z})\pmb{x}(s) + \pmb{c}^\prime_m(s)\pmb{y}(s,\pmb{z}) + d_m(s,\pmb{z}) \leq 0 \forall \pmb{z} \in  \mathcal{Z}_s,  s \in [S].
$$
第二类“软”线性约束($m \in \mathcal{M}_2$)与目标函数类似，考虑分布集合$\mathcal{F}$下的最坏期望，并要求该最坏期望不为正：
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_m(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_m(\tilde{s},\tilde{\pmb z})} \leq 0 \forall m \in \mathcal{M}_2.
$$
除以上两类约束之外，在离散随机变量的不同取值下，RSO还包含非线性约束（如凸约束，整数约束等）
$$
\pmb{r}(s) := \left(\pmb{w},\pmb{x}(s),\pmb{y}^0(s),\dots,\pmb{y}^{I_z}(s) \right) \in \mathcal{X}_s \forall s \in [S],
$$</p>
<h3 id="事件式近似法则">事件式近似法则</h3>
<p>记离散随机变量$\tilde{s}$的取值范围为$[S]$。特别地，离散随机变量$\tilde{s}$每一个取值$s$对应一个情景$s$。定义由情景组成的一个非空集合为一个事件$\mathcal{E} \subseteq [S]$。如此，全部情景的一个划分（partition?）定义了一个相互独立（mutually exclusive）又完全穷尽（collectively exhaustive）的MECE事件集合，记为$\mathcal{C}$。相应地，满足$\mathcal{H}_{\mathcal{C}}(s) = \mathcal{E}$ 函数$\mathcal{H}_{\mathcal{C}}:[S] \mapsto \mathcal{C}$确定了情景$s$在一个MECE事件集合中唯一所属的事件$\mathcal{E}$。</p>
<p>给定一个MECE事件集合，事件式静态近似法则定义如下
$$
\mathcal{A}\left(\mathcal{C}\right)
:= \left\{x : [S] \mapsto \mathbb{R} \left|
\begin{array}{l}<br>
x(s) =  x^\mathcal{E}, \mathcal{E} = \mathcal{H}_\mathcal{C}(s) \\\
\mbox{for some } x^\mathcal{E} \in \mathbb{R}
\end{array}\right. \right\};
$$
亦即，不同事件下，静态决策不同。</p>
<p>类似地，事件式线性近似法则定义如下
$$
\bar{\mathcal{A}}\left(\mathcal{C}, \mathcal{I}\right) := \left\{ y : [S]  \times \mathbb{R}^{I_z}  \mapsto \mathbb{R} \left|
\begin{array}{l}<br>
y(s,\pmb{z}) =
\displaystyle  y^0(s) + \sum_{i \in \mathcal{I}} y^i(s) z_i  \\\
\mbox{for some } y^0, y^i \in \mathcal{A}(\mathcal{C}), i \in \mathcal I
\end{array}\right. \right\}
$$
其中，信息集合$\mathcal I \subseteq [I_z]$为连续随机变量$\tilde{\pmb z}$的部分索引（components?），声明了连续随机变量$\tilde{\pmb z}$中，事件式线性近似法则所能线性依赖的成分。事件式线性近似法则声明了在不同事件下，动态决策不同，并且动态决策为连续随机变量$\tilde{\pmb z}$的线性函数。</p>
<p>基于事件式近似法则，完整的RSO模型如下
$$
\begin{array}{cll}
\min &amp;\displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_0(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_0(\tilde{s},\tilde{\pmb z})} \\\
{\rm s.t.} &amp;
\pmb{a}^\prime_m(s,\pmb{z})\pmb{w} + \pmb{b}^\prime_m(s,\pmb{z})\pmb{x}(s) + \pmb{c}^\prime_m(s)\pmb{y}(s,\pmb{z}) + d_m(s,\pmb{z}) \leq 0 &amp; \forall \pmb{z} \in  \mathcal{Z}_s,  s \in [S],  m \in \mathcal{M}_1 \\\
&amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_m(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_m(\tilde{s},\tilde{\pmb z})} \leq 0 &amp; \forall m \in \mathcal{M}_2 \\\
&amp;\left(\pmb{w},\pmb{x}(s),\pmb{y}^0(s),\dots,\pmb{y}^{I_z}(s) \right) \in \mathcal{X}_s &amp; \forall s \in [S]\\\
&amp; x_j \in \mathcal{A}(\mathcal{C}^j_x) &amp; \forall j \in [J_x] \\\
&amp; y_j \in \bar{\mathcal{A}}(\mathcal{C}^j_y, \mathcal{I}^j_y) &amp; \forall j \in [J_y].
\end{array}
$$
其中，$\mathcal{C}^j_x, j \in [J_x]$， $\mathcal{C}^j_y, j \in [J_y]$为MECE事件集合, $\mathcal{I}^j_y, j \in [J_y]$为信息集合。</p>
<h3 id="事件式分布模糊集">事件式分布模糊集</h3>
<p>事件式分布模糊集刻画了连续随机变量$\tilde{\pmb z}$和离散随机变量$\tilde{s}$的联合分布的分布性质，包含了联合分布的分布信息。事件式分布模糊集取如下一般形式
$$
\label{eventwise_as}
\mathcal{F} = \left\{\mathbb{P} \in \mathcal{P}_0\left(\mathbb{R}^{I_z} \times [S]\right)  \left\vert
\begin{array}{ll}
(\tilde{\pmb z},\tilde{s}) \sim \mathbb{P}\\\
\mathbb{E}_{\mathbb{P}}[\tilde{\pmb z} \mid \tilde{s} \in \mathcal{E}_k] \in \mathcal{Q}_k &amp; \forall k \in [K] \\\
\mathbb{P}[\tilde{\pmb z} \in \mathcal{Z}_s \mid \tilde{s} = s]  = 1 &amp; \forall s \in [S]  \\\
\mathbb{P}[\tilde{s} = s]  = p_s &amp; \forall s \in [S]  \\\
\mbox{for some } \pmb{p} \in \mathcal{P}<br>
\end{array}
\right.
\right\}
$$
其中，$\mathcal{E}_k, k \in [K]$为不同事件（注意，这些事件不需要组成MECE事件集合），$\mathcal{Z}_s, s \in [S]$, $\mathcal{Q}_k, k \in [K]$, 和$\mathcal{P} \subseteq \{\pmb{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$为封闭的凸集合。事件式分布模糊集声明了
(1) 不同事件（$\mathcal{E}_k$）下连续随机变量$\tilde{\pmb z}$的事件期望（即条件期望）。
(2) 不同情景（$s$）下连续随机变量$\tilde{\pmb z}$的支撑集合（即条件支撑集合）。
(3) 不同情景（$s$）发生的概率。</p>
<p>不确定集合$\mathcal{Q}_k, k \in [K]$和$\mathcal{P} \subseteq \{\pmb{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$分别允许条件信息（1）和（3）亦可以是不确定的。</p>
<p><a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603">Chen, Sim, and Xiong, 2020</a>证明了事件式分布模糊集有非常好的普适性。它可以描述随机优化中常用的确定的离散分布（deterministic discrete distribution），以及分布鲁棒优化中用到的不确定的离散分布（uncertain discrete distribution）, 确定的（或不确定的）混合分布（mixture distribution），基于矩信息的分布模糊集（moments ambiguity set），以及数据驱动下（1）基于机器学习聚类或分类算法的分布模糊集（K-means ambiguity set）与（2）基于Wasserstein距离的分布模糊集（Wasserstein ambiguity set）。</p>
<h2 id="经典鲁棒优化转化">经典鲁棒优化转化</h2>
<p>给定情景$s$，RSO模型中目标函数和“软（硬）”约束实际上是决策变量和连续随机变量$\tilde{\pmb z}$的取值$\pmb{z}$的双线性函数。因为，我们可以将它们方便地记为
$$
{\pmb{a}^\prime_m(s,\pmb{z})\pmb{w} + \pmb{b}^\prime_m(s,\pmb{z})\pmb{x}(s) + \pmb{c}^\prime_m(s)\pmb{y}(s,\pmb{z}) + d_m(s,\pmb{z})}   := \pmb{r}^\prime(s)\pmb{G}_m(s)\pmb{z} + h_m(s)    \forall m \in [M] \cup \{0\}.
$$
其中，$\pmb{G}_m(s)  \in  \mathbb{R}^{J_r \times I_z}$和 $h_m(s) \in \mathbb{R}$为参数。这样的双线性函数在事件式分布模糊集下的最坏期望可以通过求解一个经典鲁棒优化模型得到。换句话说，RSO模型可以很方便地通过的配套建模工具包进行建模。目前，<a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603">Chen, Sim, and Xiong, 2020</a>论文中所提到的建模工具包RSOME的<a href="https://sites.google.com/view/rsome/home%7D">MATLAB版本</a>和<a href="https://xiongpengnus.github.io/rsome/">Python 版本</a>都已经发布。读者可以下载进行测试，并通过用户手册中的实例学习RSO的应用场景。</p>
<p><strong>定理</strong>
{theorem}{模型等价转换}{thm:worst-case expectation}\label{thm:worst-case expectation}
最坏期望
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{r}^\prime(\tilde{s})\pmb{G}_m(\tilde{s})\tilde{\pmb z} + h_m(\tilde{s}) }
$$
等于如下经典鲁棒优化模型的最优目标函数值
$$
\begin{array}{cll}
\inf &amp; \gamma \\\
{\rm s.t.} &amp; \gamma \geq \pmb{\alpha}^\prime\pmb{p} + \displaystyle \sum_{k \in [K]} \pmb{\beta}^\prime_k\pmb{\mu}_k &amp; \forall \pmb{p} \in \mathcal{P},  \dfrac{\pmb{\mu}_k}{\sum_{s \in \mathcal{E}_k} p_s} \in \mathcal{Q}_k,  k \in [K] \\\
&amp; \alpha_s + \displaystyle \sum_{k \in \mathcal{K}_s} \pmb{\beta}_k^\prime\pmb{z}  \geq \pmb{r}^\prime(s)\pmb{G}_m(s)\pmb{z} + h_m(s) &amp; \forall \pmb{z} \in \mathcal{Z}_s,  s \in [S] \\\
&amp; \gamma \in \mathbb{R},  \pmb{\alpha} \in \mathbb{R}^S,  \pmb{\beta}_k \in \mathbb{R}^{I_z} &amp; \forall k \in [K],
\end{array}
$$
其中对每一个$s \in [S]$, $\mathcal{K}_s = \{k \in [K] \mid s \in \mathcal{E}_k\}$.</p>

    </div>

    
    


    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/RoSite/post/4.%E5%88%86%E5%B8%83%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">分布鲁棒优化（Distributionally robust optimization）</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/RoSite/post/6.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E9%B2%81%E6%A3%92%E6%80%A7%E4%BC%98%E5%8C%96/">
            <span class="next-text nav-default">鲁棒性优化（Robustness Optimization）</span>
            <span class="prev-text nav-mobile">Next</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

  <div id="remark42"></div>

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:operations_r@163.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/Operations-Research-Science" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://www.zhihu.com/org/yun-chou-orwei-wo" rel="me noopener" class="iconfont"
      title="zhihu"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M351.791182 562.469462l192.945407 0c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262l159.282726 0c0 0-0.86367-67.402109-18.578124-67.402109s-279.979646 0-279.979646 0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461c-4.536316 12.313443 24.62791 5.832845 36.941354 0 12.313443-5.832845 68.050885-25.924439 84.252893-103.69571l86.570681 0c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262L109.86113 490.530013c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449L279.868105 562.469462c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513 0 0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-0.055259 0.185218 167.855986 193.263655c0 0 22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-0.045025 0.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"></path>
  <path d="M584.918753 182.033893l0 668.840094 70.318532 0 28.807093 80.512708 121.875768-80.512708 153.600307 0L959.520453 182.033893 584.918753 182.033893zM887.150192 778.934538l-79.837326 0-99.578949 65.782216-23.537066-65.782216-24.855084 0L659.341766 256.673847l227.807403 0L887.149169 778.934538z"></path>
</svg>

    </a>
  
    <a href="https://space.bilibili.com/403058474" rel="me noopener" class="iconfont"
      title="bilibili"  target="_blank"
      >
      <svg
  class="icon" style="" viewBox="0 0 1024 1024" version="1.1" width="36"
  height="36" id="svg8">
  <path
      style=""
      d="M 744.60599,0.00486267 A 41.779915,41.779915 0 0 0 710.4184,18.673394 L 548.5048,255.32642 h -11.70046 a 41.779915,41.779915 0 0 0 -10.80295,-7.84928 L 235.66,97.084498 a 41.779915,41.779915 0 0 0 -20.07193,-4.960864 41.779915,41.779915 0 0 0 -18.3748,79.145436 L 359.4859,255.32642 H 128.16909 c -49.458302,0 -89.27932,39.82105 -89.27932,89.27932 v 508.65224 c 0,49.4583 39.821018,89.27934 89.27932,89.27934 h 19.48445 C 149.12802,984.5043 179.92773,1024 224.79179,1024 c 44.86407,0 75.66379,-39.4957 77.13826,-81.46268 H 719.98116 C 721.45559,984.5043 752.25533,1024 797.1194,1024 c 44.86406,0 75.6638,-39.4957 77.13824,-81.46268 h 21.57323 c 49.45831,0 89.27936,-39.82104 89.27936,-89.27934 V 344.60574 c 0,-49.45827 -39.82105,-89.27932 -89.27936,-89.27932 H 649.74567 L 779.38103,65.866924 A 41.779915,41.779915 0 0 0 744.60599,0.00486267 Z M 644.49108,418.70871 c 6.29985,0.21538 12.44451,2.01107 17.86888,5.22196 l 171.36218,98.10771 c 18.23417,10.21935 24.63334,33.34627 14.24614,51.48533 -10.38726,18.13909 -33.57344,24.32718 -51.61587,13.77296 L 624.9903,489.18895 c -15.21356,-8.41858 -22.66871,-26.1765 -18.03211,-42.93436 4.63664,-16.75784 20.15573,-28.14465 37.53289,-27.54588 z M 350.2006,432.31846 c 16.89952,0.0317 31.69582,11.33328 36.17844,27.62747 4.48262,16.2942 -2.44981,33.57765 -16.95507,42.24898 l -140.7157,86.91312 c -17.68528,11.18244 -41.09629,5.77692 -52.08912,-12.02686 -10.99282,-17.80373 -5.33855,-41.15658 12.58167,-51.95857 L 329.9002,438.2095 c 6.0643,-3.86439 13.10951,-5.90891 20.3004,-5.89104 z M 501.605,641.53985 c 3.75002,-0.15248 7.48645,0.53903 10.93349,2.0235 0.15842,0.0637 0.31618,0.12888 0.47325,0.19582 0.59328,0.27092 1.17574,0.56489 1.74609,0.88121 0.15868,0.0854 0.31643,0.17233 0.47325,0.2611 0.55694,0.32165 1.10131,0.66458 1.63185,1.02807 0.16455,0.1123 0.32777,0.2265 0.48956,0.34269 0.50382,0.36781 0.99371,0.75428 1.46868,1.15864 0.18724,0.15504 0.37218,0.31282 0.55484,0.47323 0.43271,0.38784 0.8518,0.79061 1.25653,1.20756 0.15449,0.16114 0.30679,0.32437 0.45693,0.48959 0.40798,0.44266 0.79989,0.89988 1.17494,1.37076 0.17799,0.22544 0.35205,0.45395 0.5222,0.68538 0.25932,0.34701 0.50964,0.70071 0.75064,1.06071 0.26712,0.39516 0.52286,0.79784 0.76699,1.20757 0.16907,0.29043 0.33231,0.58424 0.48957,0.88123 0.21836,0.41297 0.42513,0.83199 0.62009,1.25653 0.14836,0.32333 0.28983,0.64976 0.42429,0.97911 0.21319,0.51552 0.40915,1.03801 0.58747,1.5666 0.0677,0.19499 0.13296,0.39085 0.19582,0.58748 0.18652,0.60823 0.34984,1.22334 0.48957,1.84399 0.0397,0.16277 0.0779,0.32601 0.11423,0.48957 0.1436,0.69112 0.25788,1.38801 0.34269,2.08877 0.005,0.0381 0.0111,0.0761 0.0163,0.11424 0.0857,0.78056 0.13474,1.56471 0.14687,2.34988 0.005,0.0543 0.0111,0.10879 0.0163,0.1632 0,0 -0.008,1.12132 0,1.45234 0,0 -0.14697,17.84761 5.89102,34.12231 3.01902,8.13734 7.33278,15.10615 12.61433,19.61501 5.28157,4.50889 11.42894,7.62081 23.64572,7.62081 12.2168,0 18.36416,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.5953,-11.47767 12.6143,-19.61501 6.03799,-16.2747 5.89103,-34.12231 5.89103,-34.12231 -0.44885,-13.87045 10.45922,-25.46302 24.3311,-25.86506 13.87189,-0.40201 25.42828,10.53953 25.78348,24.41272 0,0 1.11929,25.7226 -9.00791,53.01927 -5.06359,13.64832 -13.1986,28.46036 -27.05631,40.29073 -13.85772,11.83039 -33.5454,19.63135 -56.20142,19.63135 -22.65603,0 -42.34371,-7.80096 -56.20141,-19.63135 -4.1801,-3.56856 -7.78733,-7.42433 -10.99878,-11.42303 -3.21235,4.00037 -6.81703,7.85309 -10.99876,11.42303 -13.85773,11.83039 -33.5454,19.63135 -56.20144,19.63135 -22.65601,0 -42.3437,-7.80096 -56.2014,-19.63135 -13.85775,-11.83037 -21.99272,-26.64241 -27.05632,-40.29073 -10.12725,-27.29667 -9.00789,-53.01928 -9.00789,-53.01927 0.20714,-13.83687 11.58744,-24.88848 25.42444,-24.69013 14.1263,0.19991 25.2971,12.0278 24.69011,26.14247 0,0 -0.14697,17.84761 5.89103,34.12231 3.01902,8.13734 7.31646,15.10615 12.598,19.61501 5.28155,4.50889 11.44526,7.62081 23.66203,7.62081 12.21681,0 18.36418,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.57899,-11.47767 12.598,-19.61501 5.76352,-15.53489 5.89112,-32.05691 5.89103,-33.56746 0.006,-0.37466 0.0111,-1.05336 0.0163,-1.20759 -0.0117,-0.74583 0.0105,-1.49177 0.0652,-2.23565 0.009,-0.15784 0.0204,-0.31561 0.0327,-0.47324 0.14204,-1.56859 0.43163,-3.12027 0.86487,-4.63449 0.0213,-0.0763 0.0433,-0.15244 0.0652,-0.22848 3.0335,-10.25748 12.24157,-17.46007 22.92769,-17.93417 z"
      id="rect824"/>
</svg>

    </a>


<a href="https://allenz-me.github.io/RoSite/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
  
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2017 -
    2022
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        运筹OR帷幄
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/RoSite/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/RoSite/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/RoSite/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/RoSite/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/RoSite/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/RoSite/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







<script>
  if (typeof MathJax === 'undefined') {
      window.MathJax = {
          loader: {
              load: ['[tex]/mhchem']
          },
          
          tex: {
              inlineMath: {'[+]': [['$', '$']]},
              tags: 'ams',
              packages: {'[+]': ['mhchem']}
          }
      };
      (function() {
          var script = document.createElement('script');
          script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
          script.defer = true;
          document.head.appendChild(script);
      })();
  } else {
      MathJax.texReset();
      MathJax.typeset();
  }
</script>

</body>
</html>

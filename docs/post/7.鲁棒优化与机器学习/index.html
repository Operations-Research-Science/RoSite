<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>鲁棒优化与机器学习（Machine learning） - 鲁棒优化电子书 —— 运筹OR帷幄</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="运筹OR帷幄" />
  <meta name="description" content="覃含章 \textcolor{magenta}{分布式鲁棒贝叶斯学习\cite{kirschner2020distributionally}}" />

  <meta name="keywords" content="Hugo, theme, jane" />






<meta name="generator" content="Hugo 0.89.4" />


<link rel="canonical" href="https://allenz-me.github.io/RoSite/post/7.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" />





<link rel="icon" href="/RoSite/favicon.ico" />











<link rel="stylesheet" href="/RoSite/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">





<meta property="og:title" content="鲁棒优化与机器学习（Machine learning）" />
<meta property="og:description" content="覃含章 \textcolor{magenta}{分布式鲁棒贝叶斯学习\cite{kirschner2020distributionally}}" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://allenz-me.github.io/RoSite/post/7.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-01-03T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-01-03T00:00:00+00:00" />

<meta itemprop="name" content="鲁棒优化与机器学习（Machine learning）">
<meta itemprop="description" content="覃含章 \textcolor{magenta}{分布式鲁棒贝叶斯学习\cite{kirschner2020distributionally}}"><meta itemprop="datePublished" content="2022-01-03T00:00:00+00:00" />
<meta itemprop="dateModified" content="2022-01-03T00:00:00+00:00" />
<meta itemprop="wordCount" content="6619">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="鲁棒优化与机器学习（Machine learning）"/>
<meta name="twitter:description" content="覃含章 \textcolor{magenta}{分布式鲁棒贝叶斯学习\cite{kirschner2020distributionally}}"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/RoSite/" class="logo">主页</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/post/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/tags/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/categories/"></a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite"></a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/RoSite/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/RoSite/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/RoSite/" class="logo">
    
      主页
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/post/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/tags/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite/categories/"></a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://allenz-me.github.io/RoSite"></a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">鲁棒优化与机器学习（Machine learning）</h1>
      
      <div class="post-meta">
        <time datetime="2022-01-03" class="post-time">
          2022-01-03
        </time>
        
        <span class="more-meta"> 6619 words </span>
          <span class="more-meta"> 14 min read </span>

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Table of Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#从鲁棒优化角度看回归模型regression-正则性regularization和鲁棒性robustness">从鲁棒优化角度看回归模型（Regression）: 正则性（Regularization）和鲁棒性（Robustness）</a></li>
    <li><a href="#基于对抗样本adversarial-samples的鲁棒学习robust-learning">基于对抗样本（Adversarial Samples）的鲁棒学习（Robust Learning）</a></li>
    <li><a href="#神经网络neural-network中的分布鲁棒优化">神经网络（Neural Network）中的分布鲁棒优化</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>覃含章</p>
<p>\textcolor{magenta}{分布式鲁棒贝叶斯学习\cite{kirschner2020distributionally}}</p>
<p>本章中我们介绍鲁棒优化与机器学习相结合的一些研究的最新进展。</p>
<h2 id="从鲁棒优化角度看回归模型regression-正则性regularization和鲁棒性robustness">从鲁棒优化角度看回归模型（Regression）: 正则性（Regularization）和鲁棒性（Robustness）</h2>
<p>我们知道，著名的LASSO算法实际上是求解带有$L_1$正则项的线性回归模型。即，一般是考虑求解这样一个优化问题
$$
\min_{\pmb{\beta}} | \pmb{y} -\pmb{X} \pmb{\beta} |_2+\lambda |\pmb{\beta}|_1,
$$
其中$\pmb{X}\in \mathbb{R}^{M\times N}$是描述数据特征（feature）的矩阵，$\pmb{y}\in \mathbb{R}^M$是描述数据标签（label）的向量，$\lambda&gt;0$是正则项前的系数。在一些限制条件和假设下，可以证明存在某个自然数$k$,使得LASSO等价于求解如下问题（我们使用$|\cdot |_0$ 表示一个向量非零元素的个数，即$|\pmb{\beta}|_0=\text{card}(\{ i:\pmb{\beta}_i\neq 0 \})$）：
$$
\begin{align*}
\min_{\pmb{\beta}}  &amp; |\pmb{y}-\pmb{X}\pmb{\beta}|_2 \\\
\text{s.t. } &amp; |\pmb{\beta}|_0 \leq k.
\end{align*}
$$
也就是说在这种情况下LASSO所得到的解是稀疏（sparse）的。这里我们主要考虑这样一种非概率的统计模型，即我们认为我们只能得到$\pmb{X}$的一个带有误差的样本$ \pmb{X}'$。我们利用鲁棒优化的思想，认为$ \pmb{X}'=\pmb{X}+\pmb{\Delta}$，而$\pmb{\Delta}\in \mathcal{U}\subset \mathbb{R}^{M\times N}$，这里的$\mathcal{U}$就是我们的不确定集合（uncertainty set），注意这个集合是非随机的（deterministic）的。我们因此就可以考虑这样一个鲁棒线性回归问题：
$$
\min_{\pmb{\beta}} \max_{\pmb{\Delta}\in \mathcal{U}} | \pmb{y} -(\pmb{X}+\pmb{\Delta}) \pmb{\beta} |_2.
$$
这个鲁棒线性回归是个什么意思呢，也就是说我们现在优化的时候，所选择的$\pmb \beta$是最小化了不确定集里最差的那个$\pmb X'$，即我们要让“最坏情况”下的损失函数值最小。而在传统的LASSO或者线性回归中，我们的目标可以看成是要让期望的损失函数值最小。下面先初步解答如下问题：在线性回归模型中，我们什么时候可以将正则性和鲁棒性，这一个来自统计/机器学习，一个来自优化理论的性质等同看待？这里就以回归模型中最出名的脊回归（Ridge Regression）和LASSO为例。
$$
\begin{align}
&amp; \min_{\pmb{\beta}}|\pmb y - \pmb X\pmb \beta|_2+\lambda|\pmb \beta|_2=\min_{\pmb \beta}\max_{\pmb \Delta\in \mathcal{U}_{\text{RLS}}} | \pmb y - (\pmb X + \pmb \Delta) \pmb \beta|_2,\label{equ:RLS} \\\
&amp; \min_{\pmb{\beta}}|\pmb y - \pmb X\pmb \beta|_2 +\lambda |\pmb \beta|_1  =\min_{\pmb \beta}\max_{\pmb \Delta\in \mathcal{U}_{\text{LASSO}}} | \pmb y - (\pmb X+\pmb  \Delta) \pmb \beta|_2\label{equ:LASSO}.
\end{align}
$$
注意到脊回归和LASSO说白了只是正则项不同（选用$L_1$和$L_2$正则）的最小二乘法（least squares method），那么我们就发现上面的结果告诉了我们它们都对应特定的鲁棒线性优化模型，只是对应的不确定集不同罢了！具体来说，我们有$\mathcal{U}_{\text{RLS}}$和$\mathcal{U}_{\text{LASSO}}$对应两个不同的二阶锥（second-order cone）约束集：
$$
\begin{align}
&amp; \mathcal{U}_{\text{RLS}}=\left\{ \pmb \Delta: \left(\sum_{ij} \Delta_{ij}^2\right)^{1/2}\leq \lambda   \right\}, \\\
&amp; \mathcal{U}_{\text{LASSO}}=\left\{ \pmb \Delta: \pmb \Delta\text{的每列$\Delta_i$都满足: } |\Delta_i|_2\leq \lambda  \right\}.
\end{align}
$$
那么这边我们就获得了对脊回归、LASSO的一种基于鲁棒优化的新认识：这两种带正则项的线性回归其实可以看成一种鲁棒线性回归算法！那么自然，我们接下来应该也会对这两个问题感兴趣：</p>
<ol>
<li>正则性和鲁棒性在线性回归中是否都是一回事？</li>
<li>如果不都是一回事的话，在什么条件下是？什么条件下不是？</li>
</ol>
<p><strong>鲁棒线性回归定理</strong>
{theorem} 鲁棒线性回归定理 <a href="https://www.sciencedirect.com/science/article/abs/pii/S0377221717302734">Bertsimas and Copenhaver, 2018</a>{thm:RO_Reg}\label{thm:RO_Reg}
（1）存在$0&lt;\alpha\leq 1$使得对任何$\pmb y, \pmb X, \pmb \beta$,
$$
|\pmb y-\pmb X\pmb \beta|_p + \alpha \max_{\pmb \Delta \in \mathcal{U}} |\pmb \Delta \pmb \beta|_p\leq \max_{\pmb \Delta\in \mathcal{U}}|\pmb y - (\pmb X+\pmb \Delta)\pmb \beta|_p\leq |\pmb y-\pmb X\pmb \beta|_p +  \max_{\pmb \Delta \in \mathcal{U}} |\pmb \Delta \pmb \beta|_p.
$$
（2）我们令$\mathcal{U}=\{\pmb \Delta : |\pmb \Delta|\leq \lambda  \}$，其中的范数$|\cdot|$如下表中所示，则有</p>
<p>| $| \cdot |$  |  $|\pmb \Delta|$的取值  | $\alpha=1$的“当且仅当”条件 |
| $q$-Frobenuis范数 | $\left( \sum_{ij}|\Delta_{ij}|^q  \right)^{1/q}$ | $p\in\{1,q,\infty\}$|
| $q$-谱范数 |  奇异值的$L_q$范数 |  $p\in \{1,2,\infty\}$|
| $(L_q,L_r)-$诱导范数 |  $\max_{\pmb \beta}\frac{|\pmb \Delta \pmb \beta|_r}{|\beta|_q} $ | $p\in \{1,r,\infty\}$ |</p>
<p>定理$\ref{thm:RO_Reg}$是<a href="https://www.sciencedirect.com/science/article/abs/pii/S0377221717302734">Bertsimas and Copenhaver, 2018</a>的文章中给出的基于上述两个问题的一般化回答。定理中的（1）表明一般来说我们都能用正则项的形式将鲁棒问题的取值控制住，但一般来说两者并不是完全一致的（文章中也给出了一些详细的例子来佐证）；而（2）则给出了鲁棒性=正则性，即（1）中的$\alpha=1$的“当且仅当”条件。比如这其中的$q$-Frobenuis范数情形，其中$p=1$和$q=2$的时候就对应了我们前面的$\eqref{equ:LASSO}$和$\eqref{equ:RLS}$。表中的其他内容则表明类似结论也可以被推广到其它矩阵范数上。</p>
<h2 id="基于对抗样本adversarial-samples的鲁棒学习robust-learning">基于对抗样本（Adversarial Samples）的鲁棒学习（Robust Learning）</h2>
<p>本节我们将前一节仅仅针对回归模型的思路拓展，介绍在更一般的机器学习任务里，如果出现所谓的对抗样本，如何训练我们的模型，和相应的样本复杂度（相比于非对抗情境的机器学习任务）。我们主要考虑如下优化问题：
$$
\min_{\pmb \theta} \frac{1}{N}\sum_{i=1}^N \max_{\pmb x_i'\in \mathcal{U}_i}g(\pmb \theta,\pmb x_i',y_i).
$$
其中，$g(\pmb theta,\pmb x_i',y_i)$ 是一个损失函数（和前一节不同，这里的$g$不一定要是某个范数了），比如说，现在我们也可以将它看成一个基于人工神经网络（artifical neural network）的损失函数。$\pmb \theta$就是我们要优化的参数，$(\pmb x_i,y_i)$是一个数据点，$\mathcal{U}_i$则是针对每个数据点定义的一个不确定集。我们注意到，这个最优化问题可以利用常见的交替方向法来求解。具体来说，算法每一步中我们将$\pmb \theta$的值固定，然后我们通过如下方式计算$\pmb \Delta_{x_i}$:
$$
\pmb \Delta_{x_i} = \arg\max_{\pmb \Delta:\pmb x_i+\pmb \Delta\in \mathcal{U}_i} g(\pmb \theta,\pmb x_i+\pmb \Delta,y_i). \label{equ:exact delta}
$$</p>
<p>当然这个优化问题$\eqref{equ:exact delta}$一般来说是难以直接求得的（我们这里没有限制$g$），那么如果我们认为$g$是光滑的，就可以求解一个一阶泰勒展开的近似问题：
$$
\pmb  \Delta_{x_i}' = \arg\max_{\pmb \Delta:\pmb x_i+\pmb \Delta\in \mathcal{U}_i} g(\pmb \theta,\pmb x_i,y_i) +\left&lt; \nabla_{\pmb x} g(\pmb \theta,\pmb x,y_i),\pmb \Delta \right&gt; . \label{equ:approx delta}
$$</p>
<p>根据式\eqref{equ:approx delta}我们就可以在固定$\pmb \theta$值的情况下更新$\pmb \Delta_{x_i}'$，也即$\pmb x_i'=\pmb x_i+\pmb \Delta_{x_i}'$。假设算法每步一共更新了$mb$次，那么在固定数据点集$\{ (\pmb x_i',y_i) \}_{i=1}^{|mb|}$的情况下，我们就可以对$\pmb \theta$采用一步批梯度下降法（mini-batch gradient descent）的迭代。如此，我们就描述了我们的对抗训练（adversarial training）算法，算法的具体实现细节和一些数值实例可见<a href="https://arxiv.org/abs/1511.05432">Shaham et al., 2018</a>的工作。本节我们接着讨论对抗训练中的一些复杂度问题，我们将仅限于讨论分类（classification）问题。</p>
<p>我们先定义分类错误（classification error）为：对分布$\mathcal{P}: \mathbb{R}^d \times \{\pm 1\} \rightarrow \mathbb{R} $,分类器（classifier）$f:\mathbb{R}\rightarrow \{\pm 1\}$的分类错误率$e$为$e=\mathbb{P}_{(\pmb x,y)\sim \mathcal{P}}[f(\pmb x)\neq y] $. 也就是分类错误率其实就是分类器出错的概率。然后我们将这个定义拓展，定义所谓的$\mathcal{U}$-鲁棒分类错误率：
对分布$\mathcal{P}:\mathbb{R}^d\times\{\pm 1\} \rightarrow \mathbb{R} $,定义$<br>
\mathcal{U}:\mathbb{R}^d\rightarrow \mathbf{P}(\mathbb{R}^d)$（$\mathbf{P}(\mathbb{R}^d)$表示$\mathbb{R}^d$的支撑集，即所有子集的集合）。分类器（classifier）$f:\mathbb{R}\rightarrow \{\pm 1\}$的$\mathcal{U}$-鲁棒分类错误率$e$为$e=\mathbb{P}_{(\pmb x,y)\sim \mathcal{P}}[\exists \pmb x'\in \mathcal{U}(\pmb x):  f(\pmb x')\neq y] $. <a href="https://papers.nips.cc/paper/2018/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html">Schmidt et al., 2018</a>的文章在$\mathcal{P}$为高斯分布和伯努利分布的假设下研究了$\mathcal{U}(\pmb x)=\mathcal{U}^{\epsilon}_\infty(x)=\{x'\in \mathbb{R}^d | |x'-x|_\infty \leq \epsilon \}. $</p>
<p><strong>定理</strong>
{theorem}{鲁棒分类样本复杂度定理<a href="https://papers.nips.cc/paper/2018/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html">Schmidt et al., 2018</a> }{Sample Complexity}
\label{thm:SCbound}</p>
<p>(1) 高斯模型：令$( x_1,y_1),\ldots,( x_n,y_n)$是从$\mathcal{N}(\theta^*,\sigma)$中独立同分布抽样得到的样本，其中高斯分布的参数满足$|\theta^*|_2=\sqrt{d},\sigma\leq c \cdot d^{1/4}$（$c&gt;0$是一个常数）.</p>
<ul>
<li>有高概率$f_{\hat{w}}=y_1\cdot x_1$的分类错误率不超过1%。</li>
<li>如果取$\epsilon$使得$\frac{1}{4}d^{-1/4}\leq \epsilon \leq \frac{1}{4}$，那么如果$n\geq \epsilon^2 \sqrt{d}$，有高概率$f_{\hat{w}}=\frac{1}{n}\sum_{i=1}^n y_ix_i$的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率不超过1%。</li>
<li>基于样本$( x_1,y_1),\ldots,( x_n,y_n)$，对任意0/1分类器$f_n$，如果$n\leq c'\frac{\epsilon^2\sqrt{d}}{\log d}$（$c'&gt;0$是一个常数），期望的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率至少为$\frac{1}{2}(1-1/d)$.</li>
</ul>
<p>(2) 伯努利模型：存在参数$\theta^*\in \{\pm 1\}^d,\tau&gt;0$，使得抽样机制定义为先均匀地抽样$y\in \{-1,1\}$，再对$\pmb x$的每个坐标独立以$1/2+\tau$概率抽得$y\cdot\theta_i^*$，以$1/2-\tau$概率抽得$-y\cdot\theta_i^*$。令$\tau\geq c\cdot d^{-1/4}$，$\epsilon&lt;3\tau&lt;1$, $\gamma&lt;1/2$。</p>
<ul>
<li>有高概率$f_{\hat{w}}=y_1\cdot \pmb x_1$的分类错误率不超过1%。</li>
<li>如果取$\epsilon$使得$\frac{1}{4}d^{-1/4}\leq \epsilon \leq \frac{1}{4}$，那么如果$n\geq \epsilon^2 \sqrt{d}$，有高概率$f_{\hat{w}}=y_1\cdot T(\pmb x_1)$ 的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率不超过1%。$T$是一个非线性算子，使得$\pmb x$的每个非负坐标取$1$，负坐标取$-1$。</li>
<li>基于样本$( x_1,y_1),\ldots,( x_n,y_n)$，对任意0/1分类器$f_n$，如果$n\leq c'\frac{\epsilon^2\gamma^2 d}{\log d/\gamma}$（$c'&gt;0$是一个常数），期望的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率至少为$\frac{1}{2}-\gamma$.</li>
</ul>
<p>定理$\ref{thm:SCbound}$给我们最大的一个启示就是看起来对于分类问题，鲁棒分类错误是和样本遵循的分布高度相关的。具体来说，在高斯模型中，我们对于常规的分类错误来说只需要一个数据点就可以做到高概率的完美分类，但对于鲁棒分类错误我们至少需要$\sqrt{d}$阶的样本数量才能做到比较好的分类（这是由线性分类器对于鲁棒分类错误的样本复杂度和鲁棒分类错误的样本复杂度下界放在一起说明的）。而作为对比，对于伯努利模型，除了对于常规的分类错误来说同样一个数据点就可以做到高概率的完美分类，对于鲁棒分类错误来说用一个非线性的分类器也只需要一个数据点就可以做到完美分类。而在高斯模型中，下界保证了任何非线性的分类器在理论上也无法突破$\sqrt{d}$样本数量。</p>
<p>这便是<a href="https://papers.nips.cc/paper/2018/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html">Schmidt et al., 2018</a>的工作主要要说明的，为此它们利用了两个著名的开放分类数据集，MNIST和CIFAR10，利用卷积神经网络和前面提到的对抗训练算法，它们发现基于前者训练出来的分类器，在测试数据集上利用$\mathcal{U}_{\infty}^{\epsilon}$的定义扰动数据，可以达到很低的鲁棒分类错误率。而对于CIFAR，虽然还能保持一般意义上很低的分类错误率，却有很高的鲁棒分类错误率。基于前面的结果，一种可以接受的解释就是MNIST这个数据集更接近伯努利模型，而CIFAR10更接近高斯模型。另外，我们也可以体会到实际上神经网络模型对于标准意义上的分类错误能达到很高的标准，但往往对于鲁棒分类错误就不那么在行了。</p>
<h2 id="神经网络neural-network中的分布鲁棒优化">神经网络（Neural Network）中的分布鲁棒优化</h2>
<p>本节我们讨论上一节所引入的问题的一种更高级的尝试，利用分布式鲁棒优化进行对抗训练，具体来说我们主要介绍<a href="https://arxiv.org/abs/1710.10571">Sinha et al., 2018</a>的工作。注意，和前面不同的是，这里的分布式鲁棒优化里的不确定集不再是“确定性”的了，而是成了一个描述“分布”（测度）的集合。因此，我们相当于要考虑这样一个以对抗训练为目标的优化问题
$$
\min_{\pmb \theta\in \Theta} \max_{P\in\mathcal{P}}\mathbb{E}_P[g(\pmb \theta;\pmb Z)]. \label{equ:DRO}
$$
其中，$\pmb \theta$仍然是训练模型的参数，$\mathcal{P}$就是一个描述分布/测度的不确定集，而$\pmb Z$为将所有数据$Z=[\pmb X;\pmb y]$简写起来的形式。这边一个很关键的概念就是近些年机器学习和优化领域都十分热门的Wasserstein度量，令我们考虑的数据集$\pmb Z\in \mathcal{Z}$且$\mathcal{Z}$是实数域的一个子集，如果存在一个“价格”函数$c:\mathcal{Z}\times\mathcal{Z}\rightarrow \mathbb{R}_+ \cup \{\infty\}$,那么对任意两个取值在$\mathcal{Z}$上的概率测度$P,Q$，我们有$P,Q$之间的Wasserstein距离为
$$
W_c(P,Q):=\inf_{\mu\in \Gamma(P,Q) } \int_{\mathcal{Z}\times\mathcal{Z}} c(p,q)d\mu(p,q),
$$
其中$\Gamma(P,Q)$是所有取值在$\mathcal{Z}\times\mathcal{Z}$上的边缘分布为$P$和$Q$的概率测度的集合。于是，我们考虑我们的不确定集用Wasserstein度量定义，即$\mathcal{P}=\{P:W_c(P,P_0)\leq \rho\}$。然后我们可以证明，考虑问题(\ref{equ:DRO})的拉格朗日松弛形式，我们有如下等价关系（松弛因子$\gamma&gt;0$）：
$$
\min_{\pmb \theta\in \Theta}\underbrace{\max_{P}\mathbb{E}_P[g(\pmb \theta;\pmb Z)-\gamma W_c(P,P_0)]}_{F(\pmb \theta)}=\min_{\pmb \theta\in \Theta} \mathbb{E}_{P_0}[\underbrace{\max_{\pmb Z'\in \mathcal{Z}} \left(g(\pmb \theta;\pmb Z') -\gamma c(\pmb Z',\pmb Z)\right)}_{\phi_\gamma(\pmb \theta;\pmb Z)} ]. \label{equ:DRO_relaxed}
$$
然后，利用$P_0$的样本得到的经验分布$\hat P_n$代替$P_0$，我们需要求解优化问题：
$$
\min_{\pmb \theta\in \Theta}\mathbb{E}_{\hat P_n}[\phi_\gamma(\pmb \theta;\pmb Z) ]. \label{equ:DRO_empirical}
$$</p>
<p>对此，<a href="https://arxiv.org/abs/1710.10571">Sinha et al., 2018</a>给出了基于随机梯度下降法（SGD）的算法：</p>
<ul>
<li>输入：分布$P_0$的样本，$\Theta,\mathcal{Z}$，算法步长$\{\alpha_t&gt;0\}_{t=0}^{T}$</li>
<li><strong>for</strong> $t=0,\ldots,T-1$ <strong>do</strong>
<ul>
<li>抽样$\pmb Z^t\sim P_0$且找到$g(\pmb \theta^t;\pmb Z)-\gamma c(\pmb Z,\pmb Z^t)$的一个（局部）$\epsilon$-最优解$\pmb Z_t'$</li>
<li>$\pmb \theta^{t+1}\leftarrow \text{Proj}_{\Theta}(\pmb \theta^t-\alpha_t\nabla_{\pmb \theta}) g( \pmb \theta^t;\pmb Z_t') $</li>
</ul>
</li>
</ul>
<p><a href="https://arxiv.org/abs/1710.10571">Sinha et al., 2018</a>证明，在假设$c$是连续，且$c(\cdot,\pmb Z)$对任意$\pmb Z\in \mathcal{Z}$是1-强凸，并且$g$对于$\pmb \theta，\pmb Z$都是关于系数$L_{\pmb \theta\pmb \theta},L_{\pmb \theta\pmb Z},L_{\pmb Z\pmb Z},L_{\pmb Z\pmb \theta}$和$L_2$范数李普希茨（Lipschitz）连续的，算法对于问题(\ref{equ:DRO_relaxed})的全局最优值（$g$是凸的）/局部最优值的收敛速度。</p>
<p><strong>定理</strong>
{theorem}{非凸SGD的分布式鲁棒优化收敛性定理<a href="https://arxiv.org/abs/1710.10571">Sinha et al., 2018</a> }{nonconvexSGD}
%\label{thm:nonconvexSGD}</p>
<p>假设$\mathbb{E}[|\nabla F(\pmb \theta)-\nabla_{\pmb \theta}\phi_\gamma(\pmb \theta;\pmb Z) |_2^2]\leq \sigma^2$, $\Theta=\mathbb{R}^d$, 取$\Delta_F\geq F(\pmb \theta^0)-\min_{\pmb \theta} F(\theta)$, $L_\phi:=L_{\pmb \theta\pmb \theta}+\frac{L_{\pmb \theta \pmb Z}L_{\pmb Z \pmb \theta}}{\gamma-L_{\pmb Z\pmb Z}}$, $\alpha_t\equiv \sqrt{\frac{2\Delta_F}{L_\phi \sigma^2 T}}$。我们的算法保证
$$
\frac{1}{T}\sum_{t=1}^T \mathbb{E}\left[|\nabla F(\pmb \theta^t) |_2^2  \right] -\frac{2L_{\pmb \theta\pmb Z}^2}{\gamma-L_{\pmb Z\pmb Z}} \epsilon\leq \sigma\sqrt{\frac{8L_\phi \Delta_F}{T}}.
$$
{theorem}</p>
<p>这个收敛性定理成立的 关键还是在于我们对于$g$有光滑性假设，也就是说这里的分析对于常见的光滑的神经网络损失函数都是成立的。接下来，我们考虑理论上在鲁棒情形下这个算法的泛化（generalization）能力（对应前一节的鲁棒分类错误率）。事实上，<a href="https://arxiv.org/abs/1710.10571">Sinha et al., 2018</a>证明了如下结论：对任意$\theta\in \Theta$，
$$
\max_{P:W_c(P,P_0)\leq \rho}\mathbb{E}_P[g(\pmb \theta;\pmb Z)]\leq \gamma\rho+\mathbb{E}_{\hat P_n}[\phi_\gamma(\pmb \theta;\pmb Z)]+O(1/\sqrt{n}).
$$
具体的分析仍然是基于Monge映射$T_\gamma(\pmb \theta;\pmb Z_0):=\arg\max_{\pmb Z\in \mathcal{Z}}\{ g(\pmb \Theta;\pmb Z) - \gamma c(\pmb Z,\pmb Z_0) \}$的光滑性，这里我们不再展开讨论了，有兴趣的读者可以参阅他们的文章。</p>

    </div>

    
    


    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/RoSite/post/6.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E9%B2%81%E6%A3%92%E6%80%A7%E4%BC%98%E5%8C%96/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">鲁棒性优化（Robustness Optimization）</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/RoSite/post/8.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3/">
            <span class="next-text nav-default">鲁棒优化模型求解（Model implementation）</span>
            <span class="prev-text nav-mobile">Next</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

  <div id="remark42"></div>

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:operations_r@163.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/Operations-Research-Science" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://www.zhihu.com/org/yun-chou-orwei-wo" rel="me noopener" class="iconfont"
      title="zhihu"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M351.791182 562.469462l192.945407 0c0-45.367257-21.3871-71.939449-21.3871-71.939449L355.897709 490.530013c3.977591-82.182744 7.541767-187.659007 8.816806-226.835262l159.282726 0c0 0-0.86367-67.402109-18.578124-67.402109s-279.979646 0-279.979646 0 16.850783-88.141456 39.318494-127.053698c0 0-83.60514-4.510734-112.121614 106.962104S81.344656 355.077018 76.80834 367.390461c-4.536316 12.313443 24.62791 5.832845 36.941354 0 12.313443-5.832845 68.050885-25.924439 84.252893-103.69571l86.570681 0c1.165546 49.28652 4.596691 200.335724 3.515057 226.835262L109.86113 490.530013c-25.275663 18.147312-33.701566 71.939449-33.701566 71.939449L279.868105 562.469462c-8.497535 56.255235-23.417339 128.763642-44.275389 167.210279-33.05279 60.921511-50.55235 116.65793-169.802314 212.576513 0 0-19.442818 14.257725 40.829917 9.073656 60.273758-5.185093 117.305683-20.739347 156.840094-99.807147 20.553105-41.107233 41.805128-93.250824 58.386782-146.138358l-0.055259 0.185218 167.855986 193.263655c0 0 22.035876-51.847855 5.832845-108.880803L371.045711 650.610918l-42.1244 31.157627-0.045025 0.151449c11.69946-41.020252 20.11206-81.5749 22.726607-116.858498C351.665315 564.212152 351.72876 563.345412 351.791182 562.469462z"></path>
  <path d="M584.918753 182.033893l0 668.840094 70.318532 0 28.807093 80.512708 121.875768-80.512708 153.600307 0L959.520453 182.033893 584.918753 182.033893zM887.150192 778.934538l-79.837326 0-99.578949 65.782216-23.537066-65.782216-24.855084 0L659.341766 256.673847l227.807403 0L887.149169 778.934538z"></path>
</svg>

    </a>
  
    <a href="https://space.bilibili.com/403058474" rel="me noopener" class="iconfont"
      title="bilibili"  target="_blank"
      >
      <svg
  class="icon" style="" viewBox="0 0 1024 1024" version="1.1" width="36"
  height="36" id="svg8">
  <path
      style=""
      d="M 744.60599,0.00486267 A 41.779915,41.779915 0 0 0 710.4184,18.673394 L 548.5048,255.32642 h -11.70046 a 41.779915,41.779915 0 0 0 -10.80295,-7.84928 L 235.66,97.084498 a 41.779915,41.779915 0 0 0 -20.07193,-4.960864 41.779915,41.779915 0 0 0 -18.3748,79.145436 L 359.4859,255.32642 H 128.16909 c -49.458302,0 -89.27932,39.82105 -89.27932,89.27932 v 508.65224 c 0,49.4583 39.821018,89.27934 89.27932,89.27934 h 19.48445 C 149.12802,984.5043 179.92773,1024 224.79179,1024 c 44.86407,0 75.66379,-39.4957 77.13826,-81.46268 H 719.98116 C 721.45559,984.5043 752.25533,1024 797.1194,1024 c 44.86406,0 75.6638,-39.4957 77.13824,-81.46268 h 21.57323 c 49.45831,0 89.27936,-39.82104 89.27936,-89.27934 V 344.60574 c 0,-49.45827 -39.82105,-89.27932 -89.27936,-89.27932 H 649.74567 L 779.38103,65.866924 A 41.779915,41.779915 0 0 0 744.60599,0.00486267 Z M 644.49108,418.70871 c 6.29985,0.21538 12.44451,2.01107 17.86888,5.22196 l 171.36218,98.10771 c 18.23417,10.21935 24.63334,33.34627 14.24614,51.48533 -10.38726,18.13909 -33.57344,24.32718 -51.61587,13.77296 L 624.9903,489.18895 c -15.21356,-8.41858 -22.66871,-26.1765 -18.03211,-42.93436 4.63664,-16.75784 20.15573,-28.14465 37.53289,-27.54588 z M 350.2006,432.31846 c 16.89952,0.0317 31.69582,11.33328 36.17844,27.62747 4.48262,16.2942 -2.44981,33.57765 -16.95507,42.24898 l -140.7157,86.91312 c -17.68528,11.18244 -41.09629,5.77692 -52.08912,-12.02686 -10.99282,-17.80373 -5.33855,-41.15658 12.58167,-51.95857 L 329.9002,438.2095 c 6.0643,-3.86439 13.10951,-5.90891 20.3004,-5.89104 z M 501.605,641.53985 c 3.75002,-0.15248 7.48645,0.53903 10.93349,2.0235 0.15842,0.0637 0.31618,0.12888 0.47325,0.19582 0.59328,0.27092 1.17574,0.56489 1.74609,0.88121 0.15868,0.0854 0.31643,0.17233 0.47325,0.2611 0.55694,0.32165 1.10131,0.66458 1.63185,1.02807 0.16455,0.1123 0.32777,0.2265 0.48956,0.34269 0.50382,0.36781 0.99371,0.75428 1.46868,1.15864 0.18724,0.15504 0.37218,0.31282 0.55484,0.47323 0.43271,0.38784 0.8518,0.79061 1.25653,1.20756 0.15449,0.16114 0.30679,0.32437 0.45693,0.48959 0.40798,0.44266 0.79989,0.89988 1.17494,1.37076 0.17799,0.22544 0.35205,0.45395 0.5222,0.68538 0.25932,0.34701 0.50964,0.70071 0.75064,1.06071 0.26712,0.39516 0.52286,0.79784 0.76699,1.20757 0.16907,0.29043 0.33231,0.58424 0.48957,0.88123 0.21836,0.41297 0.42513,0.83199 0.62009,1.25653 0.14836,0.32333 0.28983,0.64976 0.42429,0.97911 0.21319,0.51552 0.40915,1.03801 0.58747,1.5666 0.0677,0.19499 0.13296,0.39085 0.19582,0.58748 0.18652,0.60823 0.34984,1.22334 0.48957,1.84399 0.0397,0.16277 0.0779,0.32601 0.11423,0.48957 0.1436,0.69112 0.25788,1.38801 0.34269,2.08877 0.005,0.0381 0.0111,0.0761 0.0163,0.11424 0.0857,0.78056 0.13474,1.56471 0.14687,2.34988 0.005,0.0543 0.0111,0.10879 0.0163,0.1632 0,0 -0.008,1.12132 0,1.45234 0,0 -0.14697,17.84761 5.89102,34.12231 3.01902,8.13734 7.33278,15.10615 12.61433,19.61501 5.28157,4.50889 11.42894,7.62081 23.64572,7.62081 12.2168,0 18.36416,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.5953,-11.47767 12.6143,-19.61501 6.03799,-16.2747 5.89103,-34.12231 5.89103,-34.12231 -0.44885,-13.87045 10.45922,-25.46302 24.3311,-25.86506 13.87189,-0.40201 25.42828,10.53953 25.78348,24.41272 0,0 1.11929,25.7226 -9.00791,53.01927 -5.06359,13.64832 -13.1986,28.46036 -27.05631,40.29073 -13.85772,11.83039 -33.5454,19.63135 -56.20142,19.63135 -22.65603,0 -42.34371,-7.80096 -56.20141,-19.63135 -4.1801,-3.56856 -7.78733,-7.42433 -10.99878,-11.42303 -3.21235,4.00037 -6.81703,7.85309 -10.99876,11.42303 -13.85773,11.83039 -33.5454,19.63135 -56.20144,19.63135 -22.65601,0 -42.3437,-7.80096 -56.2014,-19.63135 -13.85775,-11.83037 -21.99272,-26.64241 -27.05632,-40.29073 -10.12725,-27.29667 -9.00789,-53.01928 -9.00789,-53.01927 0.20714,-13.83687 11.58744,-24.88848 25.42444,-24.69013 14.1263,0.19991 25.2971,12.0278 24.69011,26.14247 0,0 -0.14697,17.84761 5.89103,34.12231 3.01902,8.13734 7.31646,15.10615 12.598,19.61501 5.28155,4.50889 11.44526,7.62081 23.66203,7.62081 12.21681,0 18.36418,-3.11192 23.64573,-7.62081 5.28154,-4.50886 9.57899,-11.47767 12.598,-19.61501 5.76352,-15.53489 5.89112,-32.05691 5.89103,-33.56746 0.006,-0.37466 0.0111,-1.05336 0.0163,-1.20759 -0.0117,-0.74583 0.0105,-1.49177 0.0652,-2.23565 0.009,-0.15784 0.0204,-0.31561 0.0327,-0.47324 0.14204,-1.56859 0.43163,-3.12027 0.86487,-4.63449 0.0213,-0.0763 0.0433,-0.15244 0.0652,-0.22848 3.0335,-10.25748 12.24157,-17.46007 22.92769,-17.93417 z"
      id="rect824"/>
</svg>

    </a>


<a href="https://allenz-me.github.io/RoSite/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
  
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2017 -
    2022
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        运筹OR帷幄
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/RoSite/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/RoSite/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/RoSite/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/RoSite/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/RoSite/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/RoSite/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







<script>
  if (typeof MathJax === 'undefined') {
      window.MathJax = {
          loader: {
              load: ['[tex]/mhchem']
          },
          
          tex: {
              inlineMath: {'[+]': [['$', '$']]},
              tags: 'ams',
              packages: {'[+]': ['mhchem']}
          }
      };
      (function() {
          var script = document.createElement('script');
          script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
          script.defer = true;
          document.head.appendChild(script);
      })();
  } else {
      MathJax.texReset();
      MathJax.typeset();
  }
</script>

</body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>鲁棒优化电子书 —— 运筹OR帷幄</title>
    <link>https://allenz-me.github.io/RoSite/</link>
    <description>Recent content on 鲁棒优化电子书 —— 运筹OR帷幄</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 10 Jan 2022 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://allenz-me.github.io/RoSite/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>序言</title>
      <link>https://allenz-me.github.io/RoSite/post/0preface/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/0preface/</guid>
      
        <description>&lt;p&gt;沈顺璇教授(Prof. Melvyn Sim)会为我们做序&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>鲁棒优化简介（Introduction）</title>
      <link>https://allenz-me.github.io/RoSite/post/1.-%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/1.-%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E7%AE%80%E4%BB%8B/</guid>
      
        <description>&lt;p&gt;汤勤深&lt;/p&gt;
&lt;p&gt;根据维基百科，鲁棒优化（Robust Optimization）是最优化理论中的一类用来寻求在不确定（Uncertain)环境中使优化问题具有一定程度的鲁棒性（Robustness）的方法。其中，不确定性可以通过问题的参数或者解的确定性变异（Deterministic variability）来刻画 &lt;a href=&#34;https://en.wikipedia.org/wiki/Robust_optimization&#34;&gt;(Wikipedia, 2021)&lt;/a&gt;。也就是说鲁棒优化是用来寻求对不确定性免疫的解的一类方法 &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;(Bertsimas and Sim, 2004)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;在传统的优化模型中，通常假设模型的输入数据是具体的、准确的数值。然而，现实生活中所获得的大部分数据都是具有一定的误差。而有时细微的误差也将导致优化问题的最优解不再最优或者导致原问题不具有可行解（Infeasible）。以&lt;a href=&#34;http://www.netlib.org/&#34;&gt;NETLIB&lt;/a&gt;中题PILOT4为例，其某一约束为：
$$
\begin{align*}
{\pmb{a}^{\top} \pmb{x} \equiv} &amp;amp; {-15.79081 x_{826}-8.598819 x_{827}-1.88789 x_{828}-1.362417 x_{829}-1.526049 x_{830}}\\\
&amp;amp; { -0.031883 x_{849}-28.725555 x_{850}-10.792065 x_{851}-0.19004 x_{852}-2.757176 x_{853}}\\\
&amp;amp; { -12.290832 x_{854}+717.562256 x_{855}-0.057865 x_{856}-3.785417 x_{857}-78.30661 x_{858}} \\\
&amp;amp; { -122.163055 x_{859}-6.46609 x_{860}-0.48371 x_{861}-0.615264 x_{862}-1.353783 x_{863}}\\\
&amp;amp; { -84.644257 x_{864}-122.459045 x_{865}-43.15593 x_{866}-1.712592 x_{870}-0.401597 x_{871}}\\\ 
&amp;amp; { +x_{880}-0.946049 x_{898}-0.946049 x_{916} \geq b \equiv 23.387405.}
\end{align*}
$$
用Cplex解得这个问题的解为：
$$
\begin{array}{lll}
x_{826}^{*} = 255.6112787181108 &amp;amp; x_{827}^{*}=6240.488912232100 &amp;amp; x_{828}^{*}=3624.613324098961 \\\ 
{x_{829}^{*} = 18.20205065283259} &amp;amp; {x_{849}^{*}=174397.0389573037} &amp;amp; {x_{870}^{*}=14250.00176680900} \\\
{x_{871}^{*} = 25910.00731692178} &amp;amp;  {x_{880}^{*}=104958.3199274139} &amp;amp;.
\end{array}
$$&lt;/p&gt;
&lt;p&gt;解$\pmb{x}^{*}$满足$\pmb a^{\top} \pmb x^* = b$。 然而，只要稍微改动$\pmb{a}$中某一项的系数，那么$\pmb a^{\top} \pmb x^* \neq b$，也即$\pmb x^*$不再是最优解。&lt;/p&gt;
&lt;p&gt;如何解决这个问题？最直观的方法是，假设每一个系数都在一定范围内变动，从而求一个解使得对所有在这个范围内变动的系数都是最优的。举个例子，对于约束
$$
ax \leq b,
$$
我们希望它对所有$a \in [\underline{a}, \bar{a}]$ 都成立，也即原有约束将变成
$$
ax \leq b,, \forall a \in [\underline{a}, \bar{a}].
$$
这个问题首先由Soyster在1973年研究&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.21.5.1154&#34;&gt;(Soyster, 1973)&lt;/a&gt;。他假设系数矩阵$\pmb A$中每一列都在一个下凸集（Convex set）中（也称为列不确定性），也即他研究如下问题： 
$$
\begin{array}{cl} 
\max &amp;amp; \pmb{c}^{\prime} \pmb{x} \\\ 
\mathbf { s.t. } &amp;amp; \displaystyle \sum_{j=1}^{N} \pmb A_{j} x_{j} \leq \pmb{b}, \quad \forall \pmb A_{j} \in \mathcal{U}_{j}, j\in [N] \\\ 
&amp;amp; \pmb{x} \geq \mathbf{0}.
\end{array}
$$&lt;/p&gt;
&lt;p&gt;然而，此种方法所得到的解太过于保守（Conservative）而饱受诟病。随后Ben-tal and Nemirovski &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/moor.23.4.769&#34;&gt;1998&lt;/a&gt;, &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0167637799000164&#34;&gt;1999&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/PL00011380&#34;&gt;2000&lt;/a&gt;和&lt;a href=&#34;https://epubs.siam.org/doi/10.1137/S0895479896298130&#34;&gt;EI-Ghaoui and Lebret 1997&lt;/a&gt;, &lt;a href=&#34;&#34;&gt;EI-Ghaoui et al. 1998&lt;/a&gt;为降低保守性而引进了椭球型不确定集（Ellipsoids uncertainty set）。同时也考虑了其他形式的不确定性，比如行不确定性。其中，椭球型不确定集一方面比较难跟现实数据结合，另外一方面，转化（Reformulate）之后的模型大都是二阶锥规划（Second order cone programming）或者半正定规划（Semi-definite programming）问题&amp;mdash;求解起来比较复杂。此外，这种方法依然比较保守。&lt;/p&gt;
&lt;p&gt;2004年， &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;为了克服椭球型不确定集的缺点，引进了预算不确定集（budget uncertainty set），将原问题转化成线性规划问题，并且得出了所得解可行概率的下限，也即所得解对所有约束不可行的概率的上限。&lt;/p&gt;
&lt;p&gt;本电子书将在第三章介绍不确定性最优化，不同种类的不确定集，以及鲁棒优化理论中很核心的对等式转换理论（Robust counterpart）。此电子书把这种将模型参数假定在给定不确定集中而进行优化问题求解的方法统称为经典鲁棒优化（Classical robust optimization）。&lt;/p&gt;
&lt;p&gt;为什么称为经典鲁棒优化？因为经典鲁棒优化构成了现在普遍使用的分布鲁棒优化（Distributionally robust optimization）的基础，同时也是分布鲁棒优化的一种特殊形式。&lt;/p&gt;
&lt;p&gt;如果我们不仅仅知道优化模型某些参数（以下称为随机量，即random variable）的支撑集（Support set），还知道这些参数服从某一分布，那此类优化问题为随机优化问题（Stochastic programming）：&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\min\ &amp;amp; \mathbb{E}_{\mathbb{P}}[g(\pmb x,\tilde{\pmb \xi})], \label{model::stochastic programming} \\\ 
\mathbf{s.t.}\ &amp;amp;  \mathbb{E}_{\mathbb{P}}[f_i(\pmb x,\tilde{\pmb \xi})] \leq 0,, i\in[I], \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;一般地，我们假设$g(\cdot)$和$f_i(\cdot)$均为下凸函数。&lt;/p&gt;
&lt;p&gt;可是，恰恰是知道随机量服从某一分布这个假设导致很多问题。一方面，模型中的随机量在生产经营或者模型背景中通常是多种因素作用的结果，这就导致很难准确估计某一随机量的边际分布，更别说所有随机量的集中分布了。另一方面，就算知道边际分布或者集中分布，除了很多时候因为随机量过多而模型维度过大之外，在多阶段问题中，还常常受制于“维度诅咒（Curse of dimentionality）”。而在现今科技发展，各行各业所收集和掌握的数据量呈井喷式态势，使得从大量数据中提取一些随机量的统计信息（比如需求的均值和方差）变得可行。而分布式鲁棒优化提供了将这些统计信息融入到模型决策中的一种思路。&lt;/p&gt;
&lt;p&gt;具体来说，如果我们将所需要用到的统计信息放到一个集合中，假设为$\mathcal{F}$，那么$\mathcal{F}$就是所有拥有这些统计信息的分布的一个集合。我们称这个集合为模糊集（Ambiguity set）。在模糊集中，选取一个分布使得在最坏情况下，进行模型求解。这样所求得的解就具有一定的鲁棒性。也即，模型$\eqref{model::stochastic programming}$将变成：&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\min\ &amp;amp; \sup_{\mathbb{P} \in \mathcal{F}}\mathbb{E}_{\mathbb{P}}[g(\pmb x,\tilde{\pmb\xi}], \label{model::General DRO model}\\\
\mathbf{s.t.}\ &amp;amp;  \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[f_i(\pmb x,\tilde{\pmb\xi}] \leq 0,, i\in[I].\notag
\end{align}
$$
我们称模型$\eqref{model::General DRO model}$为分布鲁棒优化模型。其中，如果$\mathcal{F} = {\mathbb{P}}$，那分布鲁棒模型就是随机优化模型。如果，在$\mathcal{F}$中，我们只知道随机量$\tilde{\pmb \xi}$在某一个集合$\mathcal{U}$中，那分布鲁棒模型退化成经典鲁棒模型。本书将在第四种着重介绍不同不同的模糊集和分布式鲁棒模型的求解方法。&lt;/p&gt;
&lt;p&gt;以上的经典鲁棒优化模型和分布鲁棒优化模型只适用于单阶段（Single stage）问题。而现实中所面临的决策往往是多阶段（Multi-stage）的。
其中，最经典的莫过于两阶段随机规划模型：
$$\begin{align}
\min\ &amp;amp; \pmb c^{\top} \pmb x + \mathbb{E}_{\mathbb{P}}[g(\pmb x,\tilde{\pmb \xi}],\label{model::Two Stage SP model} \\\
\mathbf{s.t.}\ &amp;amp;  \pmb{Ax} = \pmb b\notag \\\
&amp;amp; \pmb x \geq \mathbf{0},\notag
\end{align}
$$
其中
$$ \begin{align*}
g(\pmb x,\pmb \xi) = \min\ &amp;amp; \pmb q^{\top}\pmb{y},\\\
\mathbf{s.t.}\ &amp;amp;  \pmb{T}\pmb x + \pmb{W}\pmb y = \pmb h\\\
&amp;amp; \pmb y \geq \mathbf{0}，
\end{align*}
$$
$\pmb \xi := (\pmb q, \pmb h, \pmb T, \pmb W)$为第二阶段的输入数据。也即第二阶段的决策依赖于第一阶段随机量的实现（Realization）。这就导致在模型 $\eqref{model::Two Stage SP model}$ 中，第一阶段决策变量$\pmb x$称为“现时决策（Here-and-now decision）”各阶段之间决策变量和随机量之间的交互使得问题的复杂度随着阶段的增加而呈指数增长，也即“维度诅咒”。在随机规划中，学者们通过引入决策规则（Decision rule）去近似地解决这一问题。但是，因为近似模型表现不好而被“打入冷宫”。而鲁棒优化的出现，让决策规则重洗换发出了勃勃生机。本书将在第五章详细介绍多阶段随机规划问题以及如何使用不同的决策规则和鲁棒优化的方法对其进行近似，并且取得很好的近似效果。&lt;/p&gt;
&lt;p&gt;近年来，随着鲁棒优化在各种不同问题求解中的良好表现，其价值越来越被学界和业界所发现。比如，从鲁棒优化的角度去处理具有广泛运用的机会约束问题，可以收到比较好的效果。而最新的研究显示，被广泛运用在机器学习中回归模型（Regression）的正则性（Regularization）和鲁棒优化具有等价关系。这一发现启发了越来越多的学者将鲁棒优化和机器学习相结合。本书将在第六章讲解鲁棒优化下的机会约束问题，在第七种讲解鲁棒优化和机器学习结合的一些最新研究成果。&lt;/p&gt;
&lt;p&gt;同时，在本书的最后一章，我们将介绍鲁棒模型在不同求解平台上的实现方式。也将在不同的章节引入不同的案例或算例。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>概览（Overview）</title>
      <link>https://allenz-me.github.io/RoSite/post/2.%E6%A6%82%E8%A7%88/</link>
      <pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/2.%E6%A6%82%E8%A7%88/</guid>
      
        <description>&lt;p&gt;孙秋壮&lt;/p&gt;
&lt;p&gt;在进行系统的鲁棒优化学习之前，我们进行一些预备知识的回顾。本章将对线性规划、凸优化、锥优化以及风险偏好及其度量进行简要介绍。&lt;/p&gt;
&lt;h2 id=&#34;线性规划概览linear-optimization&#34;&gt;线性规划概览（Linear optimization）&lt;/h2&gt;
&lt;p&gt;线性规划（LP）是数学规划中形式最为简单的一种模型。一个线性规划可以写作：
$$
\begin{array}{rcl}
&amp;amp; \min &amp;amp; \pmb{c}^{\top} \pmb{x} \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb{A}\pmb x \geq \pmb{b}, \\\
&amp;amp;  &amp;amp; \pmb{x}  \geq \pmb{0}. \\\
\end{array}
$$
可见上式中，目标函数和约束都是线性的形式，所以被叫做“线性规划”。虽然它的形式简单，但线性规划的建模能力非常强大，有很多经典的数学建模问题都可以转化为线性规划，也有很多非线性的函数也可以等价转化为线性规划求解。比如对于如下非线性的规划
$$
\begin{array}{rcl}
&amp;amp; \min &amp;amp; f( \pmb{x} ) = \displaystyle\max_{k} { \pmb{d}^{\top}_k \pmb{x} + c_k } \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb{A} \pmb x \geq \pmb{b}.
\end{array}
$$
我们可以等价地将其转化为线性规划
$$
\begin{array}{rcl}
&amp;amp; \min &amp;amp; z \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb{A} \pmb x \geq \pmb{b}, \\\
&amp;amp; &amp;amp;  z \geq \pmb{d}^{\top}_k \pmb{x} + c_k, \forall k.  \\\
\end{array}
$$
当然，在实际解决过程的问题中要十分注意转化是否等价！一个常见的错误就是认为如下的两个数学规划问题是等价的。
$$
\begin{array}{rcl}
&amp;amp; \min &amp;amp; \displaystyle\sum_j c_j|x_j| \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb{A} \pmb x \geq \pmb{b}. \\\
\end{array}
$$
$$
\begin{array}{rcl}
&amp;amp; \min &amp;amp; \displaystyle \sum_j c_jz_j \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb{A} \pmb x \geq \pmb{b}, \\\
&amp;amp; &amp;amp;  x_j \geq z_j, \\\
&amp;amp; &amp;amp;  -x_j \geq z_j. \\\
\end{array}
$$
其实，当第一个规划问题有界，且存在$c_j&amp;lt;0$时，我们可以令线性规划中对应的$z_j\mapsto\infty$，使得第二个问题最优解趋向于$-\infty$。此时易见两个问题并非等价。&lt;/p&gt;
&lt;p&gt;说到数学规划问题，就不得不提到对偶（duality）理论。考虑一个（标准形式的）线性规划问题：
$$
\begin{array}{rcl}
&amp;amp;\min &amp;amp; \pmb{c}^{\top}\pmb x \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb A \pmb x = \pmb b, \\\
&amp;amp;&amp;amp; \pmb x \geq \pmb 0.
\end{array}
$$
我们可以使用拉格朗日乘子将上述问题写成：
$$
\begin{array}{rcl}
g(\pmb p) = &amp;amp;\min &amp;amp; \pmb{c}^{\top}\pmb x + \pmb p^{\top}( \pmb b -  \pmb A \pmb x)\\\
&amp;amp; {\rm s.t.}&amp;amp; \pmb x \geq \pmb 0.
\end{array}
$$
令$\pmb x^{*}$为线性规划的最优解，可见
$$
g(\pmb p) \leq \pmb c^{\top}\pmb x^{*} + \pmb p^{\top}( \pmb b -  \pmb A \pmb x^{*}) = \pmb c^{\top} \pmb x^{*}, \quad \forall \pmb p.
$$
也就是说，$ g(\pmb p)$是最优目标函数$\pmb c’\pmb x^{*} $的一个下界。为了使这个下界尽可能的“紧”一些，我们想要求得$\displaystyle\max_{\pmb p} g(\pmb p)$：
$$
g(\pmb p)=\min_{\pmb x \geq \pmb 0} [\pmb c^{\top}\pmb x + \pmb p^{\top}(\pmb b - \pmb A \pmb x)]
=\pmb p^{\top}\pmb b+\min_{\pmb x\geq \pmb 0}[(\pmb c + \pmb A^{\top}\pmb p)^{\top}\pmb x].
$$
其中，我们有
$$
\min_{\pmb x\geq \pmb 0}[(\pmb c + \pmb A^{\top}\pmb p)^{\top}\pmb x]=
\begin{cases}
0, &amp;amp; \pmb c^{\top}+\pmb p^{\top}\pmb A \geq \pmb 0, \\\
-\infty, &amp;amp; \text{otherwise}.
\end{cases}
$$
至此，我们推出了原问题（primal）的对偶形式
$$
\begin{array}{rcl}
&amp;amp;\max &amp;amp; \pmb{b}^{\top}\pmb p \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb A^{\top} \pmb p \leq \pmb c. \\\
\end{array}
$$&lt;/p&gt;
&lt;p&gt;关于原问题和对偶问题的关系，我们有弱对偶和强对偶两个定理。其中弱对偶表述的是：当$\pmb x$是原问题的可行解且$\pmb p$是对偶问题的可行解时，我们一定有$\pmb b^{\top} \pmb p\leq \pmb c^{\top}\pmb x$。也就是说原问题（min）的最优目标函数都要比对偶问题（max）最优目标函数要大。由此定理可知，如果我们能找到一组可行解$(\pmb x,\pmb p)$使得$\pmb b^{\top} \pmb p=\pmb c^{\top} \pmb x$，那么$\pmb x$和$\pmb p$就一定分别是原问题和对偶问题的最优解。值得一提的是，弱对偶对任意数学规划问题都成立。而强对偶表述的是：当线性规划有一个最优解时，那么它的对偶问题也有最优解，且两个问题的最优目标函数值相同。注意这里我们加上了线性规划这一条件。在更一般的凸优化中，我们必须要验证Slater condition来确认强对偶是否成立。关于线性规划的详细介绍，可以参阅&lt;a href=&#34;http://athenasc.com/linoptbook.html&#34;&gt;Bertsimas and Tsitsiklis, 1997&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;凸优化概览convex-optimization&#34;&gt;凸优化概览（Convex optimization）&lt;/h2&gt;
&lt;p&gt;虽然线性规划的建模能力十分强大，现实生活中很多非线性问题依然无法被LP解决。这个时候我们需要使用非线性规划（NLP）来求出最优解。一个非线性规划可以写作
$$
\begin{array}{rcll}
&amp;amp;\min &amp;amp; f(\pmb{x}) \\\
&amp;amp; {\rm s.t.} &amp;amp; g_i(\pmb x) \leq 0, &amp;amp; i=1,…,m, \\\
&amp;amp; &amp;amp; h_i(\pmb x) = 0, &amp;amp; i=1,…,l. \\\
\end{array}
$$
其中，$f(\pmb x):\mathbb R^n\mapsto\mathbb R$，$g_i(\pmb x):\mathbb R^n\mapsto\mathbb R$和$h_i(\pmb x):\mathbb R^n\mapsto\mathbb R$是关于$\pmb x$的（通常连续且可微的）函数。&lt;/p&gt;
&lt;p&gt;在非线性规划问题中，我们通常关注局部最优点和全局最优点。如果对于可行域中的$\pmb x$，对于任意可行域中的$\pmb y$都有$f(\pmb x)\leq f(\pmb y)$，那么$\pmb x$就是全局最小。类似的，如果$f(\pmb x)$比它周围的点都要小，那么$\pmb x$是一个局部最小。（局部最小严格定义是，存在以$\pmb x$为中心的一个开球，使得$f(\pmb x)$比开球和可行域交集中所有可以取到的函数值都要小。）对于一个一般的非线性规划问题，我们通常很难验证一个点是局部最优还是全局最优。而如果一个非线性规划问题是凸优化问题，这个问题便迎刃而解。
具体来说，一个函数$f:S\mapsto R$如果满足$f(\lambda \pmb x_1+(1-\lambda)\pmb x_2)\leq \lambda f(\pmb x_1)+(1-\lambda)f(\pmb x_2)$，$\forall \lambda\in[0,1]$, $\pmb x_1, \pmb x_2\in S$，那么这个函数就被称为凸函数。在一个非线性规划问题中，如果$f(\pmb x)$，$g(\pmb x)$和$h(\pmb x)$都为凸函数，那么这个NLP就是一个凸优化问题。&lt;/p&gt;
&lt;p&gt;凸优化中一个重要的定理就是，如果$\pmb x^*$是$f$的局部最小，那么$\pmb x^*$也是$f$可行域中的全局最小。这个性质使得很多算法（例如各种迭代下降算法、内点算法等等）可以找到凸优化问题的全局最优解。我们也可以应用KKT条件来验证一个解是否为凸优化的问题的最优解。凸优化的详细介绍可以参阅 &lt;a href=&#34;https://web.stanford.edu/~boyd/cvxbook/&#34;&gt;Boyd and Vandenberghe&lt;/a&gt;。然而，在一个凸优化问题中，凸函数$f$，$g$和$h$的形式太过多元化。相比之下，任意一个线性规划都可以转化为标准形式。这样的标准形式可以大大减少推导鲁棒对等式（robust counterpart）时的步骤。那么一个凸优化问题可以转变为“标准形式”吗？为了达到这个目的，我们将在下节中介绍锥优化。&lt;/p&gt;
&lt;h2 id=&#34;锥优化概览conic-optimization&#34;&gt;锥优化概览（Conic optimization）&lt;/h2&gt;
&lt;p&gt;沿用上节的符号系统，我们考虑目标函数$f(\pmb x)$为线性形式的凸优化问题，即$f(\pmb x)=\pmb c^{\top} \pmb x$。无论$g(\pmb x)$和$h(\pmb x)$形式如何，凸优化问题的可行域一定是一个凸集，写作$\mathcal X$。那么我们考虑的凸优化问题可以表示为：
$$
\begin{array}{rcl}
&amp;amp;\min &amp;amp; \pmb c^{\top}\pmb{x} \\\
&amp;amp; {\rm s.t.} &amp;amp; \pmb x \in \mathcal X. \\\
\end{array}
$$
这个问题可以等价为如下规划问题
$$
\begin{array}{rcl}
&amp;amp;\min &amp;amp; \pmb c^{\top}\pmb{x} \\\
&amp;amp; {\rm s.t.} &amp;amp; y=1, \\\
&amp;amp; &amp;amp; (\pmb x,y)\in \mathcal K.
\end{array}
$$
其中，$\mathcal K=\text{cl}{ (\pmb x,y):\pmb x/y \in \mathcal X, y&amp;gt;0 }$，$\text{cl}{\cdot}$表示一个集合的闭包。之所以写成这种形式，是因为$\mathcal K$是一种叫作“锥”的性质非常好的集合。我们把一个集合$\mathcal K$叫作锥，如果对任意的$\pmb x\in \mathcal  K$，$\lambda \pmb x\in \mathcal K$对所有$\lambda \geq 0$都成立。&lt;/p&gt;
&lt;p&gt;基于这个变换，第一个问题是：如何把线性规划和锥联系起来？第二个问题是：如果有办法联系起来，我们可以把线性规划的优良性质借鉴过来吗？我们先解决第一个问题——显然，非负$m$维实数域$\mathbb R_+^m$是一个锥。那么，我们可以把一个线性约束等价为
$$
\pmb{A} \pmb x \geq \pmb b \Leftrightarrow \pmb{A}\pmb x - \pmb b \geq \pmb 0 \Leftrightarrow \pmb{A}\pmb x - \pmb b \in \mathcal{K}, \quad \mathcal{K} = \mathbb{R}_{+}^{m}.
$$
而线性规划中很多非常好的数学性质来源于不等号“$\geq$”。具体来说，不等号满足&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;反射性（reflexibility）：$\pmb a \geq \pmb a$；&lt;/li&gt;
&lt;li&gt;反对称性（antisymmetry）：如果$\pmb a \geq \pmb b$且$\pmb b \geq \pmb a$，那么$\pmb a = \pmb b$；&lt;/li&gt;
&lt;li&gt;传递性（transitivity）：如果$\pmb a \geq  \pmb b$且$\pmb b \geq \pmb c$，那么$\pmb a \geq  \pmb c$；&lt;/li&gt;
&lt;li&gt;如果$\pmb a \geq \pmb b$，那么$\lambda \pmb a \geq \lambda \pmb b$对于所有$\lambda \geq 0$成立；&lt;/li&gt;
&lt;li&gt;如果$\pmb a \geq \pmb b$且$\pmb c\geq  \pmb d$，那么$\pmb a+ \pmb c \geq  \pmb b+ \pmb d$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于这个观察，我们是否可以对于一个任意的锥$\mathcal K$，定义一个广义的不等式呢？答案是可以的。我们用“$\succeq_{\mathcal K}$”来定义如下的广义不等式关系：
$$
\pmb{A}\pmb x \succeq_{\mathcal{K}} \pmb{b} \Leftrightarrow \pmb{A}\pmb x - \pmb{b} \succeq_{\mathcal{K}} \pmb{0} \Leftrightarrow \pmb{A}\pmb x - \pmb{b} \in \mathcal{K},
$$
$$
\pmb{A}\pmb x \succ_{\mathcal{K}} \pmb{b} \Leftrightarrow \pmb{A}\pmb x - \pmb{b} \succ_{\mathcal {K}} \pmb{0} \Leftrightarrow \pmb{A}\pmb x - \pmb{b} \in \mathrm{int} \mathcal{K}.
$$
可以证明，不等关系“$\succeq_{\mathcal K}$”同样继承了不等号“$\geq$”的上述所有性质。&lt;/p&gt;
&lt;p&gt;基于这个推导，我们可以将一个（目标函数为线性函数的）凸优化问题一般化为锥优化框架
$$
\begin{array}{lll}
\min  &amp;amp; \displaystyle \sum_{j \in [M]}c_j^{\top} x_j &amp;amp; \\\
\text{ s.t. } &amp;amp; \displaystyle  \sum_{j\in [M]} \pmb{A}_{j} x_{j} = \pmb b, &amp;amp; \\\
&amp;amp; \pmb{x}_{i} \succeq_{\mathcal{K}_i} \pmb{0}, &amp;amp; i \in [M].
\end{array}
$$
这个形式可以比作锥优化的“标准形式”。可见它和线性规划的标准形式有诸多相似之处。推导到这里，几个很自然的问题就是，这个问题的对偶形式是什么样的？强对偶在这个问题中成立吗？为了回答这些问题，首先引入对偶锥的概念。对于锥$\mathcal K$，它的对偶锥定义为
$$
\mathcal{K}^{*} = \{\pmb{y} : \pmb{y}^{\top} \pmb{x} \geq 0, \quad \forall \pmb{x} \in \mathcal{K}\}.
$$
有了这个定义，我们来推导锥优化的对偶问题。为了简单起见，我们忽略线性约束，考虑
$$
\begin{array}{rl}
\min &amp;amp; \pmb c^{\top} \pmb x \\\
\text { s.t. } &amp;amp; \pmb{A}\pmb x \succeq_{\mathcal {K}} \pmb{b}
\end{array}
$$
的对偶问题。
注意到，对任意的$\pmb x \succeq_{K} \pmb 0$和$\pmb y \succeq_{K^{*}} \pmb{0}$，我们有$\pmb x^{\top} \pmb y \geq 0$。我们然后便可以引入拉格朗日乘子使问题等价于
$$
\min_{\pmb x}\max_{y\in \mathcal K^*}\pmb c^{\top}\pmb x+\pmb y^{\top}(\pmb b-\pmb A\pmb x).
$$
则对偶函数为
$$
\min_{\pmb x} \pmb c^{\top}\pmb{x} + \pmb{y}^{\top}(\pmb b-\pmb A\pmb x)=
\begin{cases}
\pmb b^{\top}\pmb y, &amp;amp; \pmb A^{\top} \pmb y=\pmb c, \\\
-\infty, &amp;amp; \text{otherwise}.
\end{cases}
$$
在$\pmb y\in\mathcal K^*$中最大化对偶函数，我们可以得到对偶问题
$$
\begin{array}{cl}
\max  &amp;amp; \pmb b^{\top} \pmb y\\\
\text { s.t. } &amp;amp; \pmb{A}^{\top}\pmb{y} = \pmb c, \\\
&amp;amp; \pmb y \succeq_{\mathcal {K}^{*}} \pmb{0}.
\end{array}
$$&lt;/p&gt;
&lt;p&gt;完成了对偶问题的推导，我们需要回答强对偶在这个问题中是否成立。简单来说，我们有如下结论。对于上述锥优化的“标准型”的原问题和对偶问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对偶问题的对偶问题等价于原问题。&lt;/li&gt;
&lt;li&gt;对原问题可行的任意$\pmb x$以及对对偶问题可行的任意$\pmb y$，我们有$\pmb c^{\top} \pmb x \geq \pmb b^{\top} \pmb y$。&lt;/li&gt;
&lt;li&gt;如果原问题有下界，且对某些$\pmb x$有$\pmb{A}\pmb x - \pmb b \in \mathrm{int} \mathcal K$严格成立，那么对偶问题可解，且原问题和对偶问题最优目标函数值相等。&lt;/li&gt;
&lt;li&gt;如果原问题或对偶问题有界且严格可行（$\pmb{A}\pmb x - \pmb b \in \mathrm{int} \mathcal K$），$(\pmb{x}, \pmb{y})$是最优解与下列任意一条件等价：（i）$\pmb c^{\top} \pmb x = \pmb b^{\top} \pmb y$；或（ii）$\pmb y^{\top}(\pmb{A}\pmb x - \pmb b) = 0$。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;风险偏好及度量risk-preferences-and-risk-measures&#34;&gt;风险偏好及度量（Risk preferences and risk measures）&lt;/h2&gt;
&lt;p&gt;本节主要介绍关于风险度量的基本知识。现实中，我们来决策做一件事（比如投资）时，在未来得到的回报往往都是不确定的。为了衡量一件事未来的风险和收益，人们引入了风险度量的概念。一件事的收益可以用随机变量来表示。同时，我们令$\mathcal V$为所有随机变量构成的空间，则其风险度量（risk measure）$\mu$需要满足两个特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单调性：对于任意的$\tilde r,\tilde s\in \mathcal V$且$\tilde r \geq \tilde s$， 那么$\mu[\tilde{r}] \leq \mu[\tilde{s}]$。这里，$\tilde r \geq \tilde s$表示的是state-wise dominance。&lt;/li&gt;
&lt;li&gt;平移不变性：对于所有的$c\in \mathbb R$，$\mu [\tilde{r} + c] \leq \mu [\tilde{r}] - c$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;直观来说，单调性表示了，当一件事未来的收益在任何可能性下都高于另一件事，那么它的风险一定是较小的。同时，平移不变性意味着，当一个资产确定性地增加了一定的价值，那么它的风险就会相应减少相同的数值。&lt;/p&gt;
&lt;p&gt;基于上述定义，人们定义了非常多的风险度量。其中一个非常著名的风险度量就是在险价值（Value-at-Risk，VaR）。VaR的数学定义如下：
$$
{\rm VaR}_\epsilon[\tilde{r}] := \inf\{ m \in \mathbb{R} \mid \mathbb{P}[\tilde{r} + m \geq 0] \geq 1-\epsilon \}.
$$&lt;/p&gt;
&lt;p&gt;根据上述定义，VaR衡量了在给定概率$\epsilon$下，一份投资可能的损失。例如，一个公司每个月在$\epsilon=5%$的VaR为一亿元。这意味着公司每个月都有5%的可能性损失超过一亿元。或者说，一个一亿元的损失平均每20个月就要发生一次。根据定义，我们同时可以将VaR和表示受益的随机变量$\tilde r$的分位数联系起来。下图显示，当一个随机变量5%的分位数为$-0.0263$时，对应的VaR的数值便为$0.0263$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://allenz-me.github.io/RoSite/image/var.png&#34; alt=&#34;alt&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VaR示例（from lecture slides of Melvyn Sim）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从上图同样能看出，VaR的取值只和单独的分位点值相关。而这样的性质会带来一些不便，比如对于有VaR介入的优化问题，通常来说都很难求解。同时，VaR在某些场合不能很好反应出不同投资的风险。假设我们有两种投资策略，其收益分别如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;资产1：0.95概率收益200万，0.03概率损失100万，0.02概率损失200万;&lt;/li&gt;
&lt;li&gt;资产2：0.95概率收益200万，0.03概率损失100万，0.02概率损失1000万。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显而易见资产2的风险比资产1更大，然而上述两个投资组合的VaR都是100万。为了解决这个问题，人们又提出了条件风险价值（Conditional Value-at-Risk，CVaR）的概念。CVaR计算了超过VaR值的可能损失的期望值，也就是说对于$\tilde r\sim \mathbb{P}$，
$$
{\rm CVaR}^{*}_{\epsilon} [\tilde{r}] := \mathbb{E}_{\mathbb{P}}[-\tilde{r} \mid -\tilde{r} \geq {\rm VaR}_\epsilon(\tilde{r}) ].
$$
这里我们使用CVaR$^{*}$来表示CVaR，因为我们在后文中将推导出CVaR更常用的一个定义。为了区分，我们加上了一个星号上标。上述这个定义使得CVaR对于收益/损失的尾部分布的形状更加敏感。我们根据这个定义也可以看出${\rm CVaR}^{*}_{\epsilon}[\tilde{r}] \geq {\rm VaR}_{\epsilon}(\tilde{r})$。下图显示了CVaR和VaR的联系。我们也可以计算出在之前例子中，资产1的CVaR为140万，而资产2的CVaR为460万。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://allenz-me.github.io/RoSite/image/cvar.png&#34; alt=&#34;alt&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CVaR示例（from lecture slides of Melvyn Sim）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在我们假设一项投资其未来的收益只能取$T$个可能的值$r_1,…,r_{[T]}$。如果我们取$\epsilon$使得$\epsilon T$刚好为整数，那么CVaR可以等价地表达为
$$
{\rm CVaR}^{*}_\epsilon[\tilde{r}]  = \frac{1}{\epsilon T} \max_{\mathcal{S} : \mathcal{S} \subseteq[T],  \\\
|\mathcal{S}| = \epsilon T} \sum_{t \in \mathcal{S}} -r_t.
$$
但是这个定义并不通用，因为它不能定义当$\epsilon T$不是整数的情况。为此，我们将推导出CVaR更通用的一个定义。注意到上式可等价地推出：
$$
\begin{array}{rcl}
{\rm CVaR}^{*}_\epsilon[\tilde{r}]  &amp;amp;=&amp;amp; \displaystyle \frac{1}{\epsilon T} \max_{\mathcal{S} :\mathcal{S} \subseteq [T], \atop |\mathcal{S}| = \epsilon T} \sum_{t \in \mathcal{S}} -r_t \\\
&amp;amp;=&amp;amp;  \displaystyle  \frac{1}{\epsilon T} \max_{\pmb{z} \in \{0,1\}^T \atop \pmb z&#39;\pmb 1 = \epsilon T} \sum_{t \in [T]} -r_t z_t \\\
&amp;amp;=&amp;amp;  \displaystyle  \frac{1}{\epsilon T} \max_{\pmb{z} \in [\pmb 0,\pmb 1]\atop \pmb z&#39;\pmb 1 = \epsilon T} \sum_{t \in [T] } -r_t z_t.
\end{array}
$$
我们求出上述问题的对偶问题，得到
$$
\begin{array}{rcl}
{\rm CVaR}_\epsilon[\tilde{r}]=&amp;amp;\min &amp;amp; s + \frac{1}{\epsilon T} \pmb 1&#39;\pmb p \\\
&amp;amp;{\rm s.t.}&amp;amp; s\pmb 1 + \pmb p \geq -\pmb r, \\\
&amp;amp; &amp;amp; \pmb p \geq 0,
\end{array}
$$
即
$$
{\rm CVaR}_\epsilon [\tilde{r}] = \inf_s \{s + \frac{1}{\epsilon} \frac{1}{T}\sum_{t \in [T]}(-r_t - s)^+ \}.
$$
至此，当$\epsilon T$不为整数时，我们可以根据上述推导定义CVaR为
$$
{\mbox{CVaR}}_{\epsilon} [\tilde{r}] := \inf_v \{v + \frac{1}{\epsilon} \mathbb{E}_{\mathbb{P}}[ (-\tilde{r} - v)^+ ] \}\label{eq:cvar}\tag{CVaR}.
$$
这也是在优化领域中更常用的关于CVaR的定义。可以证明，在这个定义下依然有$\text{CVaR}_\epsilon[\tilde{r}]\geq\text{VaR}_\epsilon[\tilde{r}]$。&lt;/p&gt;
&lt;p&gt;我们接下来介绍最优化确定等价收益（Optimized Certainty Equivalent，OCE）。对于不确定的收益$\tilde r$，定义其OCE为&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9965.2007.00311.x&#34;&gt;(Ben-tal and Teboulle, 2007)&lt;/a&gt;
$$
S_u(\tilde r)=\sup_{\eta\in \mathbb{R}}\{ \eta+\mathbb{E}_{\mathbb{P}}[u(\tilde r - \eta)] \}.
$$
其中，$u: \mathbb{R}\mapsto \mathbb{R}$为非递减且凹的效用函数，并满足$u(0)=0$，且$1$是$u(r)$在$r=0$时的次梯度（subgradient）。我们可以通过公式这样解释OCE：一个决策者希望在未来有$\tilde r$的回报，而且在现在可以消费部分$\tilde r$。如果他在现在消费了确定的$\eta$的价值，那么$\tilde r$的现值就是$\eta+\mathbb{E}_{\mathbb{P}}[u(\tilde r - \eta)]$。对$\tilde r$进行在现在和未来\textit{最优}分配，我们即可得到OCE。我们可以通过OCE来定义对应的风险度量。根据&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9965.2007.00311.x&#34;&gt;Ben-tal and Teboulle, 2007&lt;/a&gt;，$\mu^{\textbf{OCE}}[\tilde{r}]=-S_u(\tilde r)$是一个一致性风险度量（coherent risk measure）。为了把问题放进凸优化框架，我们记$v=-\eta$，$U(x)=-u(-x)$。此时$U:\mathbb R \mapsto \mathbb R$可以看做一个非递减的凸效用函数，而对应的风险度量表示为
$$
\mu^{\textbf{OCE}}[\tilde{r}] = \inf_{v \in \mathbb{R}}\{v + \mathbb{E}_{\mathbb{P}}[U(-\tilde{r} -v)] \}.
$$
对比式$\eqref{eq:cvar}$，我们可以看出CVaR是一种特殊的OCE度量，满足$U(r)=r^+/\epsilon$。&lt;/p&gt;
&lt;p&gt;在鲁棒优化领域，未来收益$\tilde r$的分布$\mathbb P$往往是不确定的。
如果假设分布$\mathbb P$处于一个模糊集（Ambiguity set）$\mathcal F$中，那么我们就可以写出在最坏情境（worst case）下对应的风险度量。以OCE举例，它在最坏情况下的风险度量写作
$$
\mu^{\textbf{OCE}}[\tilde{r}] = \inf_{v \in \mathbb{R}}\{v + \sup_{\mathbb{P} \in \mathcal{F}}\mathbb{E}_{\mathbb{P}}[U(-\tilde{r} -v)] \}.
$$
这样决策优化问题就变成了一个分布鲁棒优化问题。关于分布鲁棒优化问题的求解，具体可以参见第$\ref{chapter:DRO}$章。&lt;/p&gt;
&lt;p&gt;我们最后介绍凸风险度量（convex risk measure）。对于一个风险度量$\mu$，它是凸风险度量当且仅当对于任意的$\tilde{r},\tilde{s} \in \mathcal{V}$，有
$$
\mu(\lambda \tilde{r} + (1-\lambda)\tilde{s} ) \leq \lambda \mu(\tilde{r}) + (1-\lambda)\mu(\tilde{s}).
$$
值得一提的是，OCE（包括CVaR）都是凸风险度量。而且，CVaR是所有凸风险度量中对VaR有最紧上界的一个，即如果$\mu[\tilde{r}] \geq {\rm VaR}_\epsilon[\tilde{r}]$，$\forall \tilde{r} \in \mathcal{V}$，那么有$\mu[\tilde{r}] \geq {\rm CVaR}_\epsilon[\tilde{r}] \geq  {\rm VaR}_\epsilon[\tilde{r}]$，$\forall \tilde{r} \in \mathcal{V}$。
另一个著名的凸风险度量是shortfall risk measure &lt;a href=&#34;https://link.springer.com/article/10.1007/s007800200072&#34;&gt;(Follmer and Schied 2002)&lt;/a&gt; 。由于篇幅所限不在此展开。有关于风险度量系统的知识，感兴趣的读者可以参阅&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9965.00068&#34;&gt;Artzner et al., 1999&lt;/a&gt;和&lt;a href=&#34;https://link.springer.com/article/10.1007/s007800200072&#34;&gt;Follmer and Schied 2002&lt;/a&gt;。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>经典鲁棒优化（Classical robust optimization）</title>
      <link>https://allenz-me.github.io/RoSite/post/3.%E7%BB%8F%E5%85%B8%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96/</link>
      <pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/3.%E7%BB%8F%E5%85%B8%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96/</guid>
      
        <description>&lt;p&gt;苏向阳&lt;/p&gt;
&lt;h2 id=&#34;不确定性最优化optimization-under-uncertainty&#34;&gt;不确定性最优化（Optimization under uncertainty）&lt;/h2&gt;
&lt;h4 id=&#34;不确定优化方法&#34;&gt;不确定优化方法&lt;/h4&gt;
&lt;p&gt;在实际生活中不确定性广泛存在，为了更加合理的对不确定问题进行准确描述，不确定优化逐渐被学界重视。最早在20世纪50年代Bellman、Zadeh和Charnes等人便开始对不确定性优化进行了研究&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.1.73&#34;&gt;(Chames and Cooper 1959)&lt;/a&gt;。
在对不确定优化问题的描述之前，我们先来看一下传统的确定性优化问题：
$$
\begin{align}
\min &amp;amp; f(\pmb x) \label{equation::detopt}\\\
\text {s.t.} &amp;amp; h(\pmb x) \leq 0 \notag
\end{align}
$$
其中，$\pmb{x}$是决策向量，$f(\pmb{x})$为目标函数，$h(\pmb{x})$为约束条件。在$\eqref{equation::detopt}$中，无论是约束条件还是目标函数，其对应的参数都是确定的。然而，在实际问题求解中，模型中一些参数我们很难事先确定。对于一些特定的优化问题而言，一个参数的不同就可能导致原本所求得的最优解变得毫无意义&lt;a href=&#34;https://dl.acm.org/doi/10.1137/S1052623496305717&#34;&gt;(El-Ghaoui et al. 1998)&lt;/a&gt;。为了解决这类问题，不确定性问题的优化求解就变得十分重要。&lt;/p&gt;
&lt;p&gt;随着社会的不断发展，我们所需要求解模型的复杂度不断上升，模型的不确定性也在不断扩大，诸如飞机航班的线路规划、电网的最优调度、物流路径的最优规划等等。在实际生活中，造成模型不确定的根源主要来自以下几个方面：&lt;/p&gt;
&lt;p&gt;1）	数据统计和采集过程造成的数据丢失、数据偏差过大而产生的影响。&lt;/p&gt;
&lt;p&gt;2）	天气等不可抗力因素的干扰，对问题的分析产生的影响。&lt;/p&gt;
&lt;p&gt;3）	认知不全导致现有模型与实际生活中存在偏差产生的影响。&lt;/p&gt;
&lt;p&gt;4）	对于一些难以求解的非凸非线性模型，进行简化描述而产生的影响。&lt;/p&gt;
&lt;p&gt;为了更好地对不确定优化问题进行描述，我们首先给出不确定性优化数学模型的一般表达：
$$
\begin{align}
\min &amp;amp; f(\pmb{x}, \tilde{\pmb \xi}) \label{equation::uncertain opt}\\\
\text{s.t } &amp;amp; h(\pmb{x}, \tilde{\pmb \xi}) \leq 0, \forall \tilde{\pmb \xi} \in \mathcal{U} \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;在$\eqref{equation::uncertain opt}$中，$\tilde{\pmb \xi}$为不确定参数，$\mathcal{U}$表示不确定参数的集合。为了求解模型$\eqref{equation::uncertain opt}$，以Bellman等人的工作为开端，相关学者提出了一系列的求解优化方法，诸如：随机规划&lt;a href=&#34;https://link.springer.com/book/10.1007/978-1-4614-0237-4&#34;&gt;(Berge and Louveaux 2011)&lt;/a&gt;、鲁棒优化&lt;a href=&#34;https://www2.isye.gatech.edu/~nemirovs/FullBookDec11.pdf&#34;&gt;(Ben-tal et al. 2009)&lt;/a&gt;、灵敏度分析&lt;a href=&#34;https://www2.isye.gatech.edu/~nemirovs/FullBookDec11.pdf&#34;&gt;(Ben-tal et al. 2009)&lt;/a&gt;、模糊规划&lt;a href=&#34;https://books.google.com.sg/books/about/%E9%9A%8F%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E6%A8%A1%E7%B3%8A%E8%A7%84%E5%88%92.html?id=iCLSUwn0GkQC&amp;amp;redir_esc=y&#34;&gt;(刘和赵1998)&lt;/a&gt;等等。不确定性优化的理论和方法不断地被开发出来。不确定优化的理论也依据分析阶段的不同被分为事前分析方法和事后分析方法两大类。接下来我们主要对这两大类的不确定理论展开叙述。&lt;/p&gt;
&lt;h4 id=&#34;事前分析方法&#34;&gt;事前分析方法&lt;/h4&gt;
&lt;p&gt;1）	模糊规划(Fuzzy Programming)&lt;/p&gt;
&lt;p&gt;当$\mathcal{U}$是一个模糊逻辑集合时，模型$\eqref{equation::uncertain opt}$成为了处理软约束\footnote{指约束条件中，等式或不等式两边含有模糊集合，因而不能像精确数学里一样判定等式成立或者不成立。}规划问题的求解模型，即模糊规划。这类规划是为了应对由于实际生活中，有时无法提供准确的决策的情况下而产生的一类规划求解理论。对于模糊规划问题的详细求解步骤，可以参照文献&lt;a href=&#34;https://books.google.com.sg/books/about/%E9%9A%8F%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E6%A8%A1%E7%B3%8A%E8%A7%84%E5%88%92.html?id=iCLSUwn0GkQC&amp;amp;redir_esc=y&#34;&gt;(刘和赵1998)&lt;/a&gt;。在模糊规划中，需要依据决策者的个人经验来获取不确定参数的模糊隶属函数，往往存在较大的主观性，在实际中运用的刚才在也需要经过多次调整，存在诸多限制。&lt;/p&gt;
&lt;p&gt;2）	随机规划(Stochastic Optimization)&lt;/p&gt;
&lt;p&gt;当$\mathcal{U}$是一个随机不确定集合时，上述模型成为了处理随机性数据的规划求解问题，即随机规划。随机规划根据不同的决策规则，可以分为三类：&lt;/p&gt;
&lt;p&gt;1.期望模型。首先确定不确定参数的分布模型，然后通过选取离散或连续的概率分布函数对不确定参数进行描述，最终通过期望来代替不确定参数，使不确定问题转化为确定性问题并求解。如果目标函数和约束中存在随机参数，只需要将各随机参数转化为期望值，便可以将模型转化为确定性模型进而求解。&lt;/p&gt;
&lt;p&gt;2.机会约束规划模型。通俗来讲，机会约束规划模型是指允许决策不满足约束条件，但是决策满足约束条件的概率不低于事先设定的置信水平的规划求解模型。该模型的是指在一定概率下达到最优的理论。该模型需要事先给定置信水平。模型描述如下：
$$
\begin{align}
\min &amp;amp; f(\pmb{x}) \label{equation::chance opt}\\\
\text {s.t.} &amp;amp; \mathbb{P}[\pmb{h}(\pmb{x}, \tilde{\pmb \xi}) \leq 0)] \geq \alpha \notag
\end{align}
$$
3.相关机会约束规划模型&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S089812219700237X&#34;&gt;(Liu 1997)&lt;/a&gt;。相关机会约束规划是当决策者面临多个事件时，希望最大化满足这些事件的概率而产生的一种规划方法。无论是期望模型还是机会约束规划模型，最终都是确定性优化求解并得出准确值。相关机会规划虽然求解结果是确定的，但并不代表一定实现，规划的目的是极大化该事件的实现概率。&lt;/p&gt;
&lt;h4 id=&#34;事后分析方法&#34;&gt;事后分析方法&lt;/h4&gt;
&lt;p&gt;灵敏度分析（Sensitivity Analysis）是最典型的事后分析方法。灵敏度分析根据需求的不同也被划分为局部灵敏度分析(Local sensitivity analysis)和全局灵敏度分析(Global sensitivity analysis)。这里以模型$\eqref{equation::LP model}$为例对灵敏度分析展开一个简短的描述：&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
Z = \min &amp;amp; \pmb{c}^\prime\pmb{x} \label{equation::LP model}\\\
\text {s.t} &amp;amp;\pmb{A x} = \pmb{b} \notag \\\
&amp;amp; \pmb{x} \geq \mathrm{0} \notag
\end{align}
$$
由于灵敏度分析应对的是不确定优化问题，因此有时会遇到需要添加新约束的情况。这种情况下，如果最优解满足新添加的约束，则原模型的最优解仍是新模型的最优解，若不满新添加的约束，则需要重新计算。但更多的研究内容是数据变化对最优解产生的影响。即：$\pmb A$、$\pmb c$和$\pmb b$变化导致模型最优值$Z$发生的改变。灵敏度分析研究热点问题是，当参数在什么范围内进行波动时，模型的最优解$\pmb{x}^{*}$不会发生改变，具体的原理涉及到了基变量、非基变量、对偶单纯性等相关知识，这里不再详细描述，如果有兴趣的读者可以参考&lt;a href=&#34;https://www.worldcat.org/title/zui-you-hua-li-lun-yu-suan-fa/oclc/62721683&#34;&gt;陈宝林 2005&lt;/a&gt;。灵敏度分析方法虽然相对其他不确定优化方法而言比较简单，但灵敏度分析方法仅是一个评价分析工具，大大限制了该方法的使用领域。&lt;/p&gt;
&lt;h4 id=&#34;鲁棒优化robust-optimization&#34;&gt;鲁棒优化（Robust Optimization）&lt;/h4&gt;
&lt;p&gt;鲁棒优化也是一类事前分析方法，之所以单独列出来，是因为鲁棒优化是针对传统优化方法不足，由鲁棒控制理论发展而来替代随机规划和灵敏度分析的方法。在$\eqref{equation::uncertain opt}$中，如果$\mathcal{U}$是一个有界闭集，上述模型成为了处理不确定集合内所有不确定参数的优化问题，即鲁棒优化。相对于传统不确定优化方法，鲁棒优化有如下优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;鲁棒优化在建模过程中充分考虑了不确定性，并以集合的形式对变量进行描述。相对于随机规划和模糊规划，鲁棒优化不需要不确定参数的分布模型和不确定参数的模糊隶属函数。&lt;/li&gt;
&lt;li&gt;鲁棒优化的约束条件是严格成立的，即只要不确定参数$\tilde{\pmb \xi}$属于不确定集合$\mathcal{U}$，所求出的解都能满足约束条件。即优化模型具有较强的鲁棒性，最优解对参数变化的敏感性低。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鲁棒优化虽然有着随机规划和模糊规划没有的优势，但是鲁棒优化模型本身是一个半无限优化问题，很难直接进行求解，鲁棒优化的计算结果受限于不确定集$\mathcal{U}$的不同。我们会在3.2小节和3.3小节分别对鲁棒优化中的不确定集$\mathcal{U}$和鲁棒优化对等式及转换理论进行阐述。&lt;/p&gt;
&lt;h3 id=&#34;鲁棒优化理论的发展&#34;&gt;鲁棒优化理论的发展&lt;/h3&gt;
&lt;p&gt;1973年，Soyster首次用鲁棒优化的思想来解决线性规划中的不确定性&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.21.5.1154&#34;&gt;(Soyster 1973)&lt;/a&gt;。虽然该方法基于最坏情况的基础上进行考虑，结果过于保守。但是Soyster为不确定优化的发展开拓了全新的思路，开辟了鲁棒优化发展的道路。&lt;/p&gt;
&lt;p&gt;Mulvey等人在1995年首次提出鲁棒优化的概念&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.43.2.264&#34;&gt;(Mulvey et al. 1995)&lt;/a&gt;。他们给出了基于情景集鲁棒优化的一般模型框架，提出了解鲁棒（Solution robust）和模型鲁棒（Model robust）的概念，通过将目标函数拆分为聚合函数与罚函数来消除不确定参数对结果的影响。在此之后，不断有学者投入到鲁棒优化的研究中，在这方面的奠基之作是在20世纪90年代由以色列学者&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/moor.23.4.769&#34;&gt;Ben-tal and Nemirovski 1998&lt;/a&gt; &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0167637799000164&#34;&gt;Ben-tal and Nemirovski 1999&lt;/a&gt;和美国伯克利大学的&lt;a href=&#34;https://people.eecs.berkeley.edu/~elghaoui/Pubs/rob-ls.pdf&#34;&gt;El-Ghaoui and Lebret 1997&lt;/a&gt;提出。Ben-Tal证明了如果不确定集合$\mathcal{U}$是一个椭球不确定集（后面具体介绍），那么对于一些最重要的一般凸优化问题(线性规划、二次约束规划、半定规划等)，其鲁棒对等式要么是精确的，要么近似是一个可处理的问题，可以采用诸如内点法的算法在多项式时间内求解。除此之外，Ben-Tal给出了一般不确定半定规划问题的计算可处理的近似鲁棒对等式。在此之后，Ben-Tal等人又提出了可调鲁棒优化概念等概念，并被广泛运用到各行各业中。&lt;/p&gt;
&lt;p&gt;21世纪初，&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;(Bertsimas and Sim 2004)&lt;/a&gt;在Soyster、Ben-Tal和Nemirovski的研究基础上提出了全新的鲁棒优化框架。Bertsimas和Sim的鲁棒优化涵盖了离散优化，最主要的特点是所建立的鲁棒对等式不增加问题求解的复杂度。另一方面，Bertsimas和Sim的鲁棒优化允许出现约束违背(Constraint Violation)的情况，在这种情况下得到的鲁棒解大概率具有可行性。Bertsimas和Sim的理论由于其易处理性及实用性，受到了学界的广泛认可。&lt;/p&gt;
&lt;h2 id=&#34;鲁棒优化研究路线&#34;&gt;鲁棒优化研究路线&lt;/h2&gt;
&lt;p&gt;鲁棒优化自提出以来便受到广泛关注，也不断地被各个领域的学者应用到各行各业中，对于鲁棒优化问题的求解思路也是大同小异。具体如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://allenz-me.github.io/RoSite/image/123.png&#34; alt=&#34;alt&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;鲁棒优化研究路线&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在前面我们已经提到，当模型$\eqref{equation::uncertain opt}$中的不确定集合为闭集合时，$\eqref{equation::uncertain opt}$可以视为一个鲁棒优化模型。此时，目标函数和约束条件中均含有不确定参数，为了更通俗地描述，我们对$\eqref{equation::uncertain opt}$做一些变形：&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\min &amp;amp; F  \label{Ro transform}\\\
\text {s.t. }&amp;amp; f(\pmb{x}, \tilde{\pmb \xi}) \leq F &amp;amp;&amp;amp; \forall \tilde{\pmb \xi} \in U \notag \\\
&amp;amp;\pmb{h}(\pmb{x}, \tilde{\pmb \xi}) \leq 0 &amp;amp;&amp;amp; \forall \tilde{\pmb \xi} \in U \notag
\end{align}
$$
转换后可以明显看出(应注意转换是否等价，具体参照第二章)，无论原鲁棒优化模型的目标函数是线性还是非线性，是否含不确定参数，都可以由$\eqref{Ro transform}$表示。但是模型$\eqref{Ro transform}$通常很难直接求解，为了方便求解我们需要通过数学优化理论将模型$\eqref{Ro transform}$转换为一个多项式时间内可以求解的凸优化问题，即&lt;strong&gt;鲁棒对等问题&lt;/strong&gt;(Robust Counterpart)。&lt;/p&gt;
&lt;p&gt;目前，鲁棒优化的研究方向主要体现在不确定集合的选取及鲁棒对等转换理论上：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;不确定集合的选取。如何选取合适的不确定集合对不确定参数进行准确的描述，直接影响了模型的优化结果，而且不同的不确定集合所对应的鲁棒对等问题也不同。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;鲁棒对等转换理论。如何把已经构建好的鲁棒优化模型转化成一个可以在多项式时间内求解的模型，直接影响了优化时间和优化结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;不确定集uncertainty-set&#34;&gt;不确定集（Uncertainty set）&lt;/h2&gt;
&lt;p&gt;鲁棒优化中，不同的不确定集合对结果影响十分明显，当不确定集合越精细模型复杂度越高，求解越困难。当不确定集合越宽泛时，所求出的最优解越保守，越不经济。为了权衡二者的关系，如果选择一个适合的不确定集合一直是相关学者的一个研究热点。常见的不确定集合主要有如下几类:&lt;/p&gt;
&lt;p&gt;1.盒式不确定集合（Box Uncertainty Set）&lt;/p&gt;
&lt;p&gt;$$
U_{\infty}=\{\tilde{\pmb \xi} :|\tilde{\pmb \xi}|_{\infty} \leq \tau\}=\{\tilde{\pmb \xi} :\left|\tilde{\pmb \xi}_{i}\right| \leq \tau\}
$$&lt;/p&gt;
&lt;p&gt;盒式不确定集合是最简单的不确定集合，也被称作区间集。由于鲁棒优化是考虑极端情况下的优化求解方法，对于一些模型可能会出现所有不确定参数都在区间集上下界进行优化的情况，然而实际中该情况发生的概率极低或不会发生，很出现过度保守的情况。&lt;/p&gt;
&lt;p&gt;2.椭球不确定集（Ellipsoidal Uncertainty Set）&lt;a href=&#34;https://www2.isye.gatech.edu/~nemirovs/FullBookDec11.pdf&#34;&gt;(Ben-tal et al. 2009&lt;/a&gt;, &lt;a href=&#34;https://web.stanford.edu/~boyd/cvxbook/&#34;&gt;Boyd and Vandenberghe)&lt;/a&gt;：椭球集/椭球交集
$$
\begin{align}
U_{2}=\{\tilde{\pmb \xi} :|\tilde{\pmb \xi}|_{2} \leq \Omega\}=\{\tilde{\pmb \xi} : \sum \tilde{\xi}_{i}^{2} \leq \Omega^{2}\} \label{uncertainty set ellipsoid}
\end{align}
$$
$$
\begin{align}
U_{2}&amp;amp;=\{\tilde{\pmb \xi} :(\tilde{\pmb \xi}-\overline{\pmb{u}})^{T} R^{-1}(\tilde{\pmb \xi}-\overline{\pmb{u}}) \leq \Omega^{2}\} \label{uncertainty set ellipsoid 1}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;在Ben-tal的经典著作《Robust Optimization》称式$\eqref{uncertainty set ellipsoid}$为椭球不确定集合，式(3.8)为椭球交集不确定集合。在Boyd的经典著作《convex optimization》中称$\eqref{uncertainty set ellipsoid 1}$为椭球集，$\eqref{uncertainty set ellipsoid}$为退化的椭球。为了方便描述，本文以Ben-tal的描述为准。上述公式中，$\tilde{\pmb \xi}$ 为不确定参数向量，$\overline{\pmb{u}}$为不确定参数的期望或预测值向量，$R$为协方差矩阵，$\Omega$为不确定度，用以刻画不确定参数扰动范围。相对于椭球集，椭球交集能更准确地对不确定参数进行描述，但是椭球交集在求解二次优化问题、锥二次优化、半定规划问题时难以直接求解，Ben-tal已经证明了这些优化问题中使用椭球交集时是NP-hard问题。如果采用椭球集，在线性规划、二次优化问题和锥二次优化时可以转化为可处理问题，但是在半定规划中，仍需满足诸多限制才能求解。椭球不确定集虽然可以很好地表示很多类型集合，方便数据输入，在一定程度上可以体现不确定参数之间的关联性。但是椭球不确定集会增加问题求解的复杂度，因此应用不够广泛。&lt;/p&gt;
&lt;p&gt;3.多面体不确定集（Polyhedral Uncertainty Set）&lt;/p&gt;
&lt;p&gt;$$
U_{1}=\{\tilde{\pmb \xi} :|\tilde{\pmb \xi}|_{1} \leq \Gamma,|\tilde{\pmb \xi}| \leq e\}=\{\tilde{\pmb \xi} : \sum\left| \tilde{\xi}_{i}\right| \leq \Gamma,|\tilde{\pmb \xi}| \leq e\}
$$
多面体集合&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/educ.1063.0022&#34;&gt;(Bertsimas and Thiele 2006)&lt;/a&gt;可以看作是椭球集合的一种特殊表现形式&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0167637799000164&#34;&gt;(Ben-tal and Nemirovski 1999)&lt;/a&gt;。尽管多面体不确定集难以刻画不确定参数间的相关性，但其具有线性结构、易于控制不确定度，在实际工程问题中广受青睐&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/educ.1063.0022&#34;&gt;(Bertsimas and Thiele 2006)&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;4.基数/预算不确定集（Budget uncertainty Set）&lt;/p&gt;
&lt;p&gt;$$
U_{1}=\{\tilde{\pmb \xi} : \sum \left| \frac{\xi_i-\widehat{\xi_i}}{\overline{\xi_i}-\underline{\xi_i}} \right| \leq \Gamma,| \pmb{\xi} | \leq e\}
$$
式中，$\overline{\xi_{i}}，\underline{\xi_{i}}$分别表示不确定参数的上下界，$\widehat{\xi_{i}}$表示$\xi_{i}$的预测值。最先提出这种不确定集合的是&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;，由于这种不确定集合是基于不确定参数偏移量的相对值进行构建的，能够对更精确描述参数的波动情况，因此也被称为基数不确定集&lt;a href=&#34;http://www.optimization-online.org/DB_FILE/2010/10/2769.pdf&#34;&gt;(Jiang et al. 2010&lt;/a&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/7944676&#34;&gt;Baringo and Baringo 2017&lt;/a&gt; &lt;a href=&#34;https://www.jstor.org/stable/23070141&#34;&gt;Bertsimas et al. 2010)&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;5.数据驱动不确定集（Data-driven Uncertainty Set）&lt;/p&gt;
&lt;p&gt;无论是采用盒式还是椭球式不确定集合，都会出现所得到的解过于保守的情况，为了解决解的过度保守，一些学者根据历史数据进行不确定集合的构造，也被称为数据驱动不确定集合。数据驱动不确定集合的构建，是使用统计假设检验的置信区间来精确描述不确定参数 的分布 。在04年Bertsimas、Sim和09年Ben-Tal等人的研究中，假定不确定参数为 ，其分布 不能精确获得。最初始的研究是基于数据结构特性做出的先验假设。这些方法假设 是没有依赖的，但是不会认为 的边界分布是确定的。在13年Bertsimas对数据驱动不确定集合的构造进行了进一步的改进。Bertsimas假设数据S有独立分布，这些S可以为不确定参数的分布 添加更多的细节。并且通过这些细节信息，设计一个概率保证的集合，相对于传统的集合，新的集合更小，所求出的结果也不是那么的精确。关于数据驱动的先验假设和假设检验可以参照&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-017-1125-8&#34;&gt;Bertsimas et al. 2018&lt;/a&gt;的研究。&lt;/p&gt;
&lt;p&gt;除去以上常见的不确定集合，一些学者为了适应不同的情况以及更精确地对不确定参数进行描述，还衍生出了很多种组合不确定集合，具体如：盒式+椭球式不确定集、盒式+多面体不确定集、盒式+椭球式+多面体不确定集等等。&lt;/p&gt;
&lt;h2 id=&#34;对等式转换理论robust-counterpart&#34;&gt;对等式转换理论（Robust counterpart）&lt;/h2&gt;
&lt;p&gt;前文我们已经提到，鲁棒优化是一个半无限优化问题，通常情况下很难直接求解。为了对鲁棒优化问题进行求解，我们需要对原模型做出一定程度的转化，转化后模型需要在多项式时间内可以求解。在这方面做出重要突破的学者有Soyster、Ben-tal、Bertsimas和Sim等。Soyster提出用线性优化模型求解问题，并使用凸集内所有数据，但该方法存在过于保守的弊端。Ben-tal和Nemirovski、Bertsimas和Sim在Soyster的基础上进行了改进，使得鲁棒优化适用性更广。接下来我们分别对这些理论进行描述。&lt;/p&gt;
&lt;p&gt;1.Soyster的鲁棒对等模型&lt;/p&gt;
&lt;p&gt;尽管Soyster的线性优化模型前文已经提到，但是这里为了方便描述，再次给出Soyster考虑的线性优化问题：
$$
\begin{align}
\max &amp;amp;\pmb{c^\prime} \pmb{x} \label{Soyster}\\\
\text {s.t.} &amp;amp;\pmb{A x} \leq \pmb{b} \notag\\\
&amp;amp;\pmb{l} \leq \pmb{x} \leq \pmb{u}\notag
\end{align}
$$
Soyster假设不确定参数只出现在矩阵A中，且不确定性对矩阵A中各列元素互不影响。令$\xi_{i j}=\left(\tilde{a}_{i j}-a_{i j}\right) / \hat{a}_{i j}$为[-1,1]对称分布的随机变量，其中$\tilde{a}_{i j} \in\left[\pmb{a}_{i j}-\hat{a}_{i j}, a_{i j}+\hat{a}_{i j}\right]$为随机变量，$\hat{\pmb{a}}_{i j}$为波动范围，其鲁棒对等式如下：
$$
\begin{align}
\max  &amp;amp;\pmb{c^\top} \pmb{x}&amp;amp; \label{Soyester counterpart}\\\
\text {s.t.} &amp;amp;\sum_{j} a_{ij} x_{j}+\sum_{j \in J} \tilde{a}_{ij} y_{j} \leq b_{i} &amp;amp; \forall i \notag\\\
&amp;amp;\pmb{1} \leq \pmb{x} \leq \pmb{u} &amp;amp;\notag\\\
&amp;amp;-y_{j} \leq x_{j} \leq y_{j} &amp;amp; \forall j \notag\\\
&amp;amp;\pmb{y} \geq 0&amp;amp; \notag
\end{align}
$$
公式$\eqref{Soyester counterpart}$的详细推导如下：&lt;/p&gt;
&lt;p&gt;对比公式$\eqref{Soyster}$和公式$\eqref{Soyester counterpart}$，主要区别在于第一条约束，推导如下：&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\sum_{j} \tilde{a}_{i j} x_{j} &amp;amp;=\sum_{j: x_{j} \geq 0}\left(a_{i j}+\hat{a}_{i j}\right) x_{j}+\sum_{j: x_{j}&amp;lt;0}\left(a_{i j}-\hat{a}_{i j}\right) x_{j} \notag\\\
&amp;amp;=\sum_{j} a_{i j} x_{j}+\sum_{j: x_{j} \geq 0} \hat{a}_{i j} x_{j}-\sum_{j: x_{j}&amp;lt;0} \hat{a}_{i j} x_{j} \notag\\\
&amp;amp;=\sum_{j} a_{i j} x_{j}+\sum_{j} a_{i j}\left|x_{j}\right| \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;令$y=|x|$即可由公式$\eqref{Soyster}$推导至公式$\eqref{Soyester counterpart}$。
$J$表示不确定参数所在的列。假设最优解为$\pmb{x^{*}}$，则&lt;br&gt;
$$
\sum_{j} \tilde{a}_{i j} x_{j}^{*}=\sum_{j} a_{i j} x_{j}^{*}+\sum_{j} \xi_{i j} \hat{a}_{i j} x_{j}^{*} \leq \sum_{j} a_{i j} x_{j}+\sum_{j} \tilde{a}_{i j} y_{j} \leq b_{j}
$$
由上式我们可以看出，$\sum_{j} \tilde{\pmb{a}}_{i j} x_{j}^{*}$和$\pmb{b}$之间存在明显间隙，这样的处理，会使得当求解极大化问题时，目标函数过小。求解极小化问题时，目标函数过大，求解结果过于保守。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Ben-tal和Nemirovski鲁棒对等模型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于模型$\eqref{Soyster}$，Ben-tal和Nemirovski提出了不同的求解思路，鲁棒对应模型如下：
$$
\begin{align}
\max &amp;amp;\quad\pmb{c^\prime} \pmb{x} \label{BenNemirovski}\\\
\text {s.t.} &amp;amp;\quad\sum_{j} a_{i j} x_{j}+\sum_{j \in J} \tilde{a}_{ij} y_{j}+\Omega_{i} \sqrt{\sum_{j \in J}\left(\hat{a}_{i j}^{2} x_{j}^{2}\right)} \leq b_{i} \forall i \notag\\\
&amp;amp;\quad{\pmb{1} \leq \pmb{x} \leq \pmb{u}} \notag \\\
&amp;amp;\quad{-y_{j} \leq x_{j} \leq y_{j}} \forall j \notag\\\
&amp;amp;\quad{\pmb{y} \geq 0} \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;因为随机变量对称分布，所以Ben-tal和Nemirovski采用随机变量的期望和方差来进行替换相关约束问题。$\eqref{BenNemirovski}$中$\Omega$大于0，需要事先给定。我们可以明显看出，模型$\eqref{Soyester counterpart}$的可行解是模型$\eqref{BenNemirovski}$可行解的子集。因此，Ben-tal和Nemirovski的方法保守度更低一点，同时可以通过对$\Omega$的调整来改变问题的保守度。但是模型$\eqref{BenNemirovski}$不再是线性规划，模型求解困难度上升，这也是Ben-tal和Nemirovski鲁棒优化的不足之处。&lt;/p&gt;
&lt;p&gt;Ben-tal和Nemirovski的方法虽然能降低模型的保守程度，但是并不能求解离散优化，针对这一痛点，Bertsimas和Sim提出了一种全新的鲁棒架构&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Bertsimas和Sim鲁棒对等模型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Bertsimas和Sim通过引入参数$\Gamma_{i}$来调节模型的保守程度，$\Gamma_{i} \in\left[0,\left|J_{i} |, \quad\right| J_{i} |\right.$表示第i行共有多少列元素是不确定，假设不确定元素个数不超过$\left\lfloor\Gamma_{i}\right\rfloor$个，其中$\left\lfloor\Gamma_{i}\right\rfloor$是大于等于$\Gamma_{i}$的最小整数，并$a_{i j}$的波动范围是$\left(\Gamma_{i}-\left\lfloor\Gamma_{i} |\right) \hat{\pmb{a}}_{i j}\right.$，如果模型满足以上要求，那么模型一定可以求解。即使超 过$\left\lfloor\Gamma_{i}\right\rfloor$个不确定元素，也有很高的概率得到鲁棒解。&lt;/p&gt;
&lt;p&gt;Bertsimas和Sim的模型如下：
$$
\begin{align}
\max &amp;amp; \pmb{c^\top} \pmb{x}  \label{BertSim}\\\
\text {s.t. }
&amp;amp;\sum_{j} a_{ij} x_{j} +
\underset{
\{
S_{i} \cup \{ t_{i} \} \mid S_{i} \subseteq J_{i}, \left| S_{i} \right| = \left\lfloor \Gamma_{i} \right\rfloor, t_{i} \in J_{i} \backslash S_{i}
\}
} {\mathop{\max}}
\left\{
\sum_{j\in S_{i}} \hat{a}_{ij}{y_j} +
\left(
\Gamma_i -\left\lfloor \Gamma_i \right\rfloor&lt;br&gt;
\right)
a_{it_i}y_{t_{i}}
\right\}
\leq b_{i} \quad \forall i \notag \\\
&amp;amp;\pmb{1} \leq \pmb{x} \leq \pmb{u} \notag \\\
&amp;amp;-y_{j} \leq x_{j} \leq y_{j}\quad \forall j \notag\\\
&amp;amp;\pmb{y} \geq 0  \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;当$\Gamma_{i}$为整数时，此时$\Gamma_{i}=\left|\Gamma_{i}\right|$，对第i个约束，有如下形式:&lt;/p&gt;
&lt;p&gt;$$
\sum_{j} a_{ij} x_{j} + \underset{
\{ S_{i} \cup \{ t_{i} \} \mid S_{i} \subseteq J_{i}, \left| S_{i} \right| = \left\lfloor \Gamma_{i} \right\rfloor, t_{i}\in J_{i} \backslash S_{i} \}
}{\mathop{\max}}
\left\{ \sum_{j\in S_{i}}{\hat{a}_{ij} y_j} \right\}\leq b_{i}
$$&lt;/p&gt;
&lt;p&gt;当$\Gamma_{i}$的值为0时，变量的系数均为标称值，约束变为名义问题（nominal problem）。当$\Gamma_{i}$取最大值$\left\lfloor\Gamma_{i}\right\rfloor$时，此时所有的不确定元素均不为标称值，模型等价于Soyster模型。当$\Gamma_{i}$的值介于最大值和最小值之间变动时，模型的保守度也相应变动。当$\Gamma_{i}$的值为$\Omega_{i} \sqrt{\sum_{j \in J}\left(\hat{a}_{i j}^{2} x_{j}^{2}\right)}$时，约束违背（具体参考&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;）的概率边界值与Ben-tal一致。因此，当$\Gamma_{i}$的值过小时，鲁棒优化模型保守性差，较大概率发生约束违背。当$\Gamma_{i}$的值过大时，计算结果过于保守。
模型$\eqref{BertSim}$是非线性模型，不能直接求解，Bertsimas和Sim对模型做出了如下转化：
$$
\begin{align}
\max &amp;amp;\quad\pmb{c^\prime} \pmb{x} \label{LP Bertsim}\\\
\text {s.t.} &amp;amp;\sum_{j} a_{i j} x_{j} + z_{i} \Gamma_{i}+\sum_{j \in J_{i}} p_{i j} \leq b_{i} &amp;amp;&amp;amp; \forall i \notag\\\
&amp;amp;{z_{i}+p_{i j} \geq \hat{a}_{i j} y_{j}} &amp;amp;&amp;amp; \forall i, j \in J_{i} \notag\\\
&amp;amp;{\pmb{1} \leq \pmb{x} \leq \pmb{u}}\notag\\\
&amp;amp;{-y_{j} \leq x_{j} \leq y_{j}} &amp;amp;&amp;amp; \forall j \notag\\\
&amp;amp;{\pmb{y} \geq 0} \notag\\\
&amp;amp;{p_{i j} \geq 0} &amp;amp;&amp;amp; \forall i, j \in J_{i} \notag\\\
&amp;amp;{z_{i} \geq 0} &amp;amp;&amp;amp; \forall i \notag
\end{align}
$$
模型转化的理论依据是对偶理论，具体的证明过程在作者稿件中有详细描述，有兴趣的读者可以自行翻阅，这里不再赘述。
在此基础上，Bertsimas和Sim提出了鲁棒离散优化的模型&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;。
模型$\eqref{Soyster}$的鲁棒对等模型如下所示：
$$
\begin{align}
\max &amp;amp;\quad\pmb{c^\prime} \pmb{x} + \mathop {\max }\limits_{\{ {\left. S_0 \right|S_0 \subseteq J_0,\left| S_0 \right| \leq \Gamma_0} \}} \{ {\sum\limits_{j \in S_0} {d_j\left| x_j \right|} } \} \label{Bertsimas and Sim counterpart}\\\
\text {s.t.} &amp;amp;\sum\limits_{j} a_{i j}x_j+\mathop {\max }\limits_{\{ {\left. {S_i \cup \{ t_i \}} \right|S_i \subseteq J_i,\left| S_i \right| = \left\lfloor \Gamma_i \right\rfloor ,t_i \in J_i\backslash S_i} \}}
\{ {\sum\limits_{j \in S_i} {\hat{a}_{i j}\left| x_j \right| + \left( {\Gamma_i - \left\lfloor {\Gamma_i} \right\rfloor } \right){\hat{a}_{i{t_i}}}\left| x_{t_i} \right|}} \}\le b_{i}&amp;amp;&amp;amp;\forall i \notag\\\
&amp;amp;{\pmb{1} \leq \pmb{x} \leq \pmb{u}} \notag \\\
&amp;amp;{-y_{j} \leq x_{j} \leq y_{j}} &amp;amp;&amp;amp; \forall j \notag\\\
&amp;amp;{\pmb{y} \geq 0}\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;其中，$\Gamma_{0}$是区间$\left[0, | J_{0} |\right.$内的整数，$J_{0}=\{j | d_{j}&amp;gt;0\}$ $\left|J_{0}\right|$，是$\pmb{c}$中不确定元素的个数。Bertsimas和Sim考虑了目标函数的不确定性，所以有了$\eqref{Bertsimas and Sim counterpart}$中目标函数的表达形式。对于目标函数中的$\pmb{c}$，允许变化的不确定元素有$\Gamma_{0}$个，取值为$\mathop {\pmb{c^\top}}\limits_{j \in S_0}  + \mathop {\max }\limits_{\{ {\left. S_0 \right|S_0 \subseteq J_0,\left| S_0 \right| \leq {\Gamma _0}} \}} \sum\limits_{j \in S_0} d_j $，其余均为标称值。&lt;/p&gt;
&lt;p&gt;同样的，模型$\eqref{Bertsimas and Sim counterpart}$也需要经过处理才能求解，处理后的混合整数规划模型如下所示：
$$
\begin{align}
\max &amp;amp;\quad\pmb{c^\prime} \pmb{x} + z_{0} \Gamma_{0}+\sum_{j \in J_{0}} p_{0j} \notag\\\
\text {s.t.} &amp;amp;\sum_{j} a_{i j} x_{j}+z_{i} \Gamma_{i}+\sum_{j \in J_i} p_{i j} \leq b_{i} &amp;amp;&amp;amp; \forall i \notag\\\
&amp;amp;{z_{0}+p_{0j} \geq d_{j} \pmb{y}_{j}} &amp;amp;&amp;amp; \forall i, j \in J_{0}\notag\\\
&amp;amp;{z_{i}+p_{ij} \geq \hat{a}_{ij} \pmb{y}_{j} \quad {\forall i \neq 0, j \in J_{i}}} \notag\\\
&amp;amp;{\pmb{1} \leq \pmb{x} \leq \pmb{u}}\notag\\\
&amp;amp;{-y_{j} \leq x_{j} \leq y_{j}} &amp;amp;&amp;amp; \forall j \notag\\\
&amp;amp;{\pmb{y} \geq 0} \notag\\\
&amp;amp;{p_{i j} \geq 0} &amp;amp;&amp;amp; \forall i, j \in J_{i} \notag\\\
&amp;amp;{z_{i} \geq 0} &amp;amp;&amp;amp; \forall i \notag\\\
&amp;amp;{x_{i} \in Z} &amp;amp;&amp;amp; \forall i=1, \ldots, k \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;我们以&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;中的仿真算例进行说明：
$$
\begin{align}
\max &amp;amp;\sum_{i=1}^{n}p_{i}x_{i}-\phi  \sum_{i=1}^{n}\sigma_{i}^{2}x_{i}^{2}\label{example}\\\
\text {s.t.}&amp;amp;\sum_{i=1}^{n}x_{i}=1\notag\\\
&amp;amp; x_{i}\geq 0 \notag
\end{align}
$$
其中，$\sigma_{i}$为$i$类股票回报的标准差，$\phi$是控制风险和回报之间交易的一个参数。
其中，$p_{i}=1.15+i \frac{0.05}{150}, \quad \sigma_{i}=\frac{0.05}{450} \sqrt{2 i n(n+1)}$ 。&lt;/p&gt;
&lt;p&gt;这个模型考虑了$n=150$支股票。对第$i$支股票，回报率的期望是$p_i$，标准差是$\sigma_i$。我们用$x_i$定义决策变量代表每支股票的投资比例，并用参数$\phi=5$来平衡投资的回报期望和风险。对于模型$\eqref{example}$，为了便于理解我们可以写为以下形式：
$$
\begin{align}
\max \min_{z \in U} &amp;amp;\sum_{i=1}^{n}\left(p_{i}-\sigma_{i} z_{i}\right) x_{i} \label{example robust}\\\
\text{ s.t. } &amp;amp;\sum_{i=1}^{n} x_{i}=1 \notag\\\
&amp;amp;x_{i} \geq 0 \notag
\end{align}
$$
其中，$z=\phi \sigma x$， $\sigma_{i} z_{i}$可以理解为$p_i$的偏移量，即模型$\eqref{BertSim}$中的$\hat{\mathbf{a}}_{ij}$。因此，模型$\eqref{example robust}$类似模型$\eqref{equation::uncertain opt}$，套用Bertsimas和Sim鲁棒对等模型$\eqref{BertSim}$可得到：
$$
\begin{align}
\max &amp;amp;\quad z \label{example robust 1}\\\
\text {s.t.} &amp;amp; z \leq \sum_{i=1}^{n}p_{i}x_{i}+\underset{\{ \left. S_{i}\cup \{ t_{i} \} \right|{S_{i}}\subseteq J_{i},\left| S_{i} \right|=\left\lfloor \Gamma_{i} \right\rfloor ,t_{i}\in J_{i}\backslash S_{i} \}}{\mathop{\max}},\{ \sum\limits_{j\in S_{i}}{\sigma_{j} x_{j}+\left(\Gamma_{i}-\left\lfloor \Gamma_{i} \right\rfloor  \right)\sigma_{i} x_{t_{i}}} \} \notag\\\
&amp;amp;\sum_{i=1}^{n}x_{i}=1 \notag\\\
&amp;amp; x_{i}\geq 0 \notag
\end{align}
$$
模型$\eqref{example robust 1}$依据模型$\eqref{LP Bertsim}$进行转换，转化后结果如下：
$$
\begin{align}
\max &amp;amp;\quad z \label{example final}\\\
\text {s.t.} &amp;amp; z \leq \sum_{i=1}^{n}p_{i}x_{i}-\left ( \sum_{i=1}^{n}Q_{i}+\Gamma_{i}m_{i}  \right ) \notag\\\
&amp;amp;Q_{i}+m_{i}\geq \sigma_{i}x_{i}\notag\\\
&amp;amp;\sum_{i=1}^{n}x_{i}=1 \notag\\\
&amp;amp;x_{i}\geq 0\notag\\\
&amp;amp;Q_{i}\geq 0\notag\\\
&amp;amp;m_{i}\geq 0\notag
\end{align}
$$
$\eqref{example final}$中的$\Gamma$对应$\eqref{example}$中$\phi$是一个事先给定的常量。我们可以看出$\eqref{example final}$是一个线性模型，可以调用cplex或gurobi来快速求解。当$\Gamma$为5时，函数最优值为1.170。
除此之外,在&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;中的&lt;strong&gt;Proposition 1&lt;/strong&gt;也提到了&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://allenz-me.github.io/RoSite/image/ro.png&#34; alt=&#34;alt&#34;&gt;&lt;/p&gt;
&lt;p&gt;等价为以下的线性优化模型：
$$
\begin{align}
\beta_{i}\left(\boldsymbol{x}^{*}, \Gamma_{i}\right)=\text { maximize } &amp;amp; \sum_{j \in J_{i}} \hat{a}_{i j}\left|x_{j}^{*}\right| z_{i j} \notag\\\
\text { subject to} &amp;amp; \sum_{j \in J_{i}} z_{i j} \leq \Gamma_{i} \notag\\\
&amp;amp; 0 \leq z_{i j} \leq 1 \quad \forall j \in J_{i} \notag
\end{align}
$$
在此之前我们已经对模型进行了改写，其实改写的模型即为具有多面体不确定集合的数学模型，模型如下：
$$
\begin{align}{rl}
\max~&amp;amp;\min\limits_{\pmb{z}\in U}\sum\limits_{i=1}^n(p_i - \sigma_i z_i)x_i  \label{example another}\\\
\text{s.t.} &amp;amp;\sum\limits_{i=1}^n x_i = 1\notag \\\
&amp;amp;x_i \geq 0, \forall i = 1, 2, &amp;hellip;, n \notag
\end{align}
$$
在该模型中，随机变量$\pmb{z}$代表实际股票回报率和期望值间的偏差。这个随机被约束在一个预算不确定集（Budget uncertainty set）$\mathcal{U}$中，其表达式如下：
$$
\begin{align}
U = \{\pmb{z}|\ 0\leq z_{i j} \leq 1,  \sum_{j \in J_{i}} z_{i j} \leq \Gamma_{i} \}\rightarrow
U =\{\pmb{z}||\pmb{z}|_{\infty}\leq 1, |\pmb{z}|_1\leq \Gamma\} \notag
\end{align}
$$
对于现有的鲁棒优化问题，已经有成熟的优化工具可以直接求解，对于模型$\eqref{example}$和$\eqref{example another}$都可以直接在rsome（matlab环境下的工具包）进行建模求解，具体内容会在第八章详细介绍。&lt;/p&gt;
&lt;p&gt;本算例的相关代码如下（Python3.6环境下调用gurobi的求解，Github地址：https://github.com/Feeling-well/robust-optimization）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;原始模型不能直接调用求解器求解，但是有如下的等价形式：
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    max  z
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;    s.t. z&amp;lt;=sum(p[i]x[i])-(sum(Q[i])+Γ[i]m[i])
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        Q[i]+m[i]&amp;gt;=σ[i]x[i]
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        Q[i]&amp;gt;=0
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        m[i]&amp;gt;=0
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        sum(x[i])=1
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;        x[i]&amp;gt;=0
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;Γ是控制风险和回报之间交易的参数，我们这里设置为5
&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;gurobipy&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;try&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RO&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;#添加常量&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;Gamma&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;151&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;450&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;151&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.15&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;Gamma&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;c1&#34;&gt;# 添加变量&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addVars&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lb&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addVar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;z&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;Q&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addVars&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Q&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;mm&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addVars&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;m&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

    &lt;span class=&#34;n&#34;&gt;px&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;QC&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
    
    &lt;span class=&#34;c1&#34;&gt;# 添加约束&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addConstrs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;px&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Γ&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;QC&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;first&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addConstrs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;second&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;addConstr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;range&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;third&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    
    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;setObjective&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GRB&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;MAXIMIZE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 设置目标函数&lt;/span&gt;


    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;write&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;RO.lp&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# 模型打印语句，可以打印成lp文件，便于查看模型是否写错&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;optimize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;# 模型求解&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;#变量输出
for v in m.getVars ():
    print (&amp;#39;%s %g&amp;#39; % (v.varName, v.x))

except GurobiError as e:
    print(&amp;#39;Error code &amp;#39; + str(e.errno) + &amp;#34;: &amp;#34; + str(e))

except AttributeError:
    print(&amp;#39;Encountered an attribute error&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
      
    </item>
    
    <item>
      <title>分布鲁棒优化（Distributionally robust optimization）</title>
      <link>https://allenz-me.github.io/RoSite/post/4.%E5%88%86%E5%B8%83%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/4.%E5%88%86%E5%B8%83%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96/</guid>
      
        <description>&lt;p&gt;章宇&lt;/p&gt;
&lt;p&gt;现实世界的&lt;strong&gt;优化问题&lt;/strong&gt;指在满足相关约束条件的前提下，确定一组决策变量的值，使预设的目标函数值最优。相关研究成果（理论、模型、算法、应用）在管理科学、金融工程、军事指挥等领域发挥着巨大指导作用，创造了巨大的社会经济价值。&lt;/p&gt;
&lt;p&gt;由于本书定位为入门级、科普级，本章将以优化问题中一类简单但重要的&lt;strong&gt;线性优化&lt;/strong&gt;（亦称&lt;strong&gt;线性规划&lt;/strong&gt;）问题为例，阐述&lt;strong&gt;分布鲁棒优化&lt;/strong&gt;的基本思想、基本模型、基本结论。感兴趣的读者需细读相关文献以获得更深入广泛的理解。&lt;/p&gt;
&lt;p&gt;线性规划问题 $\eqref{ro.mod.lo}$中，&lt;strong&gt;决策变量&lt;/strong&gt;为 $\pmb{x} \in \mathbb{R}^I$，环境&lt;strong&gt;参数&lt;/strong&gt;包括费用向量 $\pmb{a}_0 \in \mathbb{R}^I$、&lt;strong&gt;约束条件&lt;/strong&gt;左端项系数向量 $\pmb{a}_m \in \mathbb{R}^I$、右端项系数 $b_m \in \mathbb{R}$，这些参数为确定值。线性规划可用于解决许多现实问题，例如投资组合优化、生产计划、最短路等问题。
$$
\begin{align}
{\min_{\pmb{x}}} &amp;amp; \pmb{a}_0^\top\pmb{x}, &amp;amp;&amp;amp;\label{ro.mod.lo}\\\
\mbox{s.t.} &amp;amp; \pmb{a}_m^\top \pmb{x} \le b_m, &amp;amp;&amp;amp; m \in [M]. \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;现实世界中描述未来发生事件的环境参数在&lt;strong&gt;优化/规划/计划阶段&lt;/strong&gt;往往不确定，例如未来某商品需求量、两地间旅行时长、某股票回报率等。为了让优化结果对现实更具指导意义，在优化模型中考虑环境参数的不确定性至关重要。&lt;/p&gt;
&lt;p&gt;在不确定环境下，$\eqref{ro.mod.lo}$中对于某一 $m \in [M]$ 的约束式变成了
$$
\begin{align}
\pmb{a}(\tilde{\pmb \varepsilon})^\top\pmb{x} \leq b(\tilde{\pmb \varepsilon}).\label{dro.con.1}
\end{align}
$$
其中，为了阐述方便，忽略下标 $m$；随机变量 $\tilde{\pmb \varepsilon}$ 表示影响环境参数的随机因素（例如，旅行时长受天气、交通灯时长等随机因素影响），假设 $\pmb{a}(\tilde{\pmb \varepsilon})$ 和 $b(\tilde{\pmb \varepsilon})$ 皆为 $\tilde{\pmb \varepsilon}$ 的仿射函数，即
$
\pmb{a}(\tilde{\pmb \varepsilon}) := \pmb{a}^0 + \sum_{j \in [J]}\pmb{a}^j \tilde{\varepsilon}_j, b(\tilde{\pmb \varepsilon}) := b^0 + \sum_{j \in [J]}b^j \tilde{\varepsilon}_j,
$
则有
$$
\pmb{a}(\tilde{\pmb \varepsilon})^\top \pmb{x} - b(\tilde{\pmb \varepsilon})
= \underbrace{(\pmb{a}^{0})^\top\pmb{x} - b^0}_{=y^0(\pmb{x})} + \sum_{j \in [J]}\big(\underbrace{(\pmb{a}^{j})^\top\pmb{x} - b^j}_{=y^j(\pmb{x})}\big)\tilde{\varepsilon}_j = y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon}.
$$
因此，约束式 $\eqref{dro.con.1}$ 等价于
$$
\begin{align}
y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon} \le 0. \label{dro.con.2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;不确定环境下的线性规划从技术上主要关注如何处理约束式 $\eqref{dro.con.2}$。因其左端项为随机变量而右端项为实数，故通常意义上无法直接比较大小，“$\leq$” 符号用在此处不够严谨。对此，本章主要介绍两种典型处理方式，第$\eqref{dro.subsec.cc}$节基于&lt;strong&gt;分布鲁棒机会约束规划&lt;/strong&gt;思想，介绍如何处理
$$
\begin{align}
\mathbb{P} [y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon} \le 0] \ge 1 - \epsilon, \quad \forall \mathbb{P} \in \mathcal{F},\label{dro.con.cc}
\end{align}
$$
也就是约束 \eqref{dro.con.2}成立的概率不小于 $1 - \epsilon$，其中阈值 $\epsilon \in [0, 1]$ 典型取值为 1% 或 5%。第\eqref{dro.subsec.lo}节基于&lt;strong&gt;分布鲁棒线性优化&lt;/strong&gt;范式，介绍如何处理
$$
\begin{align}
\mathbb{E}_{\mathbb{P}} [y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon}] \le 0, \quad \forall \mathbb{P} \in \mathcal{F},\label{dro.con.lo}
\end{align}
$$
也就是约束 \eqref{dro.con.2} 需在其左端项通过均值来度量的情况下满足。&lt;/p&gt;
&lt;p&gt;事实上，目标函数参数不确定性亦可纳入约束讨论，因为通过引入辅助决策变量 $t \in \mathbb{R}$，\eqref{ro.mod.lo}等价于
$$
\begin{align*}
\displaystyle \min_{t, \pmb{x}} &amp;amp; t, &amp;amp;&amp;amp;\\\
\mbox{s.t.} &amp;amp; \pmb{a}_0^\top \pmb{x} \le t, &amp;amp;&amp;amp;\\\
&amp;amp;\pmb{a}_m^\top \pmb{x} \le b_m, &amp;amp;&amp;amp; m \in [M].
\end{align*}
$$
进而将目标函数中不确定参数 $\pmb{a}_0$ 置于约束中。&lt;/p&gt;
&lt;p&gt;约束式\eqref{dro.con.cc} 和 \eqref{dro.con.lo} 中，随机变量 $\tilde{\pmb \varepsilon}$ 服从联合概率分布 $\mathbb{P}$，而 $\mathbb{P}$ 本身也不确定，属于模糊集 $\mathcal{F}$；第\eqref{dro.subsec.as}节将介绍模糊集相关内容。分布鲁棒优化采取保守策略，令这两个约束条件对模糊集中所有概率分布皆满足，它也是因此得名&amp;mdash;“鲁棒”的内涵是考虑最坏情况，而“分布”表明最坏情况的主体是环境参数的分布函数。望本章内容能抛砖引玉，启发读者研究和处理更复杂的形式，并用于解决实际问题。&lt;/p&gt;
&lt;h2 id=&#34;模糊集ambiguity-set-labeldrosubsecas&#34;&gt;模糊集（Ambiguity set） \label{dro.subsec.as}&lt;/h2&gt;
&lt;p&gt;问题环境中随机参数的分布函数往往难以从现实世界直接获取。鉴于此，分布鲁棒优化方法假设其分布函数并不明确，而是处于一个&lt;strong&gt;模糊集&lt;/strong&gt; (ambiguity set) 中。模糊集通过随机变量的不完全分布信息构建而成。特别地，它还需保证相应分布鲁棒优化模型在计算上&lt;strong&gt;可处理&lt;/strong&gt;(tractable)，也就是现实规模问题可在允许时间范围内求解。&lt;/p&gt;
&lt;p&gt;从数学上说，分布鲁棒优化囊括&lt;strong&gt;随机规划&lt;/strong&gt;(stochastic programming) 和&lt;strong&gt;传统鲁棒优化&lt;/strong&gt;(robust optimization)为特殊形式，因此分布鲁棒优化更具一般性。当环境变量 $\tilde{\pmb \varepsilon}$ 的分布函数 $\mathbb{P}_0$ 可获知时，可令模糊集为单元素集 $\mathcal{F}_S:= \{\mathbb{P}_0\}$，则分布鲁棒优化退化为随机规划；当仅知环境变量的&lt;strong&gt;不确定集&lt;/strong&gt;$\Xi$ 时，可令模糊集为 $\mathcal{F}_R := \mathcal{P}_0(\Xi)$，即&lt;strong&gt;支撑集&lt;/strong&gt;为 $\Xi$ 的所有概率分布函数之集合，则分布鲁棒优化退化为传统鲁棒优化。&lt;/p&gt;
&lt;p&gt;按照描述分布函数的信息种类划分，目前相关研究主要提出了两类模糊集。&lt;/p&gt;
&lt;h2 id=&#34;基于广义矩信息generalized-moment-information的模糊集&#34;&gt;基于广义矩信息（generalized moment information）的模糊集&lt;/h2&gt;
&lt;p&gt;在统计学中，&lt;strong&gt;矩&lt;/strong&gt;(moment) 表征随机变量的分布。对于随机变量 $\tilde{\varepsilon}$，其 &lt;strong&gt;$n$ 阶矩&lt;/strong&gt;被定义为 $\mathbb{E}_{\mathbb{P}}[\tilde{\varepsilon}^n]$，$n \ge 1$。因此，随机变量一阶矩为均值，表征其&lt;strong&gt;位置&lt;/strong&gt;(location)，二阶矩与方差有关，表征其&lt;strong&gt;散度&lt;/strong&gt; (dispersion)，三阶矩表征其&lt;strong&gt;偏斜度&lt;/strong&gt;，等等。&lt;/p&gt;
&lt;p&gt;更&lt;strong&gt;广义&lt;/strong&gt;地，还可利用其它形式表征随机变量的位置、散度、偏斜度等特性。例如，&lt;strong&gt;绝对离差&lt;/strong&gt;均值  $\mathbb{E}_{\mathbb{P}}[|\tilde{\varepsilon} - \mu|]$ 可表征 $\tilde{\varepsilon}$ 的散度，其中 $\mu$ 为其均值。再如，&lt;em&gt;半绝对离差&lt;/em&gt;均值 $\mathbb{E}_{\mathbb{P}}[(\tilde{\varepsilon} - \mu)^+]$ 和 $\mathbb{E}_{\mathbb{P}}[(\mu - \tilde{\varepsilon})^+]$ 可从某种程度刻画 $\tilde{\varepsilon}$ 的偏斜度，其中 $(x)^+ := \max\{x, 0\}$。&lt;/p&gt;
&lt;p&gt;早期研究往往假设随机参数的概率分布无法准确获取，但其部分广义矩信息（和支撑集）可获取或估计，于是根据这些信息构建模糊集。例如，通过 $\tilde{\pmb \varepsilon}$ 的均值 $\pmb{\mu}$ 和&lt;strong&gt;协方差&lt;/strong&gt;矩阵 $\pmb{\Sigma}$ 构成的模糊集&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.51.4.543.16101&#34;&gt;(Ghaoui et al., 2003&lt;/a&gt;,  &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1060.0353?journalCode=opre&#34;&gt;Popescu, 2007)&lt;/a&gt; 为
$$
\begin{align}
\mathcal{F}_{MV} = \left\{
\mathbb{P} \in \mathcal{P}_0(\mathbb{R}^J)
\left|
\begin{array}{l}
\tilde{\pmb \varepsilon} \sim \mathbb{P} \\\
\mathbb{E}_\mathbb{P}[\tilde{\pmb \varepsilon}] = \pmb{\mu} \\\
\mathbb{E}_\mathbb{P}[(\tilde{\pmb \varepsilon} -\pmb{\mu}) (\tilde{\pmb \varepsilon} - \pmb{\mu})&#39;] = \pmb{\Sigma} \\\
\end{array}
\right.
\right\}.\label{eq.dro.as.mv}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;如果进一步考虑&lt;strong&gt;支撑集&lt;/strong&gt;$\Xi$，则模糊集为 $\mathcal{F}_{MVS} = \mathcal{F}_{MV} \mathcal{A}p \mathcal{P}_0(\Xi)$.
但研究表明，基于 $\mathcal{F}_{MVS}$ 的分布鲁棒优化模型一般不可处理 &lt;a href=&#34;https://epubs.siam.org/doi/abs/10.1137/S1052623401399903?journalCode=sjope8&#34;&gt;(Bertsimas and Popescu, 2005&lt;/a&gt;, &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1110.0918&#34;&gt;Natarajan, Teo, and Zheng, 2011)&lt;/a&gt;。而如果给定的 $\pmb{\Sigma}$ 不是准确协方差而是协方差的上界时，则模糊集为
$$
\begin{align}
\mathcal{F}_{M} = \left\{
\mathbb{P} \in \mathcal{P}_0(\Xi)
\left|
\begin{array}{l}
\tilde{\pmb \varepsilon} \sim \mathbb{P}\\\
\mathbb{E}_\mathbb{P}[\tilde{\pmb \varepsilon}] = \pmb{\mu}  \\\
\mathbb{E}_\mathbb{P}[(\tilde{\pmb \varepsilon} -\pmb{\mu}) (\tilde{\pmb \varepsilon} - \pmb{\mu})&#39;] \preceq \pmb{\Sigma}
\end{array}
\right.
\right\}, \label{eq.dro.as.moment}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;其中 “$\preceq$”为半正定锥空间意义上的小于等于，也就是 $\pmb{X} \preceq \pmb{Y}$ 意味着 $\pmb{Y} - \pmb{X}$ 为半正定矩阵。有趣的是，基于 $\mathcal{F}_{M}$ 的分布鲁棒线性优化模型却可处理 &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre&#34;&gt;(Wiesemann, Kuhn and Sim, 2010&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0896-z&#34;&gt;Hanasusanto et al., 2015) &lt;/a&gt;。
&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0741&#34;&gt;Delage and Ye, 2014&lt;/a&gt;研究了 $\mathcal{F}_{M}$ 的一个变种
$$
\begin{align}
\mathcal{F}_{DY} = \left\{
\mathbb{P} \in \mathcal{P}_0(\Xi)
\left|
\begin{array}{l}
\tilde{\pmb \varepsilon} \sim \mathbb{P}  \\\
(\mathbb{E}_{\mathbb{P}}[\tilde{\pmb \varepsilon}] - \pmb{\mu})^\top \pmb{\Sigma}^{-1} (\mathbb{E}_{\mathbb{P}}[\tilde{\pmb \varepsilon}] - \pmb{\mu}) \le \gamma_1 \\\
\mathbb{E}_\mathbb{P}[(\tilde{\pmb \varepsilon} -\pmb{\mu}) (\tilde{\pmb \varepsilon} - \pmb{\mu})&#39;] \preceq \gamma_2 \pmb{\Sigma}
\end{array}
\right.
\right\}, \label{eq.dro.as.moment.dy}
\end{align}
$$
其中第一个约束指 $\tilde{\pmb \varepsilon}$ 的均值处于一个以 $\pmb{\mu}$ 为球心的椭球中，$\gamma_1 \ge 0$ 和 $\gamma_2 \ge 1$ 为两个参数。从数据驱动的视角看，假设 $\tilde{\pmb \varepsilon}$ 客观上服从概率分布 $\mathbb{P}_0$，但无法观测该分布，而仅能观测其 $N$ 组样本/历史数据/观测值 $(\hat{\pmb{\varepsilon}}_\omega)_{\omega \in [N]}$，令
$$
\pmb{\mu} := \frac{1}{N}\sum_{\omega \in [N]} \hat{\pmb{\varepsilon}}_\omega, \qquad \pmb{\Sigma} := \frac{1}{N} \sum_{\omega \in [N]} (\hat{\pmb{\varepsilon}}_\omega - \pmb{\mu}) (\hat{\pmb{\varepsilon}}_\omega - \pmb{\mu})^\top,
$$
且 $\gamma_1$ 和 $\gamma_2$ 通过与样本量 $N$ 和参数 $\delta &amp;gt; 0$ 有关的某函数给定时（随着 $N \rightarrow \infty$，有 $\gamma_1 \rightarrow 0$ 和 $\gamma_2 \rightarrow 1$），则 &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0741&#34;&gt;Delage and Ye, 2010&lt;/a&gt;证明了在统计学上 $\mathbb{P}_0 \in \mathcal{F}_{DY}$ 的置信度大于等于 $1 - \delta$。&lt;/p&gt;
&lt;p&gt;并非任意基于广义矩信息（和支撑集）的模糊集都能保证相应分布鲁棒优化模型可处理。Wisemann，Kuhn 和 Sim 提出了一种具有一般性的模糊集表达形式，能囊括 $\mathcal{F}_M$ 和 $\mathcal{F}_{DY}$ 为其特殊形式，能建模许多其它的广义矩信息，如绝对离差、半方差、高阶矩等，且（在一些技术性假设条件下）对于分布鲁棒线性优化在计算上可处理  &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre&#34;&gt;(Wiesemann, Kuhn and Sim, 2014&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0896-z&#34;&gt;Hanasusanto et al., 2015 &lt;/a&gt;,
&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0741&#34;&gt;Delage and Ye, 2010)&lt;/a&gt;。其形式为
$$
\begin{align}
\mathcal{F}_{WKS} = \left\{
\mathbb{P} \in \mathcal{P}_0(\mathbb{R}^J \times \mathbb{R}^L)
\left|
\begin{array}{l}
(\tilde{\pmb \varepsilon}, \tilde{\pmb u}) \sim \mathbb{P}  \\\
\mathbb{E}_\mathbb{P}[\pmb{A}\tilde{\pmb \varepsilon} + \pmb{B} \tilde{\pmb u}] = \pmb{b} \\\
\mathbb{P}[(\tilde{\pmb \varepsilon}, \tilde{\pmb u}) \in \Xi_k] \in [\underline{p}_k, \overline{p}_k], \forall k \in [K]
\end{array}
\right.
\right\},\label{eq.dro.as.wks}
\end{align}
$$
其中 $\mathbb{P}$ 为 $\tilde{\pmb \varepsilon}$ 和辅助随机变量 $\tilde{\pmb u}$ 的联合概率分布，$\pmb{A} \in \mathbb{R}^{J \times Q}$，$\pmb{B} \in \mathbb{R}^{L \times Q}$，$\pmb{b} \in \mathbb{R}^Q$；置信集合 $\Xi_k$ 给定为
$$
\begin{align}
\Xi_k = \{
(\pmb{\varepsilon}, \pmb{u}) \in \mathbb{R}^J \times \mathbb{R}^L |
\pmb{C}_k \pmb{\varepsilon} + \pmb{D}_k \pmb{u} \preceq_{\mathcal{K}_k} \pmb{c}_k
\}, \label{eq.support.set}
\end{align}
$$
其中 $\pmb{C}_k \in \mathbb{R}^{J \times R}$，$\pmb{D}_k \in \mathbb{R}^{L \times R}$，$\pmb{c} \in \mathbb{R}^R$，而 $\mathcal{K}_k$ 代表某一真锥 (proper cone)，如非负象限、二阶锥、半正定锥等。在此，“$\preceq_{\mathcal{K}_k}$”是在该锥空间意义上的小于等于；关于锥和相应的锥规划 (conic programming) 问题相关介绍，可参见  &lt;a href=&#34;https://epubs.siam.org/doi/book/10.1137/1.9780898718829&#34;&gt;Ben-Tal and Nemirovski, 2001&lt;/a&gt;。对于表示概率界的 $\underline{\pmb{p}},\overline{\pmb{p}} \in [0, 1]^K$，有 $\underline{\pmb{p}} \le \overline{\pmb{p}}$。&lt;/p&gt;
&lt;p&gt;模糊集 $\mathcal{F}_{WKS}$ 巧妙之处在于引入了辅助随机变量 $\tilde{\pmb u}$，这为计算上的可处理性提供了一种有效途径，如下例所示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;
&lt;strong&gt;示例&lt;/strong&gt; 通过 $\tilde{\pmb \varepsilon}$ 的均值 $\pmb{\mu}$ 、绝对离差均值上界 $\pmb{\sigma}$、半绝对离差均值上界 $\pmb{h}$ 及满足 \eqref{eq.support.set} 形式的支撑集 $\Xi$ 构成的模糊集为
$$
\begin{align}
\mathcal{F}_{MAD} = \left\{
\mathbb{P} \in \mathcal{P}_0(\Xi)
\left|
\begin{array}{l}
\tilde{\pmb \varepsilon} \sim \mathbb{P} \\\
\mathbb{E}_\mathbb{P}[\tilde{\pmb \varepsilon}] = \pmb{\mu} \\\
\mathbb{E}_\mathbb{P}[|\tilde{\pmb \varepsilon} -\pmb{\mu}|] \le \pmb{\sigma} \\\
\mathbb{E}_\mathbb{P}[(\tilde{\pmb \varepsilon} -\pmb{\mu})^+] \le \pmb{h}
\end{array}
\right.
\right\},\label{eq.dro.as.mad}
\end{align}
$$
其中 $|\tilde{\pmb \varepsilon}|$ 代表对向量 $\tilde{\pmb \varepsilon}$ 的每个元素分别取绝对值构成的向量，取正符 $(\tilde{\pmb \varepsilon})^+$ 亦然。目前虽无法&lt;strong&gt;直接&lt;/strong&gt;处理基于 $\mathcal{F}_{MAD}$ 的分布鲁棒优化模型，但如引入辅助变量，$\mathcal{F}_{MAD}$ 则变成
$$
\begin{align}
\mathcal{F}_{MADL} = \left\{
\mathbb{P} \in \mathcal{P}_0(\bar{\Xi})
\left|
\begin{array}{l}
(\tilde{\pmb \varepsilon}, \tilde{\pmb u}, \tilde{\pmb v}) \sim \mathbb{P} \\\
\mathbb{E}_\mathbb{P}[\tilde{\pmb \varepsilon}] = \pmb{\mu} \\\
\mathbb{E}_\mathbb{P}[\tilde{\pmb u}] = \pmb{\sigma} \\\
\mathbb{E}_\mathbb{P}[\tilde{\pmb v}] = \pmb{h}
\end{array}
\right.
\right\},\label{eq.dro.as.ma}
\end{align}
$$
其中，扩展的支撑集为
$$
\bar{\Xi} = \{(\pmb{\varepsilon}, \pmb{u}, \pmb{v}) | \pmb{\varepsilon} \in \Xi,  \pmb{u} \ge \pmb{\varepsilon} -\pmb{\mu}, \pmb{u} \ge \pmb{\mu} - \pmb{\varepsilon}, \pmb{v} \ge \pmb{\varepsilon} - \pmb{\mu}, \pmb{v} \ge \pmb{0}\}.
$$
在此，$\mathcal{F}_{MADL}$ 即为 $\mathcal{F}_{WKS}$ 的一个特例，因此变得可处理；对于具体处理方法，可参见  &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre&#34;&gt;Wiesemann, Kuhn and Sim, 2014&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0896-z&#34;&gt;Hanasusanto et al., 2015 &lt;/a&gt;。类似地，前文提到的 $\mathcal{F}_{DY}$ 和 $\mathcal{F}_{M}$ 以及文献中更多有趣的形式&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952&#34;&gt;(例如：Bertsimas, Sim, and Zhang, 2019）&lt;/a&gt;也可借助辅助变量化为 $\mathcal{F}_{WKS}$ 的形式。&lt;/p&gt;
&lt;h3 id=&#34;基于统计距离-statistical-distance-的模糊集&#34;&gt;基于统计距离 (statistical distance) 的模糊集&lt;/h3&gt;
&lt;p&gt;在大数据时代背景下，问题环境中随机参数的历史数据越来越容易获取。为了获得随机参数概率分布，一种自然的想法是通过历史数据对应的经验分布来近似描述真实概率分布。&lt;strong&gt;经验分布&lt;/strong&gt;是建立在 $N$ 条历史数据点上的离散均匀分布，它视每一条历史数据 $\hat{\pmb{\varepsilon}}_\omega$ 为随机变量的一个支撑点，出现概率为$1/N$，即
$$
\hat{\mathbb{P}}[\tilde{\pmb \varepsilon}^\dagger = \hat{\pmb{\varepsilon}}_\omega] = \frac{1}{N}, \forall \omega \in [N].
$$
其中 $\tilde{\pmb \varepsilon}^\dagger$ 表示 $\tilde{\pmb \varepsilon}$ 对应的经验随机变量。&lt;/p&gt;
&lt;p&gt;但经验分布并不等同于真正概率分布，分布鲁棒优化的思想是假设真正概率分布与经验分布在概率空间中的*统计距离}不超过某一阈值，并以此构建模糊集。
基于此思想，如何定义两个概率分布间的统计距离成为了关键，它不仅需要具有良好的统计学意义，而且需要保证相应的分布鲁棒优化模型可处理。在此例举两种典型形式。&lt;/p&gt;
&lt;p&gt;第一是基于$\phi$-散度 ($\phi$-divergence) 的模糊集，定义为
$$
\begin{align}
\mathcal{F}_{\phi} = \left\{
\mathbb{P} \in \mathcal{P}_0(\mathbb{R}^J)
\left|
\begin{array}{l}
\tilde{\pmb \varepsilon} \sim \mathbb{P}, \tilde{\pmb \varepsilon}^\dagger \sim \hat{\mathbb{P}}, \\\
D_\phi(\mathbb{P}||\hat{\mathbb{P}}) \le \theta
\end{array}
\right.
\right\}, \label{eq.dro.as.pd}
\end{align}
$$
其中 $D_\phi(\mathbb{P}||\hat{\mathbb{P}})$ 表示所认为的真正分布 $\mathbb{P}$ 对于经验分布 $\hat{\mathbb{P}}$ 的 &lt;strong&gt;$\phi$-散度&lt;/strong&gt;（“距离”），定义如 $eqref{eq.phi.d}$而 $\theta &amp;gt; 0$ 为给定的“距离”上界。
$$
\begin{align}
D_\phi(\mathbb{P}||\hat{\mathbb{P}}) = \sum_{\omega \in [N]} \hat{\mathbb{P}}(\omega) \phi \left(\frac{\mathbb{P}(\omega)}{\hat{\mathbb{P}}(\omega)}\right) \label{eq.phi.d}
\end{align}
$$
在 \eqref{eq.phi.d} 中，$\phi:\mathbb{R}_+ \mapsto \mathbb{R}$ 为满足以下条件的凸函数：$\phi(1) = 0$，对于 $x &amp;gt; 0$ 有 $0\phi(x/0):= x \lim_{t \rightarrow +\infty} \phi(t) / t$，且 $0\phi(0 / 0):= 0$；$\mathbb{P}(\omega)$ 表示概率分布 $\mathbb{P}$ 中第 $\omega \in [N]$ 个观测值发生的概率。可见，该模糊集要求真正的概率分布函数支撑集与经验分布支撑集相同，也就无法考量到历史数据以外的点/场景，而仅仅是将历史数据发生的概率从经验分布的各 $1/N$ 变成了更具“鲁棒性”的值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;
&lt;strong&gt;示例&lt;/strong&gt; 在此例举一种研究相对较多的 $\phi$ 函数形式：当 $\phi(x) = x \log x - x + 1$ 时，$\phi$散度具体化为 \eqref{eq.kl}名为 &lt;strong&gt;Kullback-Leibler 散度&lt;/strong&gt; (KL divergence)，又名&lt;strong&gt;相对熵&lt;/strong&gt; (relative entropy)。
$$
\begin{align}
D_{KL}(\mathbb{P}||\hat{\mathbb{P}}) = \sum_{\omega \in [N]} \mathbb{P}(\omega) \log \left(\frac{\mathbb{P}(\omega)}{\hat{\mathbb{P}}(\omega)}\right) \label{eq.kl}
\end{align}
$$
为后文阐述方便，将其模糊集记为 $\mathcal{F}_{KL}$，也就是 \eqref{eq.dro.as.pd} 中的将 $D_\phi$ 具体化为 $D_{KL}$。对于更多的 $\phi$ 函数形式，可参见 &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.1120.1641&#34;&gt;Ben-tal et al., 2013&lt;/a&gt;,&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0929-7&#34;&gt;Jiang and Guan, 2016&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;第二是基于 Wasserstein 距离的模糊集，定义为
$$
\begin{align}
\mathcal{F}_W = \left\{ \mathbb{P} \in \mathcal{P}_0(\Xi)
\left|
\begin{array}{l}
\displaystyle \tilde{\pmb \varepsilon} \sim \mathbb{P}, \tilde{\pmb \varepsilon}^\dagger \sim \hat{\mathbb{P}},  \\\
\displaystyle d_W(\mathbb{P}, \hat{\mathbb{P}}) \le \theta,
\end{array}\right.
\right\}. \label{eq.dro.wasserstein}
\end{align}
$$
此模糊集囊括了概率空间中以 Wasserstein 距离为度量标准，以经验分布 $\hat{\mathbb{P}}$ 为球心，以 $\theta \in \mathbb{R}_+$ 为半径的球中所有的概率分布。\cite{esfahani2018data} 的研究表明，记真实但未知的概率分布为 $\mathbb{P}_0$，则当 $\theta$ 通过与样本量 $N$ 和参数 $\beta \in (0,1)$ 有关的某函数取值时（随着 $N \rightarrow \infty$，有 $\theta \rightarrow 0$），从统计学上可证明 $\mathbb{P} \in \mathcal{F}_W$ 的置信度大于等于 $1 - \beta$。Wasserstein 距离$d_W:\mathcal{P}_0(\Xi) \times \mathcal{P}_0(\Xi) \mapsto [0, +\infty)$ 表示所考虑的分布与经验分布在概率空间中的一种距离，定义为
$$
\begin{align}
d_W(\mathbb{P}, \hat{\mathbb{P}})  = \inf &amp;amp; \displaystyle \mathbb{E}_{\bar{\mathbb{P}}} \big[\lVert \tilde{\pmb \varepsilon} - \tilde{\pmb \varepsilon}^\dagger \rVert \big] \label{mod.wasserstein.definition} \\\
\mbox{s.t.}	&amp;amp; \displaystyle \big(\tilde{\pmb \varepsilon}, \tilde{\pmb \varepsilon}^\dagger\big) \sim \bar{\mathbb{P}}, \notag\\\
&amp;amp; \displaystyle \tilde{\pmb \varepsilon} \sim \mathbb{P},
\tilde{\pmb \varepsilon}^\dagger \sim \hat{\mathbb{P}}, \notag\\\
&amp;amp; \displaystyle \bar{\mathbb{P}}\big[ (\tilde{\pmb \varepsilon}, \tilde{\pmb \varepsilon}^\dagger) \in \Xi \times \Xi \big] = 1,\notag
\end{align}
$$
其中的 $\bar{\mathbb{P}}$ 表示 $\tilde{\pmb \varepsilon}$ 和 $\tilde{\pmb \varepsilon}^\dagger$ 的&lt;strong&gt;联合概率分布&lt;/strong&gt;，$\lVert \cdot \rVert$ 表示&lt;strong&gt;范数&lt;/strong&gt;。根据定义，可直观地将 Wasserstein 距离视为从真实分布 $\mathbb{P}$ 向经验分布 $\hat{\mathbb{P}}$ 移动&lt;strong&gt;概率质量&lt;/strong&gt;(probability mass) 的最小费用。上述定义准确说是&lt;strong&gt;1型 Wasserstein 距离&lt;/strong&gt;，对于更一般的 Wasserstein 距离定义及更详细深入的介绍可参见 &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-017-1172-1&#34;&gt;Mohajerin Esfahani and Kuhn, 2018&lt;/a&gt;, &lt;a href=&#34;https://arxiv.org/abs/1604.02199&#34;&gt;Gao and Kleywegt, 2016&lt;/a&gt;,&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0167637718300506&#34;&gt;Zhao and Guan, 2018&lt;/a&gt;}。&lt;/p&gt;
&lt;h1 id=&#34;机会约束问题chance-constraint&#34;&gt;机会约束问题（Chance constraint）&lt;/h1&gt;
&lt;p&gt;\label{dro.subsec.cc}&lt;/p&gt;
&lt;p&gt;机会约束规划是指当优化问题环境参数为随机变量时，在以一定概率满足约束条件的情况下进行优化。自从&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.6.1.73&#34;&gt;Charnes and Cooper 1959&lt;/a&gt; 提出来以来，该框架在管理科学等各领域得到了广泛研究与应用。作为抛砖引玉，本节讨论如何处理分布鲁棒&lt;strong&gt;独立&lt;/strong&gt;机会约束 $\eqref{dro.con.cc}$，读者可进而自行研究更一般也更难处理的联合机会约束 \eqref{dro.con.jcc}：
$$
\begin{align}
\mathbb{P} [y_m^0(\pmb{x}) + \pmb{y}_m(\pmb{x})^\top\tilde{\pmb \varepsilon} \le 0, \forall m \in [M]] \ge 1 - \epsilon, \quad \forall \mathbb{P} \in \mathcal{F}, \label{dro.con.jcc}
\end{align}
$$
其中的 $M$ 个约束同时成立的概率不小于 $1 - \epsilon$。&lt;/p&gt;
&lt;p&gt;从计算角度看，约束式 $\eqref{dro.con.cc}$ 左端项可等价表示为
$$
\begin{align}
\mathbb{E}_\mathbb{P}\big[\textbf{1}\{y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon}\} \le 0\}\big],\label{eq.dro.cc.lhs}
\end{align}
$$
其中，$\textbf{1}\{\cdot\}$ 为&lt;strong&gt;指示函数&lt;/strong&gt;，当其事件发生取值为1，否则为0。指示函数为非凸函数，导致 \eqref{eq.dro.cc.lhs} 对 $\pmb{x}$ 或 $\tilde{\pmb \varepsilon}$ 而言皆为非凸函数，除个别特殊情况（如 $\tilde{\pmb \varepsilon}$ 服从联合正态分布）外难以处理。事实上，即便给定决策变量 $\pmb{x}$ 和概率分布 $\mathbb{P}$，计算$\eqref{dro.con.cc}$左端项的概率值一般而言已是 NP 难问题，更何况还要基于此对 $\pmb{x}$ 进行优化 &lt;a href=&#34;https://epubs.siam.org/doi/abs/10.1137/050622328?journalCode=sjope8&#34;&gt;(Nemirovski and Shapiro, 2006)&lt;/a&gt;。而有趣的是，在给定某些模糊集 $\mathcal{F}$ 的情况下，$\eqref{dro.con.cc}$却可处理。&lt;/p&gt;
&lt;p&gt;接下来讲述如何在分布鲁棒优化框架下对机会约束式 $\eqref{dro.con.cc}$ 进行处理。易知，约束式 $\eqref{dro.con.cc}$ 等价于
$$
\begin{align}
\displaystyle \inf_{\mathbb{P} \in \mathcal{F}}\mathbb{P}[y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top \tilde{\pmb \varepsilon} \le 0] \geq 1 - \epsilon. \label{eq.dro.cc1}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;当 $\eqref{eq.dro.cc1}$中模糊集取 $\mathcal{F}:= \mathcal{F}_{MV}$ 且其中的 $\pmb{\mu}:= \pmb{0}$ 时， \cite{ghaoui2003worst} 的研究表明，$\eqref{eq.dro.cc1}$等价于
$$
\begin{align}
\displaystyle y^0(\pmb{x}) + \sqrt{\frac{1 - \epsilon}{\epsilon}} \sqrt{\pmb{y}(\pmb{x})^\top\pmb{\Sigma} \pmb{y}(\pmb{x})} \le 0.\label{eq.dro.cc.mv.eq}
\end{align}
$$
这里，令 $\pmb{\mu}:= \pmb{0}$ 并不失一般性，因为如果 $\pmb{\mu} \not= \pmb{0}$ 则可通过变量替换的方法，令 $\tilde{\pmb \xi} := \tilde{\pmb \varepsilon} - \pmb{\mu}$ 并将 $\tilde{\pmb \xi}$ 视为 $\eqref{eq.dro.cc1}$ 中的 $\tilde{\pmb \varepsilon}$。
有趣的是，$\eqref{eq.dro.cc.mv.eq}$ 恰好等价于传统鲁棒优化约束式
$$
\begin{align}
\displaystyle y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top \pmb{\varepsilon} \le 0, \quad \forall \pmb{\varepsilon} \in \Xi(\epsilon), \label{eq.ro}
\end{align}
$$
其中，不确定集为椭球形，给定为
$$
\Xi(\epsilon):= \left\{\pmb{\varepsilon} \in \mathbb{R}^J \left| \lVert \pmb{\Sigma}^{1/2}\pmb{\varepsilon}\rVert_2 \le \sqrt{\frac{1-\epsilon}{\epsilon}} \right. \right\}.
$$
关于$ \eqref{eq.dro.cc.mv.eq} $与 $\eqref{eq.ro}$ 的关系，可参见&lt;a href=&#34;10.1287/opre.1080.0683&#34;&gt;Natarajan et al., 2009&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;当 \eqref{eq.dro.cc1} 中模糊集取 $\mathcal{F}:= \mathcal{F}_{MVS}$ 时，分布鲁棒机会约束规划一般不可处理。研究者们提出了基于&lt;strong&gt;条件风险值&lt;/strong&gt; (Conditional Value-at-Risk) 的近似方法进行处理，感兴趣的读者可参见 &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0712?journalCode=opre&#34;&gt;Chen et al., 2010&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-011-0494-7&#34;&gt;Zymler, Kuhn, and Rustem, 2013&lt;/a&gt;} 等。&lt;/p&gt;
&lt;p&gt;当 $\mathcal{F}:= \mathcal{F}_{WKS}$ 且其中 $K = 1, \underline{p}_1 = \overline{p}_1 = 1$ 时，&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0896-z&#34;&gt;Hanasusanto et al., 2015 &lt;/a&gt;证明了 \eqref{eq.dro.cc1} 等价于如下一系列锥优化约束：
$$
\begin{align*}
\beta + \pmb{b}^\top \pmb{\gamma} \ge (1 - \epsilon) \tau,
&amp;amp; \beta + \pmb{c}_1^\top \pmb{\phi} \le \tau,
&amp;amp; \beta + \pmb{c}_1^\top \pmb{\psi} \le -y^0(\pmb{x}), \\\
\pmb{A}^\top \pmb{\gamma} = \pmb{C}_1^\top \pmb{\phi},
&amp;amp; \pmb{B}^\top \pmb{\gamma} = \pmb{D}_1^\top \pmb{\phi}, \\\
\pmb{A}^\top \pmb{\gamma} + \pmb{y}(\pmb{x}) = \pmb{C}_1^\top \pmb{\psi},
&amp;amp; \pmb{B}^\top \pmb{\gamma} = \pmb{D}_1^\top \pmb{\psi}, \\\
\beta \in \mathbb{R}, \pmb{\gamma} \in \mathbb{R}^L, \tau \in \mathbb{R}_+,
&amp;amp;  \pmb{\phi}, \pmb{\psi} \in \mathcal{K}_1^*
\end{align*}
$$
其中 $\mathcal{K}_1^{*}$ 表示 $\mathcal{K}_1$ 的&lt;strong&gt;对偶锥&lt;/strong&gt; \citep{ben2001lectures}。考虑到 $\mathcal{F}_M$ 和 $\mathcal{F}_{DY}$ 均为 $\mathcal{F}_{WKS}$ 的特例，当 $\mathcal{F}:= \mathcal{F}_M$ (其中支撑集为 $\eqref{eq.support.set} $的形式) 或 $\mathcal{F}:= \mathcal{F}_{DY}$ 时，$\eqref{dro.con.cc}$可等价转化成锥优化约束形式。&lt;/p&gt;
&lt;p&gt;作为 &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0896-z&#34;&gt;Hanasusanto et al., 2015 &lt;/a&gt; 的扩展，&lt;a href=&#34;https://epubs.siam.org/doi/abs/10.1137/16M1094725?journalCode=sjope8&#34;&gt;Xie, 2018&lt;/a&gt; 考虑了更一般的模糊集，研究了分布鲁棒独立机会约束规划和联合机会约束规划的等价凸优化形式。对于考虑均值、散度上界、支撑集的一类模糊集，&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.2016.1583&#34;&gt;Hanasusanto et al., 2017&lt;/a&gt; 研究了其分布鲁棒联合机会约束规划的计算复杂度及求解方法。&lt;/p&gt;
&lt;p&gt;当 (\eqref{eq.dro.cc1}) 中模糊集取 $\mathcal{F}:= \mathcal{F}_{KL}$ 时，&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0929-7&#34;&gt;Jiang and Guan, 2016&lt;/a&gt;的研究表明，$\eqref{eq.dro.cc1}$ 等价于
$$
\begin{align}
\displaystyle \hat{\mathbb{P}}[y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon} \le 0] \ge 1 - \bar{\epsilon}.\label{eq.dro.cc.kl.eq}
\end{align}
$$
其中，
$$
\bar{\epsilon}:= 1 - \inf_{t \in (0, 1)} \frac{e^{-\theta}t^{1 - \epsilon} - 1}{t - 1}.
$$
由此可见，它与随机规划中基于&lt;strong&gt;采样平均近似&lt;/strong&gt; (sample average approximation) 的机会约束式 \eqref{eq.dro.cc.saa} 相比，仅仅是具有不同的概率界 $\bar{\epsilon}$ 而已。此外，对于一般的$\phi$散度形式下分布鲁棒联合机会约束规划的处理方法，可详见 &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-015-0929-7&#34;&gt;Jiang and Guan, 2016&lt;/a&gt;。
$$
\begin{align}
\displaystyle \hat{\mathbb{P}}[y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\tilde{\pmb \varepsilon} \le 0] \ge 1 - \epsilon. \label{eq.dro.cc.saa}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;作为常用技巧，$\eqref{eq.dro.cc.saa}$ 可通过引入0-1辅助决策变量的方法等价转换为
$$
\begin{align}
\displaystyle y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\hat{\pmb{\varepsilon}}_\omega\le M_0 (1 - z_\omega), &amp;amp; \forall \omega \in [N], \label{eq.dro.cc.saa.eq} \\\
\displaystyle \frac{\sum_{\omega \in [N]} z_\omega}{N} \ge 1 - \epsilon, &amp;amp;\notag\\\
\pmb{z} \in \{0, 1\}^N.\notag&amp;amp;
\end{align}
$$
其中，$M_0$ 为一个足够大的实数。观察可知，当$y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top\hat{\pmb{\varepsilon}}_\omega\le 0$ 时，$z_\omega$ 可取值 1，代表该约束在第 $\omega$ 个场景中成立，否则不得不取值 0。&lt;/p&gt;
&lt;p&gt;当 $\mathcal{F}:= \mathcal{F}_W$ 时，&lt;a href=&#34;http://www.optimization-online.org/DB_FILE/2018/06/6671.pdf&#34;&gt;Chen, Kuhn, and Wiesemann, 2018&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-019-01445-5&#34;&gt;Xie, 2019&lt;/a&gt;讨论了如何处理分布鲁棒（独立和联合）机会约束规划问题，他们用不同的方法得到了相同的结论。此时，独立机会约束 $\eqref{eq.dro.cc1}$ 等价于如下混合 0-1 锥优化约束
$$
\begin{align*}
\epsilon N t - \pmb{e}^\top \pmb{s} \ge \theta N \lVert \pmb{y}(\pmb{x}) \rVert_*, &amp;amp; \\\
-\pmb{y}(\pmb{x})^\top \hat{\pmb{\varepsilon}}_\omega - y^0(\pmb{x}) + M_0 z_\omega \ge t - s_\omega, &amp;amp; \forall \omega \in [N], \\\
M_0(1 - z_\omega) \ge t - s_\omega, &amp;amp; \forall \omega \in [N], \\\
t \in \mathbb{R}, \pmb{z} \in \{0, 1\}^N, \pmb{s} \in \mathbb{R}^{N}. &amp;amp;
\end{align*}
$$
其中 $\pmb{e}$ 代表长度为 $N$、元素全为 1 的向量，$\lVert \cdot \rVert_*$ 为 \eqref{mod.wasserstein.definition} 中 $\lVert \cdot \rVert$ 对应的&lt;strong&gt;对偶范数&lt;/strong&gt;&lt;a href=&#34;https://web.stanford.edu/~boyd/cvxbook/&#34;&gt;(Boyd and Vandenberghe)&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;分布鲁棒线性优化distributionally-robust-linear-optimization&#34;&gt;分布鲁棒线性优化（Distributionally robust linear optimization）&lt;/h2&gt;
&lt;p&gt;\label{dro.subsec.lo}&lt;/p&gt;
&lt;p&gt;现实世界中很多优化问题可建模或近似为线性规划问题。线性约束不仅本身可描述许多现实问题的资源约束，而且可建模或近似更复杂的资源约束。作为抛砖引玉，本节讨论如何处理
分布鲁棒线性优化约束式 $\eqref{dro.con.lo}$，读者可进而自行研究更一般也更难处理的非线性约束，例如：
$$
\begin{align}
\mathbb{E}_{\mathbb{P}} \big[\max_{k \in [K]} \{y_k^0(\pmb{x}) + \pmb{y}_k(\pmb{x})^\top\tilde{\pmb \varepsilon}\}\big] \le 0, \quad \forall \mathbb{P} \in \mathcal{F}, \label{dro.con.pl}
\end{align}
$$
其左端项为关于 $\pmb{x}$ 和 $\tilde{\pmb \varepsilon}$ （各自）的分段线性凸函数；此形式出现在许多管理科学问题中，如库存管理 &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1090.0746&#34;&gt;(See and Sim, 2010&lt;/a&gt;, &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2015.2391&#34;&gt;Mamani et al., 2017)&lt;/a&gt;、预约调度 &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2013.1881?journalCode=mnsc&#34;&gt;(Mak, Rong, and Zhang, 2015&lt;/a&gt;, &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.2013.1158&#34;&gt;Kong et al., 2013&lt;/a&gt;,&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2015.2353&#34;&gt;Qi, 2017)&lt;/a&gt;、带时间窗的车辆路径问题 &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-018-1243-y&#34;&gt;(Zhang et al., 2019)&lt;/a&gt;
，等等。&lt;/p&gt;
&lt;p&gt;接下来探讨如何处理分布鲁棒线性优化约束式 $\eqref{dro.con.lo}$。易知，它等价于
$$
\begin{align}
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_\mathbb{P}[y^0(\pmb{x}) + \pmb{y}(\pmb{x})^\top \tilde{\pmb \varepsilon}] \le 0. \label{dro.con.lo.eq}
\end{align}
$$
处理该约束的关键是考察左端项中优化问题
$$
\begin{align}
Z_P(\pmb{x}) = \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_\mathbb{P}[\pmb{y}(\pmb{x})^\top \tilde{\pmb \varepsilon}] \label{dro.mod}
\end{align}
$$
的对偶问题。注意，该优化问题中 $\pmb{x}$ 被视为给定参数，而概率分布 $\mathbb{P}$ 才是决策变量。抽象地，$\eqref{dro.mod}$ 的对偶问题形式为
$$
\begin{align}
Z_D(\pmb{x}) = \inf_{\pmb{p} \in \mathcal{P}(\pmb{x})} f(\pmb{p}).\label{dro.mod.dual}
\end{align}
$$
其中 $\pmb{p}$ 为对偶决策变量，$\mathcal{P}(\pmb{x})$ 为其可行域，$f(\pmb{p})$ 为目标函数，$\pmb{y}(\pmb{x})$ 作为参数被包含于 $\mathcal{P}(\pmb{x})$ 中。在某些条件下，强对偶定理对此成立，则 $Z_P = Z_D$。于是，$\eqref{dro.con.lo.eq}$ 等价于
$$
\begin{align}
y^0(\pmb{x}) + f(\pmb{p}) \le 0, \label{eq.dro.lo.eq}\\\
\pmb{p} \in \mathcal{P}(\pmb{x}).\notag
\end{align}
$$
因此，技术上主要关注如何在取不同模糊集 $\mathcal{F}$ 的情况下求解 (\eqref{dro.mod}) 的对偶问题并证明强对偶定理成立。&lt;/p&gt;
&lt;p&gt;当 $\mathcal{F}:= \mathcal{F}_{MV}$ 或 $\mathcal{F}:= \mathcal{F}_{MVS}$ 时，由于已知 $\tilde{\pmb \varepsilon}$ 的均值 $\pmb{\mu}$，故 \eqref{dro.mod} 等价于 $Z_P(\pmb{x}) = \pmb{y}(\pmb{x})^\top \pmb{\mu}$。\cite{popescu2007robust} 针对 $\mathcal{F}:= \mathcal{F}_{MV}$ 且 $\eqref{dro.mod}$ 目标函数变为某一类非线性函数的情形，研究了其等价模型与求解方法。&lt;/p&gt;
&lt;p&gt;当 \eqref{dro.mod} 中 $\mathcal{F}:= \mathcal{F}_{DY}$ 时，则在某些技术性条件下， &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0741&#34;&gt;Delage and Ye, 2010&lt;/a&gt;推导出其对偶问题 $\eqref{dro.mod.dual}$ 的具体形式：
$$
\begin{align}
\displaystyle Z_D(\pmb{x}) = \min_{\pmb{Q}, \pmb{q}, r, t} &amp;amp; r + t &amp;amp;&amp;amp;\label{dro.mod.dy.dual}\\\
\mbox{s.t.} &amp;amp; r \ge \pmb{y}(\pmb{x})^\top \pmb{\varepsilon} - \pmb{\varepsilon}^\top \pmb{Q} \pmb{\varepsilon} - \pmb{\varepsilon}^\top \pmb{q}, &amp;amp;&amp;amp; \forall \pmb{\varepsilon} \in \Xi, \notag\\\
&amp;amp; t \ge (\gamma_2 \pmb{\Sigma} + \pmb{\mu} \pmb{\mu}^\top) \bullet \pmb{Q} + \pmb{\mu}^\top \pmb{q} + \sqrt{\gamma_1} \lVert \pmb{\Sigma}^{1/2} (\pmb{q} + 2 \pmb{Q} \pmb{\mu}) \rVert, &amp;amp;&amp;amp; \notag \\\
&amp;amp; \pmb{Q} \succeq \pmb{0},&amp;amp;&amp;amp; \notag
\end{align}
$$
其中 &lt;em&gt;$\bullet$&lt;/em&gt; 表示矩阵间的弗罗贝尼乌斯内积。注意到 (\eqref{dro.mod.dy.dual}) 中的第一个约束实则为（传统）鲁棒优化约束，因此求解 $\mathcal{F}_{DY}$ 模糊集下的分布鲁棒优化问题 $\eqref{dro.mod}$ 等价于求解鲁棒优化问题 $\eqref{dro.mod.dy.dual}$，而上一章已讲述如何求解鲁棒优化问题。&lt;/p&gt;
&lt;p&gt;当 $\eqref{dro.mod}$中 $\mathcal{F}:= \mathcal{F}_{WKS}$ 时，则在某些技术性条件下，&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre&#34;&gt;Wiesemann, Kuhn and Sim, 2014&lt;/a&gt;推导出其对偶问题 $\eqref{dro.mod.dual}$ 的具体形式：
$$
\begin{align}
\displaystyle Z_D(\pmb{x}) = \min_{\pmb{\beta}, \pmb{\eta}, \pmb{\lambda}, \pmb{\phi}} &amp;amp; \displaystyle \pmb{b}^\top \pmb{\beta} + \sum_{k \in [K]} \overline{\pmb{p}}_k \pmb{\eta}_k - \underline{\pmb{p}}_k \pmb{\lambda}_k &amp;amp;&amp;amp;\label{dro.mod.wks.dual}\\\
\mbox{s.t.} &amp;amp; \displaystyle \pmb{c}_k^\top \pmb{\phi}_k \le \sum_{k&#39; \in \mathcal{A}(k)} (\pmb{\eta}_{k&#39;} - \pmb{\lambda}_{k&#39;}), &amp;amp;&amp;amp; \forall k \in [K], \notag\\\
&amp;amp; \pmb{C}_k^\top \pmb{\phi}_k + \pmb{A}^\top \pmb{\beta} = \pmb{y}(\pmb{x}), &amp;amp;&amp;amp; \forall k \in [K], \notag\\\
&amp;amp; \pmb{D}_k^\top \pmb{\phi}_k + \pmb{B}^\top \pmb{\beta} = \pmb{0}, &amp;amp;&amp;amp; \forall k \in [K], \notag\\\
&amp;amp; \pmb{\phi}_k \in \mathcal{K}_k^*, &amp;amp;&amp;amp; \forall k \in [K],\notag
\end{align}
$$
其中，$\mathcal{A}(k):= \{k&#39; \in [K]~|~ \Xi_{k&#39;} \mbox{严格包含于} \Xi_{k} \}$，$\mathcal{K}_k^*$ 表示 $\mathcal{K}$ 的对偶锥 。&lt;/p&gt;
&lt;p&gt;当$ \eqref{dro.mod}$ 中 $\mathcal{F}:= \mathcal{F}_{KL}$ 时，则在某些技术性条件下，&lt;a href=&#34;http://www.optimization-online.org/DB%7B_%7DFILE/2012/11/3677.pdf&#34;&gt;He and Hong, 2013&lt;/a&gt; 推导出其对偶问题 $\eqref{dro.mod.dual}$的具体形式：
$$
\begin{align}
\displaystyle Z_D(\pmb{x}) = \min_{\alpha \ge 0} &amp;amp; \alpha \log \mathbb{E}_{\hat{\mathbb{P}}}[e^{\pmb{y}(\pmb{x})^\top \tilde{\pmb \varepsilon}^\dagger / \alpha}] + \alpha \theta. \label{dro.mod.kl.dual}
\end{align}
$$
其中的目标函数为凸函数，因此可用内点法 &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.1120.1641&#34;&gt;Ben-tal et al., 2013&lt;/a&gt; 或分段线性函数逼近 &lt;a href=&#34;10.1016/j.orl.2014.09.004&#34;&gt;Long and Qi, 2014&lt;/a&gt; 等方法进行处理。&lt;/p&gt;
&lt;p&gt;当 \eqref{dro.mod} 中 $\mathcal{F}:= \mathcal{F}_{W}$ 且其中的支撑集为 $\Xi:= \{\pmb{\varepsilon} \in \mathbb{R}^I | \pmb{C}\pmb{\varepsilon} \le \pmb{d}\}$ 时，则在某些技术性条件下，&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-017-1172-1&#34;&gt;Mohajerin Esfahani and Kuhn, 2018&lt;/a&gt; 推导出其对偶问题 \eqref{dro.mod.dual}的具体形式：
$$
\begin{align}
\displaystyle Z_D(\pmb{x}) = \inf_{\lambda, \pmb{s}, \pmb{\gamma}} &amp;amp;\displaystyle \lambda \theta + \frac{1}{N} \sum_{\omega \in [N]} s_\omega &amp;amp;&amp;amp;\label{dro.mod.w.dual}\\\
\mbox{s.t.} &amp;amp; \pmb{y}(\pmb{x})^\top \hat{\pmb{\varepsilon}}_\omega + \pmb{\gamma}_\omega^\top (\pmb{d} - \pmb{C} \hat{\pmb{\varepsilon}}_\omega) \le s_\omega, &amp;amp;&amp;amp; \forall \omega \in [N], \notag\\\
&amp;amp; \lVert \pmb{C}^\top \pmb{\gamma}_\omega - \pmb{y}(\pmb{x}) \rVert_* \le \lambda, &amp;amp; \forall \omega \in [N], \notag\\\
&amp;amp; \pmb{\gamma}_\omega \ge \pmb{0} &amp;amp;&amp;amp; \forall \omega \in [N].&amp;amp;
\end{align}
$$
将以上各结果嵌入到 \eqref{eq.dro.lo.eq} 即可得到 \eqref{dro.con.lo.eq} 的等价形式，进而求解鲁棒线性规划问题。&lt;/p&gt;
&lt;p&gt;事实上，&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1060.0353?journalCode=opre&#34;&gt;Popescu, 2007&lt;/a&gt;,&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1090.0741&#34;&gt;Delage and Ye, 2010&lt;/a&gt;, &lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre&#34;&gt;Wiesemann, Kuhn and Sim, 2014&lt;/a&gt;, &lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-017-1172-1&#34;&gt;Mohajerin Esfahani and Kuhn, 2018&lt;/a&gt; 的研究均解决了 \eqref{dro.con.pl} 的等价转化问题，而上述结论针对 \eqref{dro.con.lo.eq}，只是 \eqref{dro.con.pl} 中 $K = 1$ 时的特例，感兴趣的读者可细读他们的论文。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>多阶段问题与线性决策规则（Multi-stage problem and linear decision rule）</title>
      <link>https://allenz-me.github.io/RoSite/post/5.%E5%A4%9A%E9%98%B6%E6%AE%B5%E9%97%AE%E9%A2%98%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/5.%E5%A4%9A%E9%98%B6%E6%AE%B5%E9%97%AE%E9%A2%98%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99/</guid>
      
        <description>&lt;p&gt;汤勤深，陈植&lt;/p&gt;
&lt;p&gt;第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（Single stage）的问题。而企业或者决策者面对的问题中，很大一部分都是多阶段的（Multi-stage）。也即，决策者需要在一定的时间内，按时间顺序进行多个决策，且决策时只知过去已发生的随机变量（Random variable）而无法预知未来的。多阶段问题的这些特性，使得对相应问题的建模和求解特别复杂。在优化领域，一般是用随机规划或者动态规划进行建模和求解。然而，随机规划和动态规划都遭受“维度诅咒”（Curse of dimensionality）。&lt;/p&gt;
&lt;p&gt;针对随机规划和动态规划的这个致命缺点，鲁棒优化用一些决策规则（decision rule）进行规避。现有的决策规则已经可以达到很好的近似效果，甚至在某些条件下有一些决策规则可以达到最优。&lt;/p&gt;
&lt;p&gt;在这一章，我们将聚焦于如何用这些决策规则对多阶段问题（主要是两阶段问题）进行求解。在此之前，我们先着重介绍两阶段的随机规划问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：正如后面会讨论，决策规则近来越来越多地被改称为近似规则（Recourse approximation）。如若称为决策规则，则有后面阶段的决策将根据规则直接得到之嫌。而实际上，如果直接使用决策规则对后面阶段决策进行决策，其效果非常不可控。大多时候，模型会表现非常差。在模型的实施过程中，往往都是用滚动法（Rolling horizon），也即，在知道这一期的不确定性之后，将现在系统的状态当成初始状态，重新对模型进行求解，以获得下一期的最优决策。从这个角度来说，我们使用一定的规则去\textit{近似}未来的决策和不确定性之间的关系，从而达到简化模型的效果。&lt;/p&gt;
&lt;h2 id=&#34;随机规划stochastic-programming&#34;&gt;随机规划（Stochastic programming）&lt;/h2&gt;
&lt;p&gt;\label{sp_intro}
为了更好地理解随机规划，我们举例如下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例1&lt;/strong&gt;
单阶段库存管理模型 \label{example::single period inventory management}&lt;/p&gt;
&lt;p&gt;小王前不久在小区开了一个小卖部。他发现，小区对苹果的需求$\tilde{d}$满足分布$F(\cdot)$。他每天需要决定向20里外小张定$x$斤苹果。每斤苹果的进货单价为$c$，销售价格为$p$。若库存不足,也即真实需求$d$大于订货量$x$，居民可以先下单，等有货了再送过去。针对这种情况，小王一般会给一定的折扣。折算下来，每一斤苹果将增加$b$的成本。而如果订货量太多，也即$x - d \geq 0$，苹果可能会变质，折算下来一斤苹果将增加$h$的成本。小王的利润为：
$$
\pi(x, d) = p\min\{x, d\} - cx - b(d- x)^+ - h(x - d)^+.
$$&lt;/p&gt;
&lt;p&gt;小王想最大化他的期望利润，也即他将要解以下问题:
$$
\begin{align}
\max\ &amp;amp; \mathbb{E}_{\mathbb{P}}{\pi(x,\tilde{d})} \label{model::inventory management}\\\
\mathrm{s.t.}\ &amp;amp; x \geq 0\notag \notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;示例$\ref{example::single period inventory management}$就是一个在商业环境中随处可见的随机规划问题：在已知随机分布和满足一定的约束的情况下，进行决策使得期望利润最大化。一般地，随机规划关注以下问题:
$$
\begin{align}
\min\ &amp;amp; \mathbb{E}_{\mathbb{P}}{g(\pmb x,\tilde{\pmb  \xi})}, \label{model::SP model1}\\\
\mathbf{s.t.}\ &amp;amp;  \mathbb{E}_{\mathbb{P}}{f_i(\pmb x,\tilde{\pmb \xi})} \leq 0,  i\in[I].\notag
\end{align}
$$
其中，$\tilde{\pmb{\xi}}$为随机变量。&lt;/p&gt;
&lt;p&gt;示例$\ref{example::single period inventory management}$是一个单阶段的问题。但是，如果我们把卖多少苹果，$\min\{x,d\}$，当成决策$y$，那示例$\ref{example::single period inventory management}$就变成了一个两阶段的问题：第一阶段，决定定多少苹果，之后观测到需求；第二阶段，决定卖多少苹果。也即，模型$\eqref{model::inventory management}$可以写成
$$
\begin{align*}
\max\ &amp;amp; -c x - b\mathbb{E}_{\mathbb{P}}{\tilde{d}} - h x + \mathbb{E}_{\mathbb{P}}{g(x,\tilde{d})}\\\
\mathrm{s.t.}\ &amp;amp; x \geq 0
\end{align*}
$$
其中，
$$
\begin{align*}
g(x, d) = \max\ &amp;amp; (p + b + h)y\\\
\mathrm{s.t.}\ &amp;amp; y \geq x,\\\
&amp;amp; y \geq d\notag.
\end{align*}
$$
此模型可归类于由&lt;a href=&#34;https://www.jstor.org/stable/2627159&#34;&gt;Dantzig, 1995&lt;/a&gt;首先引入的经典的（线性）两阶段随机规划问题（two stage stochastic programming）： 第一阶段的决策变量为$\pmb x\in \mathbb{R}^{N_1}$，也称为“现时决策（Here-and-now decision）”。不失一般性，假设$\pmb x$的可行集为$\mathcal{X} = \{\pmb x:\pmb{Ax} = \pmb b,  \pmb x \geq \pmb 0\}$。与$\pmb x$相关的成本参数$\pmb c \in \mathbb{R}^{N_1}$。之后，随机量$\tilde{\pmb  \xi}\in \mathcal{W} \in \mathbb{R}^{I_1}$实现为$\pmb \xi$。其中$\mathcal{W}$为$ \tilde{\pmb \xi}$的支撑集。第二阶段决策变量为$\pmb y$，也称“等待决策（Wait-and-see decision）”。其相应的成本参数为$\pmb q\in \mathbb{R}^{N_2}$。此两阶段随机规划问题模型如下：
$$
\begin{align}
\min\ &amp;amp; \pmb c^{\top} \pmb x + \mathbb{E}_{\mathbb{P}}{g(\pmb x,\tilde{\pmb  \xi})},\label{model::Two Stage SP model1} \\\
\mathbf{s.t.}\ &amp;amp;  \pmb{A}\pmb x = \pmb b;\notag \\\
&amp;amp; \pmb x \geq \pmb 0,\notag
\end{align}
$$
其中
$$
\begin{align}
g(\pmb x,\pmb \xi) = \min\ &amp;amp; \pmb q^{\top}\pmb{y},\label{model::Two Stage SP model&amp;ndash;dependent} \\\
\mathbf{s.t.}\ &amp;amp;  \pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y = \pmb h(\pmb \xi);\notag\\\
&amp;amp; \pmb y \geq \pmb 0.\notag
\end{align}
$$
模型$\eqref{model::Two Stage SP model&amp;ndash;dependent}$中，$\pmb{T} \in \mathcal{R}^{I_1, M\times N_1}, \pmb h \in \mathcal{R}^{I_1,M}$是$\pmb \xi \in \mathcal{W}$的函数。在接下来的讨论中，我们假设他们仿射依赖于$\pmb \xi \in \mathbb{R}^{I_1}$：
$$
\pmb{T}(\pmb \xi) = \pmb T^0 + \sum_{i\in[I_1]}\pmb T^i\pmb \xi_i, \quad \pmb{b}(\pmb \xi) = \pmb b^0 + \sum_{i\in[I_1]}\pmb b^i\pmb \xi_i,
$$
其中，$\pmb T^0,\ldots,\pmb T^{I_1} \in \mathbb{R}^{M \times N_1}$，$\pmb b^0,\ldots,\pmb b^{I_1} \in \mathbb{R}^{M}$。&lt;/p&gt;
&lt;p&gt;另外，矩阵$\pmb W$称为递归矩阵（Recourse matrix）。第二阶段的模型$\eqref{model::Two Stage SP model&amp;ndash;dependent}$不一定总是有可行解。但是如果$\pmb W$是完全递归的（Complete recourse）&amp;mdash;对任意的$\pmb z \in \mathbb{R}^M$，存在$\pmb y\in \mathbb{R}^{N_2}$使得$\pmb W \pmb y \geq \pmb z$&amp;mdash;那么可以保证对于所有$\pmb x\in \mathbb{R}^{N_1}$和$\pmb \xi \in \mathbb{R}^{I_1}$，模型$\eqref{model::Two Stage SP model&amp;ndash;dependent}$都有可行解。然而完全递归的假设过于苛刻，有些问题不一定具有这个性质。通常情况下，我们会假设模型$\eqref{model::Two Stage SP model&amp;ndash;dependent}$对于所有的$\pmb x\in \mathcal{X}$和$\pmb \xi \in \mathcal{W}$都有可行解，也即模型$\eqref{model::Two Stage SP model&amp;ndash;dependent}$具有相对完全递归（Relatively complete recourse）。&lt;/p&gt;
&lt;p&gt;然而，两阶段随机模型具有以下难点:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大量变量和约束。&lt;/li&gt;
&lt;li&gt;难以获得$\tilde{\pmb \xi}$的集中分布。&lt;/li&gt;
&lt;li&gt;难以评估（Evaluate）目标函数。尤其当$\tilde{\pmb\xi}$的维度较大时。&lt;/li&gt;
&lt;li&gt;难以获得一个第一阶段的可行解$\pmb x$能够保证第二阶段的解$\pmb y$也是可行的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上难点，使得最简单的两阶段随机规划问题是一个$\# P$-难的问题；而如果阶段大于2，这个问题则是一个$\mathrm{PSPACE}$-难的问题&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-005-0597-0&#34;&gt;(Dyer and Stougie, 2006)&lt;/a&gt;。为了部分解决以上的这些问题，我们接下来介绍动态鲁棒优化和近似决策规则。&lt;/p&gt;
&lt;h2 id=&#34;动态鲁棒优化dynamic-robust-optimization&#34;&gt;动态鲁棒优化（Dynamic robust optimization）&lt;/h2&gt;
&lt;p&gt;在两阶段随机规划问题\eqref{model::Two Stage SP model1}中，假如$ \tilde{\pmb \xi}$的分布$\mathbb{P}$的具体分布未知，但是可以构建某个模糊集$\mathcal{P}$使得真实的分布在这个集合中，那么我们可以得到以下动态鲁棒优化模型：
$$
\begin{align}
\min\ &amp;amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{g(\pmb x,\tilde{\pmb  \xi})}, \label{model::Two Stage Robust model}\\\
\mathbf{s.t.}\ &amp;amp;  \pmb{A}\pmb x = \pmb b;\notag \\\
&amp;amp; \pmb x \geq \pmb 0,\notag
\end{align}
$$
其中
$$
\begin{align*}
g(\pmb x,\pmb \xi) = \min\ &amp;amp; \pmb q^{\top}\pmb{y},\\\
\mathbf{s.t.}\ &amp;amp;  \pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y = \pmb h(\pmb \xi);\\\
&amp;amp; \pmb y \geq \pmb 0.
\end{align*}
$$
我们可以等价地把模型$\eqref{model::Two Stage Robust model}$写成：
$$
\begin{align}
Z^* = \min\ &amp;amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{\pmb q^{\top}\pmb{y}(\tilde{\pmb  \xi})}, \label{model::Two Stage Robust model1} \\\
\mathbf{s.t.}\ &amp;amp;  \pmb A \pmb x = \pmb b;\notag\\\
&amp;amp;\pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y(\pmb \xi) = \pmb h(\pmb \xi)  \forall \pmb \xi \in \mathcal{W};\notag\\\
&amp;amp;\pmb y \in \mathcal{R}^{I_1, N_2};\notag\\\
&amp;amp;\pmb x \geq \pmb 0.\notag
\end{align}
$$
然而，模型$\eqref{model::Two Stage Robust model1}$一般来说是不可解的，因为$\pmb y$是$\pmb \xi $的任意一个函数。如果我们假设$\pmb y$和$\pmb\xi$之间的映射是可知的，比如是仿射或者二次的，那么模型$\eqref{model::Two Stage Robust model1}$是否可能有解呢？答案是肯定的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：
模型$\eqref{model::Two Stage SP model1}$是一个分布式鲁棒优化的两阶段模型。由第三章和第四章可知，当模糊集只包含随机量的支撑集时，分布式鲁棒优化模型退化成传统的鲁棒优化模型。因此，这一章节只讨论分布式鲁棒优化下的多阶段问题和线性决策规则。&lt;/p&gt;
&lt;h2 id=&#34;线性决策规则linear-decision-rule&#34;&gt;线性决策规则（Linear decision rule）&lt;/h2&gt;
&lt;p&gt;线性决策规则（LDR）是一种在动态优化模型中，假设当前阶段的决策\textbf{线性}依赖于（之前阶段）随机量的决策机制。也即，这是对决策量和随机量之间复杂关系的一种近似。相对应的，也有非线性的决策规则，比如二次决策规则（Quadratic decision rule, &lt;a href=&#34;https://www2.isye.gatech.edu/~nemirovs/FullBookDec11.pdf&#34;&gt;Ben-tal et al. 2009&lt;/a&gt;）和多项式决策规则（Polynomial decision rules, &lt;a href=&#34;https://ieeexplore.ieee.org/document/5986692&#34;&gt;Bertsimas et al., 2011&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;决策规则的提出旨在降低随机规划问题中的维度。有关于早期决策规则和随机规划结合的文献可参考&lt;a href=&#34;https://link.springer.com/article/10.1007%2FBF01585511&#34;&gt;Garstka and Wets&lt;/a&gt;等人1974年写的综述。然而，由于此近似所得模型过于保守而被弃用。
之后，&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-003-0454-y&#34;&gt;Ben-tal et al., 2004&lt;/a&gt;创造性地将LDR和鲁棒优化相结合，使得线性决策规则焕发出勃勃生机。 具体地，对于模型$\eqref{model::Two Stage Robust model1}$我们可以假设$\pmb y$是$\pmb \xi$的仿射函数，
$$
\pmb{y}(\pmb \xi) = \pmb y^0 + \sum_{i\in[I_1]}\pmb y_i^1\xi_i.
$$
不失一般性，我们定义以下集合
$$
\mathcal{L}^{I,N} = \bigg\{\pmb y \in \mathcal{R}^{I,N} \Big| \begin{array}{l}
\exists \pmb y^0, \pmb y_i^1, i \in [I_1]:\\\
\pmb y (\pmb \xi) = \pmb y^0 + \sum_{i\in[I_1]} \pmb y_i^1 \xi_i
\end{array}\bigg\}.
$$
在线性规则下，模型$\eqref{model::Two Stage Robust model1}$可以写成
$$
\begin{align}
Z^L = \min\ &amp;amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{\pmb q^{\top}\pmb{y}(\tilde{\pmb  \xi})},\label{model::Two Stage Robust model LDR}\\\
\mathbf{s.t.}\ &amp;amp;  \pmb A \pmb x = \pmb b;\notag\\\
&amp;amp;\pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y(\pmb \xi) = \pmb h(\pmb \xi)  \forall \pmb \xi \in \mathcal{W};\notag\\\
&amp;amp;\pmb y \in \mathcal{L}^{I_1,N_2},\pmb x \geq \pmb 0.\notag
\end{align}
$$&lt;/p&gt;
&lt;p&gt;由此，我们可以得到模型$\eqref{model::Two Stage Robust model1}$的一个上界。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt; {theorem}\label{theorem::upper bound}
$$
Z^{*} \leq Z^L.
$$&lt;/p&gt;
&lt;p&gt;既然是上界，那么很自然的问题是，这个近似的效果如何？近似之后的问题和原问题的差距多大？什么条件下这两个问题是一样的，也即，什么条件可以保证线性决策规则是最优的？对于前两个问题，据笔者所知，暂时没有一般性的结论。而对于第三个问题，&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.2013.1172&#34;&gt;Iancu, Sharma, and Sviridenko, 2013&lt;/a&gt;给出了模糊集中只包含随机量的支撑集时，线性决策规则最优的条件和技术性假设。 &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/moor.1100.0444&#34;&gt;Bertsimas, Iancu, and Parrilo, 2010&lt;/a&gt;和&lt;a href=&#34;https://link.springer.com/article/10.1007/s10107-011-0444-4&#34;&gt;Bertsimas and Goyal, 2012&lt;/a&gt;探讨了某几种特殊的多阶段问题中LDR最优的条件。 而对于下一小节要介绍的拓展式线性决策规则（ELDR），&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952&#34;&gt;Bertsimas, Sim, and Zhang, 2019&lt;/a&gt;证明了当第二阶段的决策变量为一维时，ELDR为最优。而&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/msom.2018.0734&#34;&gt;He, Hu, Zhang, 2020&lt;/a&gt;证明了ELDR对于车辆调度问题（Vehicle repositioning problem)在满足一定的技术性假设条件下，对于任意维度的递归决策都是最优的。对于第五小节要介绍的情景仿射递归近似规则，&lt;a href=&#34;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3305039&#34;&gt;Perakis et al., 2020&lt;/a&gt;证明了在三阶段的定价和库存模型中，当只考虑一个产品时，
事件式近似法则是最优的。而对于多个产品的情况，从数值例子来看，也接近于最优。&lt;/p&gt;
&lt;p&gt;LDR的运用使得多阶段的鲁棒优化问题受到了越来越多的学者的关注。然而，线性决策规则有一个很明显的缺点，近似模型太保守或者容易使得模型不可解。比如，&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1070.0457&#34;&gt;Chen et al., 2008&lt;/a&gt;指出，当$\pmb \xi$的支撑集$\mathcal{W} = (-\infty, + \infty)$时，
$$
\pmb{y}(\pmb \xi) = \pmb y^0 + \sum_{i\in[I_1]}\pmb y_i^1\xi_i \geq \pmb 0,
$$
可以得到$\pmb y_i^1 = \pmb 0, \forall i \in [I_1]$。此时，$\pmb y(\pmb \xi ) = \pmb y^0$是静态的（Static policy），而不是动态地依赖于$\pmb \xi$。 这就很容易导致所得的解过于保守或者模型不可解。比如考虑如下的随机优化问题：
$$
\begin{align*}
\min &amp;amp; \mathbb{E}_{\mathbb{P}}{y_1(\pmb \xi) + y_2(\pmb \xi)}\\\
\textrm{s.t.} &amp;amp; y_1(\pmb \xi) - y_2(\pmb \xi) = h(\pmb \xi);\\\
&amp;amp; y_1(\pmb \xi) \geq 0, y_2(\pmb \xi) \geq 0.
\end{align*}
$$
如果$\pmb \xi$的支撑集$\mathcal{W} = (-\infty, + \infty)$，那么$y_1(\pmb \xi) = y_1^0, y_2(\pmb \xi) = y_2^0$。而此时，等式$y_1(\pmb \xi) - y_2(\pmb \xi) = h(\pmb \xi)$将无法被满足。有鉴于此，&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1070.0457&#34;&gt;Chen et al., 2008&lt;/a&gt;提出了偏转线性决策规则（Deflected linear decision rule, DLDR）和分离线性决策规则（Segregated linear decision rule,SLDR）。&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1090.0746&#34;&gt;See and Sim, 2010&lt;/a&gt;提出了截断线性决策规则（Truncated linear decision rule），&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1090.0795&#34;&gt;Goh and Sim, 2010&lt;/a&gt;则将DLDR和SLDR扩展到双偏转线性决策规则（Bideflected linear decision rule）和广义分离线性决策规则（Generalized segregated linear decision rule）。&lt;/p&gt;
&lt;p&gt;对于LDR在多阶段问题中的更多的运用，读者可以阅读&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/educ.2015.0139&#34;&gt;Delage and Iancu, 2015&lt;/a&gt;和 &lt;a href=&#34;https://link.springer.com/article/10.1007/s10287-018-0338-5&#34;&gt;Georghiou, Kuhn, and Wiesemann&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面，我们举个LDR在多阶段鲁棒库存管理中的例子&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/opre.1090.0746&#34;&gt;(See and Sim, 2010&lt;/a&gt;,&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952&#34;&gt;Bertsimas, Sim, and Zhang, 2019)&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;** 例2** 多阶段库存管理模型
假如示例$\ref{example::single period inventory management}$中的小王每天都要定苹果。总共要定$T$天。所有的成本以都是波动的，也即都跟$t\in [T]$相关。假如第$t$天期早上的库存水平（inventory level）为$y_t$，那么第$t + 1$天的库存水平$y_{t + 1}$可以通过$y_t, x_t$和$d_t$得到：
$$
y_{t+1} = y_{t} + x_t - d_t.
$$&lt;/p&gt;
&lt;p&gt;假设需求是随机因子$\tilde{\pmb z}$的函数
$$
d_t(\tilde{\pmb z}_t) = \tilde{z}_t + \alpha \tilde{z}_{t - 1} + \cdots + \alpha \tilde{z}_1 + \mu,
$$
其中，$\alpha \in [0,1], \tilde{\pmb z}_t := (\tilde{z}_1, \ldots, \tilde{z}_t)$，$\tilde{z}_t$为第$t$天的期望为零且两两互不相关(uncorrelated)的随机因子。那么，我们可以把小王这$T$天的问题写成如下鲁棒优化模型:
$$
\begin{array}{lll}
\min, &amp;amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{P}} \mathbb{E}_{\mathbb{P}}{\sum_{t \in [T]} c_t x_t(\tilde{\pmb z}_{t - 1}) + v_{t}(\tilde{\pmb z}_{t}))}&amp;amp;\\\
\textrm{s.t.}  &amp;amp; y_{t+1}(\pmb z_t) = y_{t}(\pmb z_{t - 1}) + x_t(\pmb z_{t - 1}) - d_t(\pmb z_{t}) &amp;amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;amp;v_t(\pmb z_t) \geq h_t y_{t + 1}(\pmb z_{t}) &amp;amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;amp;v_t(\pmb z_t) \geq -b_ty_{t + 1}(\pmb z_{t}) &amp;amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;amp;0 \leq x(\pmb z_{t - 1}) \leq \bar{x}_t &amp;amp; \forall \pmb z \in \mathcal{W}, t \in [T];\\\
&amp;amp;x_t \in \mathcal{L}^{t - 1,1}, y_{t + 1} \in \mathcal{L}^{t,1}, v_t \in \mathcal{L}^{t,1} &amp;amp; \forall t \in [T].
\end{array}
$$&lt;/p&gt;
&lt;h2 id=&#34;拓展式线性决策规则extended-linear-decision-rule&#34;&gt;拓展式线性决策规则(Extended linear decision rule)&lt;/h2&gt;
&lt;p&gt;在第.1.1中，我们介绍了基于广义矩信息的模糊集。其中，&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.2014.1314?journalCode=opre&#34;&gt;Wiesemann, Kuhn and Sim, 2014&lt;/a&gt;巧妙地引入了辅助随机变量$\tilde{\pmb u}$使得升维之后的模糊集（Lifted ambiguity set）中的约束皆化为线性约束，而将非线性部分转移到了支撑集中。相应地，在模型$\eqref{model::Two Stage Robust model1}$,如果假设$\pmb y$是$\pmb \xi$和$\pmb u$的仿射函数，也即
$$
\mathcal{L}^{I + J,N} = \bigg\{\pmb y \in \mathcal{R}^{I + J,N} \Big| \begin{array}{l}
\exists \pmb y^0, \pmb y_i^1, \pmb y_j^2 \in \mathbb{R}^N, \forall i \in [I], j \in [J]:\\\
\pmb y (\pmb \xi, \pmb u) = \pmb y^0 + \sum_{i\in[I]} \pmb y_i^1 \xi_i + \sum_{j\in[J]} \pmb y_j^2 u_j
\end{array}\bigg\}.
$$&lt;/p&gt;
&lt;p&gt;在线性规则下，模型$\eqref{model::Two Stage Robust model1}$可以写成
$$
\begin{align}
Z^E = \min\ &amp;amp; \pmb c^{\top} \pmb x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}{\pmb q^{\top}\pmb{y}(\tilde{\pmb  \xi},  \tilde{\pmb u})},\label{model::Two Stage Robust model ELDR}\\\
\mathbf{s.t.}\ &amp;amp;  \pmb A \pmb x = \pmb b;\notag\\\
&amp;amp;\pmb{T}(\pmb \xi)\pmb x + \pmb{W}\pmb y(\pmb \xi,  \tilde{\pmb u}) = \pmb h(\pmb \xi)  \forall \pmb \xi \in \mathcal{W};\notag\\\
&amp;amp;\pmb y \in \mathcal{L}^{I_1 + I_2,N_2},\pmb x \geq \pmb 0.\notag
\end{align}
$$
由此，我们可以得到一个比LED更好的近似模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt; {theorem}
$$
Z^{*} \leq Z^E \leq Z^L$. \label{theorem::tighter upper bound}
$$&lt;/p&gt;
&lt;p&gt;详细的证明请参考&lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952&#34;&gt;Bertsimas, Sim, and Zhang, 2019&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;事件式近似法则event-wise-affine-recourse-approximation&#34;&gt;事件式近似法则(Event-wise affine recourse approximation)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603&#34;&gt;Chen, Sim, and Xiong, 2020&lt;/a&gt;提出的鲁棒随机优化（Robust Stochastic Optimization, RSO）模型的统一框架。&lt;/p&gt;
&lt;p&gt;定义静态决策$\pmb{w} \in \mathbb{R}^{J_w}$，连续随机变量$\tilde{\pmb z}$， 和离散随机变量$\tilde{s}$。定义只取决于离散随机变量$\tilde{s}$的动态决策$\pmb{x}(s):[S] \mapsto \mathbb{R}^{J_x}$,以及同时取决于连续随机变量$\tilde{\pmb z}$和离散随机变量$\tilde{s}$的动态决策$\pmb{y}(s,\pmb{z}): [S] \times \mathbb{R}^{I_z} \mapsto \mathbb{R}^{J_y}$。与线性近似法则类似，对应离散随机变量的不同取值，动态决策$\pmb{y}(s,\pmb{z})$为连续随机变量$\tilde{\pmb z}$的不同的线性函数：
$$
\pmb{y}(s,\pmb{z})  := \pmb{y}^0(s) + \sum_{i \in [I_z]} \pmb{y}^i(s) z_i.
$$
其中，系数$\pmb{y}^0(s),\dots,\pmb{y}^{I_z}(s)$是最终模型的实际决策变量。&lt;/p&gt;
&lt;p&gt;定义线性映射
$$
\left\{
\begin{array}{rll}
\pmb{a}_m(s,\pmb{z})   &amp;amp;:=&amp;amp;   \pmb{a}_{ms}^0 + \sum_{i \in [I_z]} \pmb{a}_{ms}^i z_i \\\
\pmb{b}_m(s,\pmb{z})   &amp;amp;:=&amp;amp;   \pmb{b}_{ms}^0 + \sum_{i \in [I_z]} \pmb{b}_{ms}^i z_i \\\
\pmb{c}_m(s)   &amp;amp;:= &amp;amp;   \pmb{c}_{ms} \\\
d_m(s,\pmb{z})  &amp;amp;:= &amp;amp;  d_{ms}^0 + \sum_{i \in [I_z]} d_{ms}^i z_i
\end{array}
\right. \forall m \in [M] \cup \{0\}.
$$
其中，参数维度如下
$$
\pmb{a}_{ms}^i \in \mathbb{R}^{J_w}, \pmb{b}_{ms}^i \in \mathbb{R}^{J_x}, \pmb{c}_{ms} \in \mathbb{R}^{J_y},  d_{ms}^i \in \mathbb{R} \forall i \in [I_z] \cup \{0\},  s \in [S].
$$
RSO模型的目标函数取分布集合$\mathcal{F}$（稍后介绍）下的最坏期望
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_0(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_0(\tilde{s},\tilde{\pmb z})}.
$$
RSO模型主要包含两类约束。第一类“硬”线性约束($m \in \mathcal{M}_1$)为一般鲁棒约束，需要在随机变量任意可能的取值下均满足：
$$
\pmb{a}^\prime_m(s,\pmb{z})\pmb{w} + \pmb{b}^\prime_m(s,\pmb{z})\pmb{x}(s) + \pmb{c}^\prime_m(s)\pmb{y}(s,\pmb{z}) + d_m(s,\pmb{z}) \leq 0 \forall \pmb{z} \in  \mathcal{Z}_s,  s \in [S].
$$
第二类“软”线性约束($m \in \mathcal{M}_2$)与目标函数类似，考虑分布集合$\mathcal{F}$下的最坏期望，并要求该最坏期望不为正：
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_m(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_m(\tilde{s},\tilde{\pmb z})} \leq 0 \forall m \in \mathcal{M}_2.
$$
除以上两类约束之外，在离散随机变量的不同取值下，RSO还包含非线性约束（如凸约束，整数约束等）
$$
\pmb{r}(s) := \left(\pmb{w},\pmb{x}(s),\pmb{y}^0(s),\dots,\pmb{y}^{I_z}(s) \right) \in \mathcal{X}_s \forall s \in [S],
$$&lt;/p&gt;
&lt;h3 id=&#34;事件式近似法则&#34;&gt;事件式近似法则&lt;/h3&gt;
&lt;p&gt;记离散随机变量$\tilde{s}$的取值范围为$[S]$。特别地，离散随机变量$\tilde{s}$每一个取值$s$对应一个情景$s$。定义由情景组成的一个非空集合为一个事件$\mathcal{E} \subseteq [S]$。如此，全部情景的一个划分（partition?）定义了一个相互独立（mutually exclusive）又完全穷尽（collectively exhaustive）的MECE事件集合，记为$\mathcal{C}$。相应地，满足$\mathcal{H}_{\mathcal{C}}(s) = \mathcal{E}$ 函数$\mathcal{H}_{\mathcal{C}}:[S] \mapsto \mathcal{C}$确定了情景$s$在一个MECE事件集合中唯一所属的事件$\mathcal{E}$。&lt;/p&gt;
&lt;p&gt;给定一个MECE事件集合，事件式静态近似法则定义如下
$$
\mathcal{A}\left(\mathcal{C}\right)
:= \left\{x : [S] \mapsto \mathbb{R} \left|
\begin{array}{l}&lt;br&gt;
x(s) =  x^\mathcal{E}, \mathcal{E} = \mathcal{H}_\mathcal{C}(s) \\\
\mbox{for some } x^\mathcal{E} \in \mathbb{R}
\end{array}\right. \right\};
$$
亦即，不同事件下，静态决策不同。&lt;/p&gt;
&lt;p&gt;类似地，事件式线性近似法则定义如下
$$
\bar{\mathcal{A}}\left(\mathcal{C}, \mathcal{I}\right) := \left\{ y : [S]  \times \mathbb{R}^{I_z}  \mapsto \mathbb{R} \left|
\begin{array}{l}&lt;br&gt;
y(s,\pmb{z}) =
\displaystyle  y^0(s) + \sum_{i \in \mathcal{I}} y^i(s) z_i  \\\
\mbox{for some } y^0, y^i \in \mathcal{A}(\mathcal{C}), i \in \mathcal I
\end{array}\right. \right\}
$$
其中，信息集合$\mathcal I \subseteq [I_z]$为连续随机变量$\tilde{\pmb z}$的部分索引（components?），声明了连续随机变量$\tilde{\pmb z}$中，事件式线性近似法则所能线性依赖的成分。事件式线性近似法则声明了在不同事件下，动态决策不同，并且动态决策为连续随机变量$\tilde{\pmb z}$的线性函数。&lt;/p&gt;
&lt;p&gt;基于事件式近似法则，完整的RSO模型如下
$$
\begin{array}{cll}
\min &amp;amp;\displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_0(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_0(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_0(\tilde{s},\tilde{\pmb z})} \\\
{\rm s.t.} &amp;amp;
\pmb{a}^\prime_m(s,\pmb{z})\pmb{w} + \pmb{b}^\prime_m(s,\pmb{z})\pmb{x}(s) + \pmb{c}^\prime_m(s)\pmb{y}(s,\pmb{z}) + d_m(s,\pmb{z}) \leq 0 &amp;amp; \forall \pmb{z} \in  \mathcal{Z}_s,  s \in [S],  m \in \mathcal{M}_1 \\\
&amp;amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{a}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{w} + \pmb{b}^\prime_m(\tilde{s},\tilde{\pmb z})\pmb{x}(\tilde{s}) + \pmb{c}^\prime_m(\tilde{s})\pmb{y}(\tilde{s},\tilde{\pmb z}) + d_m(\tilde{s},\tilde{\pmb z})} \leq 0 &amp;amp; \forall m \in \mathcal{M}_2 \\\
&amp;amp;\left(\pmb{w},\pmb{x}(s),\pmb{y}^0(s),\dots,\pmb{y}^{I_z}(s) \right) \in \mathcal{X}_s &amp;amp; \forall s \in [S]\\\
&amp;amp; x_j \in \mathcal{A}(\mathcal{C}^j_x) &amp;amp; \forall j \in [J_x] \\\
&amp;amp; y_j \in \bar{\mathcal{A}}(\mathcal{C}^j_y, \mathcal{I}^j_y) &amp;amp; \forall j \in [J_y].
\end{array}
$$
其中，$\mathcal{C}^j_x, j \in [J_x]$， $\mathcal{C}^j_y, j \in [J_y]$为MECE事件集合, $\mathcal{I}^j_y, j \in [J_y]$为信息集合。&lt;/p&gt;
&lt;h3 id=&#34;事件式分布模糊集&#34;&gt;事件式分布模糊集&lt;/h3&gt;
&lt;p&gt;事件式分布模糊集刻画了连续随机变量$\tilde{\pmb z}$和离散随机变量$\tilde{s}$的联合分布的分布性质，包含了联合分布的分布信息。事件式分布模糊集取如下一般形式
$$
\label{eventwise_as}
\mathcal{F} = \left\{\mathbb{P} \in \mathcal{P}_0\left(\mathbb{R}^{I_z} \times [S]\right)  \left\vert
\begin{array}{ll}
(\tilde{\pmb z},\tilde{s}) \sim \mathbb{P}\\\
\mathbb{E}_{\mathbb{P}}[\tilde{\pmb z} \mid \tilde{s} \in \mathcal{E}_k] \in \mathcal{Q}_k &amp;amp; \forall k \in [K] \\\
\mathbb{P}[\tilde{\pmb z} \in \mathcal{Z}_s \mid \tilde{s} = s]  = 1 &amp;amp; \forall s \in [S]  \\\
\mathbb{P}[\tilde{s} = s]  = p_s &amp;amp; \forall s \in [S]  \\\
\mbox{for some } \pmb{p} \in \mathcal{P}&lt;br&gt;
\end{array}
\right.
\right\}
$$
其中，$\mathcal{E}_k, k \in [K]$为不同事件（注意，这些事件不需要组成MECE事件集合），$\mathcal{Z}_s, s \in [S]$, $\mathcal{Q}_k, k \in [K]$, 和$\mathcal{P} \subseteq \{\pmb{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$为封闭的凸集合。事件式分布模糊集声明了
(1) 不同事件（$\mathcal{E}_k$）下连续随机变量$\tilde{\pmb z}$的事件期望（即条件期望）。
(2) 不同情景（$s$）下连续随机变量$\tilde{\pmb z}$的支撑集合（即条件支撑集合）。
(3) 不同情景（$s$）发生的概率。&lt;/p&gt;
&lt;p&gt;不确定集合$\mathcal{Q}_k, k \in [K]$和$\mathcal{P} \subseteq \{\pmb{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$分别允许条件信息（1）和（3）亦可以是不确定的。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603&#34;&gt;Chen, Sim, and Xiong, 2020&lt;/a&gt;证明了事件式分布模糊集有非常好的普适性。它可以描述随机优化中常用的确定的离散分布（deterministic discrete distribution），以及分布鲁棒优化中用到的不确定的离散分布（uncertain discrete distribution）, 确定的（或不确定的）混合分布（mixture distribution），基于矩信息的分布模糊集（moments ambiguity set），以及数据驱动下（1）基于机器学习聚类或分类算法的分布模糊集（K-means ambiguity set）与（2）基于Wasserstein距离的分布模糊集（Wasserstein ambiguity set）。&lt;/p&gt;
&lt;h2 id=&#34;经典鲁棒优化转化&#34;&gt;经典鲁棒优化转化&lt;/h2&gt;
&lt;p&gt;给定情景$s$，RSO模型中目标函数和“软（硬）”约束实际上是决策变量和连续随机变量$\tilde{\pmb z}$的取值$\pmb{z}$的双线性函数。因为，我们可以将它们方便地记为
$$
{\pmb{a}^\prime_m(s,\pmb{z})\pmb{w} + \pmb{b}^\prime_m(s,\pmb{z})\pmb{x}(s) + \pmb{c}^\prime_m(s)\pmb{y}(s,\pmb{z}) + d_m(s,\pmb{z})}   := \pmb{r}^\prime(s)\pmb{G}_m(s)\pmb{z} + h_m(s)    \forall m \in [M] \cup \{0\}.
$$
其中，$\pmb{G}_m(s)  \in  \mathbb{R}^{J_r \times I_z}$和 $h_m(s) \in \mathbb{R}$为参数。这样的双线性函数在事件式分布模糊集下的最坏期望可以通过求解一个经典鲁棒优化模型得到。换句话说，RSO模型可以很方便地通过的配套建模工具包进行建模。目前，&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603&#34;&gt;Chen, Sim, and Xiong, 2020&lt;/a&gt;论文中所提到的建模工具包RSOME的&lt;a href=&#34;https://sites.google.com/view/rsome/home%7D&#34;&gt;MATLAB版本&lt;/a&gt;和&lt;a href=&#34;https://xiongpengnus.github.io/rsome/&#34;&gt;Python 版本&lt;/a&gt;都已经发布。读者可以下载进行测试，并通过用户手册中的实例学习RSO的应用场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;
{theorem}{模型等价转换}{thm:worst-case expectation}\label{thm:worst-case expectation}
最坏期望
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}{\pmb{r}^\prime(\tilde{s})\pmb{G}_m(\tilde{s})\tilde{\pmb z} + h_m(\tilde{s}) }
$$
等于如下经典鲁棒优化模型的最优目标函数值
$$
\begin{array}{cll}
\inf &amp;amp; \gamma \\\
{\rm s.t.} &amp;amp; \gamma \geq \pmb{\alpha}^\prime\pmb{p} + \displaystyle \sum_{k \in [K]} \pmb{\beta}^\prime_k\pmb{\mu}_k &amp;amp; \forall \pmb{p} \in \mathcal{P},  \dfrac{\pmb{\mu}_k}{\sum_{s \in \mathcal{E}_k} p_s} \in \mathcal{Q}_k,  k \in [K] \\\
&amp;amp; \alpha_s + \displaystyle \sum_{k \in \mathcal{K}_s} \pmb{\beta}_k^\prime\pmb{z}  \geq \pmb{r}^\prime(s)\pmb{G}_m(s)\pmb{z} + h_m(s) &amp;amp; \forall \pmb{z} \in \mathcal{Z}_s,  s \in [S] \\\
&amp;amp; \gamma \in \mathbb{R},  \pmb{\alpha} \in \mathbb{R}^S,  \pmb{\beta}_k \in \mathbb{R}^{I_z} &amp;amp; \forall k \in [K],
\end{array}
$$
其中对每一个$s \in [S]$, $\mathcal{K}_s = \{k \in [K] \mid s \in \mathcal{E}_k\}$.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>鲁棒性优化（Robustness Optimization）</title>
      <link>https://allenz-me.github.io/RoSite/post/6.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E9%B2%81%E6%A3%92%E6%80%A7%E4%BC%98%E5%8C%96/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/6.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E9%B2%81%E6%A3%92%E6%80%A7%E4%BC%98%E5%8C%96/</guid>
      
        <description>&lt;p&gt;陈植&lt;/p&gt;
&lt;h2 id=&#34;目标驱动最优化和satisficinggoal-driven-optimization-and-satisficing&#34;&gt;目标驱动最优化和Satisficing（Goal-Driven Optimization and Satisficing）&lt;/h2&gt;
&lt;h2 id=&#34;鲁棒性优化robustness-optimization&#34;&gt;鲁棒性优化（Robustness Optimization）&lt;/h2&gt;
&lt;p&gt;经济学和心理学中常用Satisficing理论来研究决策者在不确定环境下的决策过程。在Satisficing理论的假设中，决策者依据能够同时满足全部约束的可能性大小来对各决策进行排序，并选取其中最有可能同时满足全部约束的为最优决策。基于Satisficing理论，&lt;a href=&#34;http://www.optimization-online.org/DB_HTML/2016/01/5310.html&#34;&gt;Jaillet et al., 2016&lt;/a&gt;提出如下模型
$$
\begin{align*}
\begin{array}{cll}
\max &amp;amp; \rho(\pmb{\alpha}) \\\
{\rm s.t.} &amp;amp; \pmb{A}(\pmb{z})\pmb{x} \geq \pmb{b}(\pmb{z}) &amp;amp;\forall \pmb{z} \in \mathcal{U}(\pmb{\alpha}) \\\
&amp;amp; \pmb{x} \in \mathcal{X} \\\
&amp;amp; \pmb{\alpha} \in \mathcal{S}.
\end{array}
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;一般地，对参数化不确定集合$\mathcal{U}(\pmb{\alpha})$, 可行决策$\pmb{x} \in \mathcal{X}$需要满足鲁棒约束
$$
\pmb{A}(\pmb{z})\pmb{x} \geq \pmb{b}(\pmb{z})    \forall \pmb{z} \in \mathcal{U}(\pmb{\alpha}).
$$
参数$\pmb{\alpha}$决定了不确定集合$\mathcal{U}(\pmb{\alpha})$的大小，函数$\rho(\pmb{\alpha})$则反映了决策者对这一参数的喜好程度。&lt;/p&gt;
&lt;p&gt;最简单的，取一维参数$\alpha$，$\mathcal{S} = \mathbb{R}_+$， 和$\rho(\alpha) = \alpha$, 上述模型即变为
$$
\begin{array}{cll}
\max &amp;amp; \alpha \\\
{\rm s.t.} &amp;amp; \pmb{A}(\pmb{z})\pmb{x} \geq \pmb{b}(\pmb{z}) &amp;amp; \forall \pmb{z} \in \mathcal{U}(\alpha) \\\
&amp;amp; \pmb{x} \in \mathcal{X} \\\
&amp;amp; \alpha \geq 0.
\end{array}
$$
&lt;a href=&#34;http://www.optimization-online.org/DB_HTML/2016/01/5310.html&#34;&gt;Jaillet et al., 2016&lt;/a&gt;称之为鲁棒性优化（Robustness Optimization）模型。&lt;/p&gt;
&lt;p&gt;从Satisficing理论出发，鲁棒性优化模型为一般鲁棒优化模型
$$
\begin{array}{cll}
\max &amp;amp; \pmb{c}&#39;\pmb{x} \\\
{\rm s.t.} &amp;amp; \pmb{A}(\pmb{z})\pmb{x} \geq \pmb{b}(\pmb{z}) &amp;amp; \forall \pmb{z} \in \mathcal{U}(\Gamma) \\\
&amp;amp; \pmb{x} \in \mathcal{X}
\end{array}
$$
提供了新的解释。一般鲁棒优化模型需要决策者声明自己对不确定性的偏好，即声明不确定集合$\mathcal{U}(\Gamma)$的大小。不确定集合$\mathcal{U}(\Gamma)$的大小通常由参数$\Gamma$直接调控。例如，&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;提出的鲁棒价格$\Gamma$调控了不确定参数中有多少成分能够同时取到最坏情况。对于一些决策者而言，这并不是一件容易的事，因为他们对自己的偏好并没有清楚的认识；相反，声明自身可接受的成本（亦即$\pmb{c}&#39;\pmb{x}$）也许更容易。对这样的决策者而言，求解如下鲁棒性优化模型或许更为直观
$$
\begin{array}{cll}
\max &amp;amp; \alpha \\\
{\rm s.t.} &amp;amp; \pmb{A}(\pmb{z})\pmb{x} \geq \pmb{b}(\pmb{z}) &amp;amp; \forall \pmb{z} \in \mathcal{U}(\alpha) \\\
&amp;amp; \pmb{x} \in \mathcal{X} \\\
&amp;amp; \pmb{c}^\top \pmb{x} \leq B \\\
&amp;amp; \alpha \geq 0.
\end{array}
$$
在可控成本范围内（$\pmb{c}&#39;\pmb{x} \leq B$），在更大的不确定集合影响下依然能满足不确定性约束的决策则更优。这样的决策标准，正好可以在Satisficing理论的框架下进行解释。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>鲁棒优化与机器学习（Machine learning）</title>
      <link>https://allenz-me.github.io/RoSite/post/7.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/7.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E4%B8%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
      
        <description>&lt;p&gt;覃含章&lt;/p&gt;
&lt;p&gt;\textcolor{magenta}{分布式鲁棒贝叶斯学习\cite{kirschner2020distributionally}}&lt;/p&gt;
&lt;p&gt;本章中我们介绍鲁棒优化与机器学习相结合的一些研究的最新进展。&lt;/p&gt;
&lt;h2 id=&#34;从鲁棒优化角度看回归模型regression-正则性regularization和鲁棒性robustness&#34;&gt;从鲁棒优化角度看回归模型（Regression）: 正则性（Regularization）和鲁棒性（Robustness）&lt;/h2&gt;
&lt;p&gt;我们知道，著名的LASSO算法实际上是求解带有$L_1$正则项的线性回归模型。即，一般是考虑求解这样一个优化问题
$$
\min_{\pmb{\beta}} | \pmb{y} -\pmb{X} \pmb{\beta} |_2+\lambda |\pmb{\beta}|_1,
$$
其中$\pmb{X}\in \mathbb{R}^{M\times N}$是描述数据特征（feature）的矩阵，$\pmb{y}\in \mathbb{R}^M$是描述数据标签（label）的向量，$\lambda&amp;gt;0$是正则项前的系数。在一些限制条件和假设下，可以证明存在某个自然数$k$,使得LASSO等价于求解如下问题（我们使用$|\cdot |_0$ 表示一个向量非零元素的个数，即$|\pmb{\beta}|_0=\text{card}(\{ i:\pmb{\beta}_i\neq 0 \})$）：
$$
\begin{align*}
\min_{\pmb{\beta}}  &amp;amp; |\pmb{y}-\pmb{X}\pmb{\beta}|_2 \\\
\text{s.t. } &amp;amp; |\pmb{\beta}|_0 \leq k.
\end{align*}
$$
也就是说在这种情况下LASSO所得到的解是稀疏（sparse）的。这里我们主要考虑这样一种非概率的统计模型，即我们认为我们只能得到$\pmb{X}$的一个带有误差的样本$ \pmb{X}&#39;$。我们利用鲁棒优化的思想，认为$ \pmb{X}&#39;=\pmb{X}+\pmb{\Delta}$，而$\pmb{\Delta}\in \mathcal{U}\subset \mathbb{R}^{M\times N}$，这里的$\mathcal{U}$就是我们的不确定集合（uncertainty set），注意这个集合是非随机的（deterministic）的。我们因此就可以考虑这样一个鲁棒线性回归问题：
$$
\min_{\pmb{\beta}} \max_{\pmb{\Delta}\in \mathcal{U}} | \pmb{y} -(\pmb{X}+\pmb{\Delta}) \pmb{\beta} |_2.
$$
这个鲁棒线性回归是个什么意思呢，也就是说我们现在优化的时候，所选择的$\pmb \beta$是最小化了不确定集里最差的那个$\pmb X&#39;$，即我们要让“最坏情况”下的损失函数值最小。而在传统的LASSO或者线性回归中，我们的目标可以看成是要让期望的损失函数值最小。下面先初步解答如下问题：在线性回归模型中，我们什么时候可以将正则性和鲁棒性，这一个来自统计/机器学习，一个来自优化理论的性质等同看待？这里就以回归模型中最出名的脊回归（Ridge Regression）和LASSO为例。
$$
\begin{align}
&amp;amp; \min_{\pmb{\beta}}|\pmb y - \pmb X\pmb \beta|_2+\lambda|\pmb \beta|_2=\min_{\pmb \beta}\max_{\pmb \Delta\in \mathcal{U}_{\text{RLS}}} | \pmb y - (\pmb X + \pmb \Delta) \pmb \beta|_2,\label{equ:RLS} \\\
&amp;amp; \min_{\pmb{\beta}}|\pmb y - \pmb X\pmb \beta|_2 +\lambda |\pmb \beta|_1  =\min_{\pmb \beta}\max_{\pmb \Delta\in \mathcal{U}_{\text{LASSO}}} | \pmb y - (\pmb X+\pmb  \Delta) \pmb \beta|_2\label{equ:LASSO}.
\end{align}
$$
注意到脊回归和LASSO说白了只是正则项不同（选用$L_1$和$L_2$正则）的最小二乘法（least squares method），那么我们就发现上面的结果告诉了我们它们都对应特定的鲁棒线性优化模型，只是对应的不确定集不同罢了！具体来说，我们有$\mathcal{U}_{\text{RLS}}$和$\mathcal{U}_{\text{LASSO}}$对应两个不同的二阶锥（second-order cone）约束集：
$$
\begin{align}
&amp;amp; \mathcal{U}_{\text{RLS}}=\left\{ \pmb \Delta: \left(\sum_{ij} \Delta_{ij}^2\right)^{1/2}\leq \lambda   \right\}, \\\
&amp;amp; \mathcal{U}_{\text{LASSO}}=\left\{ \pmb \Delta: \pmb \Delta\text{的每列$\Delta_i$都满足: } |\Delta_i|_2\leq \lambda  \right\}.
\end{align}
$$
那么这边我们就获得了对脊回归、LASSO的一种基于鲁棒优化的新认识：这两种带正则项的线性回归其实可以看成一种鲁棒线性回归算法！那么自然，我们接下来应该也会对这两个问题感兴趣：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;正则性和鲁棒性在线性回归中是否都是一回事？&lt;/li&gt;
&lt;li&gt;如果不都是一回事的话，在什么条件下是？什么条件下不是？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;鲁棒线性回归定理&lt;/strong&gt;
{theorem} 鲁棒线性回归定理 &lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0377221717302734&#34;&gt;Bertsimas and Copenhaver, 2018&lt;/a&gt;{thm:RO_Reg}\label{thm:RO_Reg}
（1）存在$0&amp;lt;\alpha\leq 1$使得对任何$\pmb y, \pmb X, \pmb \beta$,
$$
|\pmb y-\pmb X\pmb \beta|_p + \alpha \max_{\pmb \Delta \in \mathcal{U}} |\pmb \Delta \pmb \beta|_p\leq \max_{\pmb \Delta\in \mathcal{U}}|\pmb y - (\pmb X+\pmb \Delta)\pmb \beta|_p\leq |\pmb y-\pmb X\pmb \beta|_p +  \max_{\pmb \Delta \in \mathcal{U}} |\pmb \Delta \pmb \beta|_p.
$$
（2）我们令$\mathcal{U}=\{\pmb \Delta : |\pmb \Delta|\leq \lambda  \}$，其中的范数$|\cdot|$如下表中所示，则有&lt;/p&gt;
&lt;p&gt;| $| \cdot |$  |  $|\pmb \Delta|$的取值  | $\alpha=1$的“当且仅当”条件 |
| $q$-Frobenuis范数 | $\left( \sum_{ij}|\Delta_{ij}|^q  \right)^{1/q}$ | $p\in\{1,q,\infty\}$|
| $q$-谱范数 |  奇异值的$L_q$范数 |  $p\in \{1,2,\infty\}$|
| $(L_q,L_r)-$诱导范数 |  $\max_{\pmb \beta}\frac{|\pmb \Delta \pmb \beta|_r}{|\beta|_q} $ | $p\in \{1,r,\infty\}$ |&lt;/p&gt;
&lt;p&gt;定理$\ref{thm:RO_Reg}$是&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0377221717302734&#34;&gt;Bertsimas and Copenhaver, 2018&lt;/a&gt;的文章中给出的基于上述两个问题的一般化回答。定理中的（1）表明一般来说我们都能用正则项的形式将鲁棒问题的取值控制住，但一般来说两者并不是完全一致的（文章中也给出了一些详细的例子来佐证）；而（2）则给出了鲁棒性=正则性，即（1）中的$\alpha=1$的“当且仅当”条件。比如这其中的$q$-Frobenuis范数情形，其中$p=1$和$q=2$的时候就对应了我们前面的$\eqref{equ:LASSO}$和$\eqref{equ:RLS}$。表中的其他内容则表明类似结论也可以被推广到其它矩阵范数上。&lt;/p&gt;
&lt;h2 id=&#34;基于对抗样本adversarial-samples的鲁棒学习robust-learning&#34;&gt;基于对抗样本（Adversarial Samples）的鲁棒学习（Robust Learning）&lt;/h2&gt;
&lt;p&gt;本节我们将前一节仅仅针对回归模型的思路拓展，介绍在更一般的机器学习任务里，如果出现所谓的对抗样本，如何训练我们的模型，和相应的样本复杂度（相比于非对抗情境的机器学习任务）。我们主要考虑如下优化问题：
$$
\min_{\pmb \theta} \frac{1}{N}\sum_{i=1}^N \max_{\pmb x_i&#39;\in \mathcal{U}_i}g(\pmb \theta,\pmb x_i&#39;,y_i).
$$
其中，$g(\pmb theta,\pmb x_i&#39;,y_i)$ 是一个损失函数（和前一节不同，这里的$g$不一定要是某个范数了），比如说，现在我们也可以将它看成一个基于人工神经网络（artifical neural network）的损失函数。$\pmb \theta$就是我们要优化的参数，$(\pmb x_i,y_i)$是一个数据点，$\mathcal{U}_i$则是针对每个数据点定义的一个不确定集。我们注意到，这个最优化问题可以利用常见的交替方向法来求解。具体来说，算法每一步中我们将$\pmb \theta$的值固定，然后我们通过如下方式计算$\pmb \Delta_{x_i}$:
$$
\pmb \Delta_{x_i} = \arg\max_{\pmb \Delta:\pmb x_i+\pmb \Delta\in \mathcal{U}_i} g(\pmb \theta,\pmb x_i+\pmb \Delta,y_i). \label{equ:exact delta}
$$&lt;/p&gt;
&lt;p&gt;当然这个优化问题$\eqref{equ:exact delta}$一般来说是难以直接求得的（我们这里没有限制$g$），那么如果我们认为$g$是光滑的，就可以求解一个一阶泰勒展开的近似问题：
$$
\pmb  \Delta_{x_i}&#39; = \arg\max_{\pmb \Delta:\pmb x_i+\pmb \Delta\in \mathcal{U}_i} g(\pmb \theta,\pmb x_i,y_i) +\left&amp;lt; \nabla_{\pmb x} g(\pmb \theta,\pmb x,y_i),\pmb \Delta \right&amp;gt; . \label{equ:approx delta}
$$&lt;/p&gt;
&lt;p&gt;根据式\eqref{equ:approx delta}我们就可以在固定$\pmb \theta$值的情况下更新$\pmb \Delta_{x_i}&#39;$，也即$\pmb x_i&#39;=\pmb x_i+\pmb \Delta_{x_i}&#39;$。假设算法每步一共更新了$mb$次，那么在固定数据点集$\{ (\pmb x_i&#39;,y_i) \}_{i=1}^{|mb|}$的情况下，我们就可以对$\pmb \theta$采用一步批梯度下降法（mini-batch gradient descent）的迭代。如此，我们就描述了我们的对抗训练（adversarial training）算法，算法的具体实现细节和一些数值实例可见&lt;a href=&#34;https://arxiv.org/abs/1511.05432&#34;&gt;Shaham et al., 2018&lt;/a&gt;的工作。本节我们接着讨论对抗训练中的一些复杂度问题，我们将仅限于讨论分类（classification）问题。&lt;/p&gt;
&lt;p&gt;我们先定义分类错误（classification error）为：对分布$\mathcal{P}: \mathbb{R}^d \times \{\pm 1\} \rightarrow \mathbb{R} $,分类器（classifier）$f:\mathbb{R}\rightarrow \{\pm 1\}$的分类错误率$e$为$e=\mathbb{P}_{(\pmb x,y)\sim \mathcal{P}}[f(\pmb x)\neq y] $. 也就是分类错误率其实就是分类器出错的概率。然后我们将这个定义拓展，定义所谓的$\mathcal{U}$-鲁棒分类错误率：
对分布$\mathcal{P}:\mathbb{R}^d\times\{\pm 1\} \rightarrow \mathbb{R} $,定义$&lt;br&gt;
\mathcal{U}:\mathbb{R}^d\rightarrow \mathbf{P}(\mathbb{R}^d)$（$\mathbf{P}(\mathbb{R}^d)$表示$\mathbb{R}^d$的支撑集，即所有子集的集合）。分类器（classifier）$f:\mathbb{R}\rightarrow \{\pm 1\}$的$\mathcal{U}$-鲁棒分类错误率$e$为$e=\mathbb{P}_{(\pmb x,y)\sim \mathcal{P}}[\exists \pmb x&#39;\in \mathcal{U}(\pmb x):  f(\pmb x&#39;)\neq y] $. &lt;a href=&#34;https://papers.nips.cc/paper/2018/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html&#34;&gt;Schmidt et al., 2018&lt;/a&gt;的文章在$\mathcal{P}$为高斯分布和伯努利分布的假设下研究了$\mathcal{U}(\pmb x)=\mathcal{U}^{\epsilon}_\infty(x)=\{x&#39;\in \mathbb{R}^d | |x&#39;-x|_\infty \leq \epsilon \}. $&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;
{theorem}{鲁棒分类样本复杂度定理&lt;a href=&#34;https://papers.nips.cc/paper/2018/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html&#34;&gt;Schmidt et al., 2018&lt;/a&gt; }{Sample Complexity}
\label{thm:SCbound}&lt;/p&gt;
&lt;p&gt;(1) 高斯模型：令$( x_1,y_1),\ldots,( x_n,y_n)$是从$\mathcal{N}(\theta^*,\sigma)$中独立同分布抽样得到的样本，其中高斯分布的参数满足$|\theta^*|_2=\sqrt{d},\sigma\leq c \cdot d^{1/4}$（$c&amp;gt;0$是一个常数）.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有高概率$f_{\hat{w}}=y_1\cdot x_1$的分类错误率不超过1%。&lt;/li&gt;
&lt;li&gt;如果取$\epsilon$使得$\frac{1}{4}d^{-1/4}\leq \epsilon \leq \frac{1}{4}$，那么如果$n\geq \epsilon^2 \sqrt{d}$，有高概率$f_{\hat{w}}=\frac{1}{n}\sum_{i=1}^n y_ix_i$的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率不超过1%。&lt;/li&gt;
&lt;li&gt;基于样本$( x_1,y_1),\ldots,( x_n,y_n)$，对任意0/1分类器$f_n$，如果$n\leq c&#39;\frac{\epsilon^2\sqrt{d}}{\log d}$（$c&#39;&amp;gt;0$是一个常数），期望的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率至少为$\frac{1}{2}(1-1/d)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(2) 伯努利模型：存在参数$\theta^*\in \{\pm 1\}^d,\tau&amp;gt;0$，使得抽样机制定义为先均匀地抽样$y\in \{-1,1\}$，再对$\pmb x$的每个坐标独立以$1/2+\tau$概率抽得$y\cdot\theta_i^*$，以$1/2-\tau$概率抽得$-y\cdot\theta_i^*$。令$\tau\geq c\cdot d^{-1/4}$，$\epsilon&amp;lt;3\tau&amp;lt;1$, $\gamma&amp;lt;1/2$。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有高概率$f_{\hat{w}}=y_1\cdot \pmb x_1$的分类错误率不超过1%。&lt;/li&gt;
&lt;li&gt;如果取$\epsilon$使得$\frac{1}{4}d^{-1/4}\leq \epsilon \leq \frac{1}{4}$，那么如果$n\geq \epsilon^2 \sqrt{d}$，有高概率$f_{\hat{w}}=y_1\cdot T(\pmb x_1)$ 的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率不超过1%。$T$是一个非线性算子，使得$\pmb x$的每个非负坐标取$1$，负坐标取$-1$。&lt;/li&gt;
&lt;li&gt;基于样本$( x_1,y_1),\ldots,( x_n,y_n)$，对任意0/1分类器$f_n$，如果$n\leq c&#39;\frac{\epsilon^2\gamma^2 d}{\log d/\gamma}$（$c&#39;&amp;gt;0$是一个常数），期望的$\mathcal{U}_{\infty}^{\epsilon}$-鲁棒分类错误率至少为$\frac{1}{2}-\gamma$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;定理$\ref{thm:SCbound}$给我们最大的一个启示就是看起来对于分类问题，鲁棒分类错误是和样本遵循的分布高度相关的。具体来说，在高斯模型中，我们对于常规的分类错误来说只需要一个数据点就可以做到高概率的完美分类，但对于鲁棒分类错误我们至少需要$\sqrt{d}$阶的样本数量才能做到比较好的分类（这是由线性分类器对于鲁棒分类错误的样本复杂度和鲁棒分类错误的样本复杂度下界放在一起说明的）。而作为对比，对于伯努利模型，除了对于常规的分类错误来说同样一个数据点就可以做到高概率的完美分类，对于鲁棒分类错误来说用一个非线性的分类器也只需要一个数据点就可以做到完美分类。而在高斯模型中，下界保证了任何非线性的分类器在理论上也无法突破$\sqrt{d}$样本数量。&lt;/p&gt;
&lt;p&gt;这便是&lt;a href=&#34;https://papers.nips.cc/paper/2018/hash/f708f064faaf32a43e4d3c784e6af9ea-Abstract.html&#34;&gt;Schmidt et al., 2018&lt;/a&gt;的工作主要要说明的，为此它们利用了两个著名的开放分类数据集，MNIST和CIFAR10，利用卷积神经网络和前面提到的对抗训练算法，它们发现基于前者训练出来的分类器，在测试数据集上利用$\mathcal{U}_{\infty}^{\epsilon}$的定义扰动数据，可以达到很低的鲁棒分类错误率。而对于CIFAR，虽然还能保持一般意义上很低的分类错误率，却有很高的鲁棒分类错误率。基于前面的结果，一种可以接受的解释就是MNIST这个数据集更接近伯努利模型，而CIFAR10更接近高斯模型。另外，我们也可以体会到实际上神经网络模型对于标准意义上的分类错误能达到很高的标准，但往往对于鲁棒分类错误就不那么在行了。&lt;/p&gt;
&lt;h2 id=&#34;神经网络neural-network中的分布鲁棒优化&#34;&gt;神经网络（Neural Network）中的分布鲁棒优化&lt;/h2&gt;
&lt;p&gt;本节我们讨论上一节所引入的问题的一种更高级的尝试，利用分布式鲁棒优化进行对抗训练，具体来说我们主要介绍&lt;a href=&#34;https://arxiv.org/abs/1710.10571&#34;&gt;Sinha et al., 2018&lt;/a&gt;的工作。注意，和前面不同的是，这里的分布式鲁棒优化里的不确定集不再是“确定性”的了，而是成了一个描述“分布”（测度）的集合。因此，我们相当于要考虑这样一个以对抗训练为目标的优化问题
$$
\min_{\pmb \theta\in \Theta} \max_{P\in\mathcal{P}}\mathbb{E}_P[g(\pmb \theta;\pmb Z)]. \label{equ:DRO}
$$
其中，$\pmb \theta$仍然是训练模型的参数，$\mathcal{P}$就是一个描述分布/测度的不确定集，而$\pmb Z$为将所有数据$Z=[\pmb X;\pmb y]$简写起来的形式。这边一个很关键的概念就是近些年机器学习和优化领域都十分热门的Wasserstein度量，令我们考虑的数据集$\pmb Z\in \mathcal{Z}$且$\mathcal{Z}$是实数域的一个子集，如果存在一个“价格”函数$c:\mathcal{Z}\times\mathcal{Z}\rightarrow \mathbb{R}_+ \cup \{\infty\}$,那么对任意两个取值在$\mathcal{Z}$上的概率测度$P,Q$，我们有$P,Q$之间的Wasserstein距离为
$$
W_c(P,Q):=\inf_{\mu\in \Gamma(P,Q) } \int_{\mathcal{Z}\times\mathcal{Z}} c(p,q)d\mu(p,q),
$$
其中$\Gamma(P,Q)$是所有取值在$\mathcal{Z}\times\mathcal{Z}$上的边缘分布为$P$和$Q$的概率测度的集合。于是，我们考虑我们的不确定集用Wasserstein度量定义，即$\mathcal{P}=\{P:W_c(P,P_0)\leq \rho\}$。然后我们可以证明，考虑问题(\ref{equ:DRO})的拉格朗日松弛形式，我们有如下等价关系（松弛因子$\gamma&amp;gt;0$）：
$$
\min_{\pmb \theta\in \Theta}\underbrace{\max_{P}\mathbb{E}_P[g(\pmb \theta;\pmb Z)-\gamma W_c(P,P_0)]}_{F(\pmb \theta)}=\min_{\pmb \theta\in \Theta} \mathbb{E}_{P_0}[\underbrace{\max_{\pmb Z&#39;\in \mathcal{Z}} \left(g(\pmb \theta;\pmb Z&#39;) -\gamma c(\pmb Z&#39;,\pmb Z)\right)}_{\phi_\gamma(\pmb \theta;\pmb Z)} ]. \label{equ:DRO_relaxed}
$$
然后，利用$P_0$的样本得到的经验分布$\hat P_n$代替$P_0$，我们需要求解优化问题：
$$
\min_{\pmb \theta\in \Theta}\mathbb{E}_{\hat P_n}[\phi_\gamma(\pmb \theta;\pmb Z) ]. \label{equ:DRO_empirical}
$$&lt;/p&gt;
&lt;p&gt;对此，&lt;a href=&#34;https://arxiv.org/abs/1710.10571&#34;&gt;Sinha et al., 2018&lt;/a&gt;给出了基于随机梯度下降法（SGD）的算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输入：分布$P_0$的样本，$\Theta,\mathcal{Z}$，算法步长$\{\alpha_t&amp;gt;0\}_{t=0}^{T}$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;for&lt;/strong&gt; $t=0,\ldots,T-1$ &lt;strong&gt;do&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;抽样$\pmb Z^t\sim P_0$且找到$g(\pmb \theta^t;\pmb Z)-\gamma c(\pmb Z,\pmb Z^t)$的一个（局部）$\epsilon$-最优解$\pmb Z_t&#39;$&lt;/li&gt;
&lt;li&gt;$\pmb \theta^{t+1}\leftarrow \text{Proj}_{\Theta}(\pmb \theta^t-\alpha_t\nabla_{\pmb \theta}) g( \pmb \theta^t;\pmb Z_t&#39;) $&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.10571&#34;&gt;Sinha et al., 2018&lt;/a&gt;证明，在假设$c$是连续，且$c(\cdot,\pmb Z)$对任意$\pmb Z\in \mathcal{Z}$是1-强凸，并且$g$对于$\pmb \theta，\pmb Z$都是关于系数$L_{\pmb \theta\pmb \theta},L_{\pmb \theta\pmb Z},L_{\pmb Z\pmb Z},L_{\pmb Z\pmb \theta}$和$L_2$范数李普希茨（Lipschitz）连续的，算法对于问题(\ref{equ:DRO_relaxed})的全局最优值（$g$是凸的）/局部最优值的收敛速度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理&lt;/strong&gt;
{theorem}{非凸SGD的分布式鲁棒优化收敛性定理&lt;a href=&#34;https://arxiv.org/abs/1710.10571&#34;&gt;Sinha et al., 2018&lt;/a&gt; }{nonconvexSGD}
%\label{thm:nonconvexSGD}&lt;/p&gt;
&lt;p&gt;假设$\mathbb{E}[|\nabla F(\pmb \theta)-\nabla_{\pmb \theta}\phi_\gamma(\pmb \theta;\pmb Z) |_2^2]\leq \sigma^2$, $\Theta=\mathbb{R}^d$, 取$\Delta_F\geq F(\pmb \theta^0)-\min_{\pmb \theta} F(\theta)$, $L_\phi:=L_{\pmb \theta\pmb \theta}+\frac{L_{\pmb \theta \pmb Z}L_{\pmb Z \pmb \theta}}{\gamma-L_{\pmb Z\pmb Z}}$, $\alpha_t\equiv \sqrt{\frac{2\Delta_F}{L_\phi \sigma^2 T}}$。我们的算法保证
$$
\frac{1}{T}\sum_{t=1}^T \mathbb{E}\left[|\nabla F(\pmb \theta^t) |_2^2  \right] -\frac{2L_{\pmb \theta\pmb Z}^2}{\gamma-L_{\pmb Z\pmb Z}} \epsilon\leq \sigma\sqrt{\frac{8L_\phi \Delta_F}{T}}.
$$
{theorem}&lt;/p&gt;
&lt;p&gt;这个收敛性定理成立的 关键还是在于我们对于$g$有光滑性假设，也就是说这里的分析对于常见的光滑的神经网络损失函数都是成立的。接下来，我们考虑理论上在鲁棒情形下这个算法的泛化（generalization）能力（对应前一节的鲁棒分类错误率）。事实上，&lt;a href=&#34;https://arxiv.org/abs/1710.10571&#34;&gt;Sinha et al., 2018&lt;/a&gt;证明了如下结论：对任意$\theta\in \Theta$，
$$
\max_{P:W_c(P,P_0)\leq \rho}\mathbb{E}_P[g(\pmb \theta;\pmb Z)]\leq \gamma\rho+\mathbb{E}_{\hat P_n}[\phi_\gamma(\pmb \theta;\pmb Z)]+O(1/\sqrt{n}).
$$
具体的分析仍然是基于Monge映射$T_\gamma(\pmb \theta;\pmb Z_0):=\arg\max_{\pmb Z\in \mathcal{Z}}\{ g(\pmb \Theta;\pmb Z) - \gamma c(\pmb Z,\pmb Z_0) \}$的光滑性，这里我们不再展开讨论了，有兴趣的读者可以参阅他们的文章。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>鲁棒优化模型求解（Model implementation）</title>
      <link>https://allenz-me.github.io/RoSite/post/8.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3/</link>
      <pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/8.%E9%B2%81%E6%A3%92%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3/</guid>
      
        <description>&lt;p&gt;汤勤深，熊鹏&lt;/p&gt;
&lt;p&gt;随着鲁棒优化方法的价值不断地被学界和业界发现，出现了越来越多的语言包支持鲁棒优化模型的直接求解。其中，有基于Julia的JuMPeR &lt;a href=&#34;https://epubs.siam.org/doi/abs/10.1137/15M1020575?journalCode=siread&#34;&gt;(Dunning, Huchette, and Lubin, 2017)&lt;/a&gt;，基于C语言的ROC &lt;a href=&#34;https://pubsonline.informs.org/doi/10.1287/mnsc.2017.2952&#34;&gt;(Bertsimas, Sim, and Zhang, 2019)&lt;/a&gt;，基于Matlab的&lt;a href=&#34;xprog.weebly.com&#34;&gt;XProg&lt;/a&gt;和YALMIP以及XProg的升级版RSOME。JUMPeR和YALMIP主要支持经典鲁棒优化模型，而ROC和RSOME既支持传统鲁棒优化模型也支持分布式鲁棒优化模型，并且还可以比较简洁地定义各种决策规则。在本章中，我们将简要介绍如何在JUMPeR和YALMIP上对鲁棒优化模型求解而着重介绍如何用RSOME求解不同形式的鲁棒优化模型。由于编码原因，本章代码块部分中的$\xi$由$xi$进行表示。&lt;/p&gt;
&lt;h2 id=&#34;鲁棒模型在jumper上的实现implementation-on-jumper&#34;&gt;鲁棒模型在JuMPeR上的实现（Implementation on JuMPeR）&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;jumper.readthedocs.io/en/latest/jumper.html&#34;&gt;JuMPeR&lt;/a&gt;全称Robust Optimization with JuMP。是基于Julia中JuMP而开发的一个用来求解鲁棒优化模型的语言包。 &lt;a href=&#34;julialang.org/&#34;&gt;Julia&lt;/a&gt;是一门免费和开源的编程语言，于2018年8月1日正式发布。&lt;/p&gt;
&lt;p&gt;JuMPeR可以处理大部分的经典鲁棒优化问题：
$$
\begin{aligned}
\min \ &amp;amp; g( \pmb x)\label{model::JuMPeR RO}\\\
\mathbf{s.t.}\ &amp;amp;  f_i( \pmb x,\tilde{\pmb \xi}) \leq 0,, \forall \tilde{\pmb \xi} \in \mathcal{U}:= {\tilde{\pmb \xi} : h( \pmb \xi) \leq 0}, i \in [I],
\end{aligned}
$$
其中，在JuMPeR中，鲁棒优化模型不能包含以下几种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不能有二次项，也即不能有变量乘变量（$x\mbox{*}y$）,不确定项乘不确定项（$\tilde{xi}\mbox{*}\tilde{\varepsilon}$）。但是允许不确定项和变量相乘（$x\mbox{*}\tilde{\xi}$）。&lt;/li&gt;
&lt;li&gt;目标函数中不能包含不确定项。如果有的话，通过引入辅助变量将其转为约束条件。
在有不确定性的约束中不支持&lt;a href=&#34;julialang.org/blog/2017/08/dsl&#34;&gt;宏（Macros）&lt;/a&gt;，所以必须使用“addConstraint”。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用JuMPeR时，先用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    using JuMPeR
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;申明调用JuMPeR，并且用&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    m = RobustModel()
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;来定义模型$m$。之后可以定义变量“@defVar()”、约束“addConstraint()”、不定集“@defUnc()”，或者设定目标函数“setObjective()”。举个栗子：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例1&lt;/strong&gt;
考虑如下鲁棒优化问题：
$$
\begin{array}{rll}
\max\ &amp;amp; x_1 + x_2&amp;amp;\\\
\mathrm{s.t.}\ &amp;amp; \xi_1x_1 + x_2 \leq 2 &amp;amp; \xi_1 \in [0.3, 0.5]\\\
&amp;amp; \xi_2x_1 + x_2 \leq 6 &amp;amp; \xi_2 \in [0,2]\\\
&amp;amp; x_1, x_2 \geq 0,&amp;amp;
\end{array}
$$
其JuMPeR程序为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-julia&#34; data-lang=&#34;julia&#34;&gt;        &lt;span class=&#34;c&#34;&gt;# 调用JuMPeR&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;using&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;JuMPeR&lt;/span&gt;
    
        &lt;span class=&#34;c&#34;&gt;# 定义鲁棒模型$m$&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RobustModel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
        
        &lt;span class=&#34;c&#34;&gt;# 定义决策变量$x_1, x_2$&lt;/span&gt;
        &lt;span class=&#34;nd&#34;&gt;@defVar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        
        &lt;span class=&#34;c&#34;&gt;# 定义不确定参数$\xi_1, \xi_2$&lt;/span&gt;
        &lt;span class=&#34;nd&#34;&gt;@defUnc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.3&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;nd&#34;&gt;@defUnc&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi2&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        
        &lt;span class=&#34;c&#34;&gt;# 设定目标函数&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;setObjective&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;ss&#34;&gt;:Max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
        
        &lt;span class=&#34;c&#34;&gt;# 添加约束条件&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;addConstraint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi_1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;addConstraint&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi_2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;6.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        
        &lt;span class=&#34;c&#34;&gt;# 求解鲁棒模型&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;status&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;solveRobust&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
        
        &lt;span class=&#34;c&#34;&gt;# 输出解&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getValue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]))&lt;/span&gt;  &lt;span class=&#34;c&#34;&gt;# = 2.6666&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;getValue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]))&lt;/span&gt;  &lt;span class=&#34;c&#34;&gt;# = 0.6666&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;由此，可以看出，类似JuMPeR这种编程语言包，已经最大化地节约了编程时间。只要模型满足一定的条件（标准型），即可直接输入进行求解。然而，JuMPeR暂时只能对经典鲁棒优化问题求解。而对于分布鲁棒优化问题，则需要先手动求对偶，化成JuMPeR可以识别的形式之后才可直接编程求解。同样的，接下来要介绍的YALMIP也存在这个问题。不过，这些语言包，已经大大减少了编程时间。&lt;/p&gt;
&lt;h2 id=&#34;鲁棒优化在yalmip和cvx上的实现&#34;&gt;鲁棒优化在YALMIP和CVX上的实现&lt;/h2&gt;
&lt;p&gt;[YALMIP]](&lt;a href=&#34;https://yalmip.github.io/&#34;&gt;https://yalmip.github.io/&lt;/a&gt;)和&lt;a href=&#34;http://cvxr.com/cvx/&#34;&gt;CVX&lt;/a&gt;都是依托于MATLAB而建的优化语言包。旨在用最直观简洁的语言进行优化模型的编程和求解。其中，YAPMIP主要由林雪平大学（Linköping University）的Johan Löfberg教授，而CVX由斯坦福大学的Stephen P .Boyd和Michael C. Grant开发和维护。除YALMIP自有部分优化器外，二者主要都通过调用开源（比如：）或者商业优化器对模型进行求解。这两个优化语言包功能都非常强大，各有其长短。感兴趣的读者可以到官网&lt;a href=&#34;https://yalmip.github.io/&#34;&gt;https://yalmip.github.io/&lt;/a&gt;和&lt;a href=&#34;http://cvxr.com/cvx/&#34;&gt;http://cvxr.com/cvx/&lt;/a&gt;进行了解。现阶段，YALMIP支持经典鲁棒优化模型（当然模型本身必须是凸问题），而如果要用CVX得化成相应的LP，SOCP，或者SDP才能求解。在这一节中，我们主要介绍如何用YAPMIP这个语言包进行经典鲁棒模型的求解。&lt;/p&gt;
&lt;p&gt;YALMIP可以直接处理以下鲁棒优化问题：
$$
\begin{aligned}
\min \max_{ \pmb \xi}\ &amp;amp; g( \pmb x,\tilde{\pmb \xi}) \label{model::YALMIP RO} \\\
\mathbf{s.t.}\ &amp;amp;  f_i( \pmb x,\tilde{\pmb \xi}) \leq 0,, \forall \tilde{\pmb \xi} \in \mathcal{U}:= {\tilde{\pmb \xi} : h(\tilde{\pmb \xi}) \leq 0}, i \in [I],
\end{aligned}
$$
其中，约束和不确定集$\mathcal{U}$需满足以下几种情况之一：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;给定$ \pmb x$，每一个约束（elementwise constraints）都仿射依赖于不确定变量$\tilde{\pmb \xi}$，并且不确定集为多面（polytopic）或者锥（Conic）集。&lt;/li&gt;
&lt;li&gt;每一个约束都仿射依赖于$\tilde{\pmb \xi}$，并且$\tilde{\pmb \xi}$在一个范数球（Norm-ball, $p = 1,2, \infty$）。&lt;/li&gt;
&lt;li&gt;约束条件为锥约束并且仿射依赖于$\tilde{\pmb \xi}$，而不确定集为多面集。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外YALMIP在还有某些特殊条件下适用。详情可参考&lt;a href=&#34;https://yalmip.github.io/tutorial/robustoptimization/&#34;&gt;https://yalmip.github.io/tutorial/robustoptimization/&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;YALMIP通过sdpvar来定义变量，uncertain来定义不确定集，optimize来进行问题求解（默认为最小化问题）。接下来，我们举两个简单的栗子来阐述如何在YALMIP上进行鲁棒优化模型的求解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例2&lt;/strong&gt; 考虑如下简单鲁棒优化问题：
$$
\begin{array}{rl}
\max &amp;amp; x \\\
\mathbf{s.t.} &amp;amp;  x + \xi \leq 1,, \forall \xi\in[-0.5, 0.5].
\end{array}
$$
此问题的YALMIP的程序如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    sdpvar x \xi
    F = [x + \xi &amp;lt;= 1];
    W = [-0.5 &amp;lt;= \xi &amp;lt;= 0.5, uncertain(w)];
    objective = -x;
    sol = optimize(F + W,objective)
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;对于不确定集为锥的问题，亦可用类似的方法求解：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例3&lt;/strong&gt; 考虑如下鲁棒锥优化问题：
$$
\begin{array}{rl}
\max &amp;amp; x \\\
\mathbf{s.t.} &amp;amp;  x + \tilde{\pmb \xi}^{\prime}  \pmb{1} \leq 1,, \forall \tilde{\pmb \xi}\in \mathcal{U}.
\end{array}
$$
其中 $\mathcal{U} = {\tilde{\pmb \xi}: |\tilde{\pmb \xi}|_2 \leq 1/\sqrt{2}}$。
此问题的YALMIP的程序如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;    sdpvar x \xi(2,1)
    F = [x + sum(\xi) &amp;lt;= 1];
    W = [norm(\xi) &amp;lt;= 1/sqrt(2), uncertain(\xi)];
    objective = -x;
    sol = optimize(F + W,objective)
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;鲁棒模型在rsome上的实现&#34;&gt;鲁棒模型在RSOME上的实现&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://sites.google.com/view/rsome&#34;&gt;RSOME&lt;/a&gt;全称Robust Stochastic Optimization Modeling Environment，是一个针对MATLAB的优化建模工具包，可以在Windows，macOS，以及Linux操作系统下运行。该软件工具包为用户提供了丰富便捷的语法环境，可以直观高效地处理各类优化模型，如经典的随机规划和鲁棒优化模型，以及分布鲁棒优化和鲁棒随机优化模型等。目前版本的RSOME内置了CPLEX 12.8 的求解器，并且可以根据用户需求调用GUROBI求解器。更多详情和下载资源请参考官网&lt;a href=&#34;https://sites.google.com/view/rsome&#34;&gt;https://sites.google.com/view/rsome&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;rsome建模求解的基本步骤&#34;&gt;RSOME建模求解的基本步骤&lt;/h3&gt;
&lt;p&gt;RSOME工具包提供了灵活的函数和语法环境来定义各类优化模型。具体的建模和求解步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用rsome函数创建一个优化模型对象&lt;/li&gt;
&lt;li&gt;为优化模型创建随机变量和决策变量&lt;/li&gt;
&lt;li&gt;创建和定义模糊集合&lt;/li&gt;
&lt;li&gt;定义动态决策的近似表达式&lt;/li&gt;
&lt;li&gt;定义目标函数和约束条件&lt;/li&gt;
&lt;li&gt;求解模型和返回最优解&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们首先用一个简单的凸优化问题来演示使用RSOME工具包建模求解的基本步骤。
&lt;strong&gt;示例 4&lt;/strong&gt;
&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;介绍了一个经典的投资组合优化（Portfolio optimization）问题：
$$
\begin{array}{rl}
\max &amp;amp;\sum\limits_{i=1}^n p_i x_i - \phi\sum\limits_{i=1}^n\sigma_i^2 x_i^2  \\\
\text{s.t.} &amp;amp;\sum\limits_{i=1}^n x_i = 1\\\
&amp;amp;x_i \geq 0, \forall i = 1, 2, &amp;hellip;, n
\end{array}
$$
这个模型考虑了$n=150$支股票。对第$i$支股票，回报率的期望是$p_i$，标准差是$\sigma_i$。我们用$x_i$定义决策变量代表每支股票的投资比例，并用参数$\phi=5$来平衡投资的回报期望和风险。这个投资组合优化问题可以写成下面的代码。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-matlab&#34; data-lang=&#34;matlab&#34;&gt;    &lt;span class=&#34;c&#34;&gt;%% 定义模型参数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                    &lt;span class=&#34;c&#34;&gt;% 股票支数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.15&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                 &lt;span class=&#34;c&#34;&gt;% 回报率期望&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;450&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;c&#34;&gt;% 回报率标准差&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;phi&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                    &lt;span class=&#34;c&#34;&gt;% 平衡参数&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建模型和决策变量&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rsome&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;投资组合优化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;              &lt;span class=&#34;c&#34;&gt;% 创建一个模型model&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                      &lt;span class=&#34;c&#34;&gt;% 定义决策变量x&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 定义目标函数和约束条件&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;#39;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;phi&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sumsqr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;     &lt;span class=&#34;c&#34;&gt;% 最大化目标函数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                  &lt;span class=&#34;c&#34;&gt;% 定义约束条件 &lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                       &lt;span class=&#34;c&#34;&gt;% 定义变量边界&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 求解模型和返回最优解&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;solve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                &lt;span class=&#34;c&#34;&gt;% 求解模型&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;obj&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                            &lt;span class=&#34;c&#34;&gt;% 最优目标值&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;X&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;                                   &lt;span class=&#34;c&#34;&gt;% x的最优解&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这个投资组合优化模型被转化成一个二阶锥规划问题并由内置的CPLEX求解器求解，得到的最优值是 $1.170$。在建模和求解过程中，我们提醒读者注意：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;就像MATLAB中的其他程序应用，RSOME工具包在处理向量和矩阵时的效率会远远高于循环。因此在这个例子中，我们把决策变量$x_i$创建成一个向量$ \pmb{x}$，并用矩阵运算来定义目标函数和约束条件。&lt;/li&gt;
&lt;li&gt;MATLAB中的绝大部分矩阵运算符号和法则也适用于RSOME模型的表达式。同样的，我们也需要保证运算中的矩阵形状匹配。&lt;/li&gt;
&lt;li&gt;RSOME工具包提供了一系列凸函数，比如绝对值$\texttt{abs}$，范数$\texttt{norm}$，和这个示例中的平方和$\texttt{sumsqr}$等。在模型中使用凸函数时，必须保证该模型符合凸优化的定义，否则程序会出现错误信息。
{example}&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;用rsome定义事件式分布模糊集合&#34;&gt;用RSOME定义事件式分布模糊集合&lt;/h3&gt;
&lt;p&gt;RSOME利用在\ref{RSO}中介绍的事件式分布模糊集合$\eqref{eventwise_as}$来表达随机变量的概率分布情况。和之前介绍的软件工具相比，这个事件式分布模糊集合更加的通用，因此我们可以使用RSOME方便地建立各类鲁棒优化和随机规划的模型，比如下面的例子。
&lt;strong&gt;示例5&lt;/strong&gt;
&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/opre.1030.0065?journalCode=opre&#34;&gt;Bertsimas and Sim 2004&lt;/a&gt;介绍的投资组合优化（Portfolio optimization）问题可以写成一个经典鲁棒优化模型：
$$
\begin{array}{rl}
\max&amp;amp;\displaystyle \min_{\tilde{\pmb \xi}\in\mathcal{U}}\sum_{i=1}^n(p_i - \sigma_i\tilde{\xi}_i)x_i  \\\
\text{s.t.} &amp;amp;\sum_{i=1}^n x_i = 1\\\
&amp;amp;x_i \geq 0, \forall i = 1, 2, &amp;hellip;, n
\end{array}
$$
在该模型中，随机变量$\tilde{\pmb \xi}$代表实际股票回报率和期望值间的偏差。这个随机被约束在一个预算不确定集（budget uncertainty set）$\mathcal{U}$中，其表达式如下：
$$
\begin{align}
\mathcal{U} = \left\{\tilde{\pmb \xi}||\tilde{\pmb \xi}|_{\infty}\leq 1, |\tilde{\pmb \xi}|_1\leq \Gamma\right\}
\end{align}
$$
其中$\Gamma$代表不确定性预算（budget of uncertainty）。以上的预算不确定集可以用事件式分布模糊集合中的支撑集合来表示，这个经典鲁棒优化模型因而由以下代码建立。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-matlab&#34; data-lang=&#34;matlab&#34;&gt;    &lt;span class=&#34;c&#34;&gt;%% 定义模型参数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                    &lt;span class=&#34;c&#34;&gt;% 股票支数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.15&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;150&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                 &lt;span class=&#34;c&#34;&gt;% 回报率期望&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.05&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;450&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;sqrt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;    &lt;span class=&#34;c&#34;&gt;% 回报率标准差&lt;/span&gt;
    &lt;span class=&#34;nb&#34;&gt;gamma&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                  &lt;span class=&#34;c&#34;&gt;% 不确定性预算&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建模型，随机变量和决策变量&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rsome&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;投资组合鲁棒优化&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;          &lt;span class=&#34;c&#34;&gt;% 创建一个模型model&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                      &lt;span class=&#34;c&#34;&gt;% 定义随机变量z&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                      &lt;span class=&#34;c&#34;&gt;% 定义决策变量x&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建和定义分布模糊集合&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                        &lt;span class=&#34;c&#34;&gt;% 创建分布模糊集合&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;suppset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Inf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;...&lt;/span&gt;
              &lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Gamma&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;           &lt;span class=&#34;c&#34;&gt;% 定义支撑集信息&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                              &lt;span class=&#34;c&#34;&gt;% 传递模糊信息到模型&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 定义目标函数和约束条件&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sigma&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*\&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;           &lt;span class=&#34;c&#34;&gt;% 最大化目标函数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                  &lt;span class=&#34;c&#34;&gt;% 定义约束条件 &lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                       &lt;span class=&#34;c&#34;&gt;% 定义变量边界&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 求解模型&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;solve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                &lt;span class=&#34;c&#34;&gt;% 求解模型&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;在这个例子中，模型目标是最大化最坏情况下的(p + sigma.*$\xi$)&#39;* x， 其中随机变量$\xi$被约束在一个多面（polyhedral）支撑集中。在只有支撑集信息被定义的情况下，该模型等价于一个经典的鲁棒优化问题。RSOME工具包帮助用户将这个鲁棒优化模型自动转化为一个线性规划标准型，并通过求解器求解，得到的最优值是$1.1771$。
example}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例6&lt;/strong&gt; {example} \label{newsvendor_example}
&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603&#34;&gt;Chen, Sim, and Xiong, 2020&lt;/a&gt;介绍的报童问题可以写成以下分布鲁棒优化模型：
$$
\begin{array}{rl}
\max&amp;amp;(p - c)\cdot x - \sup\limits_{\mathbb{P}\in\mathcal{F}}\mathbb{E}_{\mathbb{P}}[\max\left\{p\cdot(x - z), 0\right\}] \\\
\text{s.t.} &amp;amp;x \geq 0
\end{array}
$$
其中参数$p$和$c$分别是产品的销售价格和预定价格，决策变量$x$代表商品的预定量，随机变量$z$代表商品的需求。随机变量$z$的分布由一个基于Wasserstein距离的分布模糊集（Wasserstein ambiguity set）刻画。&lt;a href=&#34;https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2020.3603&#34;&gt;Chen, Sim, and Xiong, 2020&lt;/a&gt;证明了这个模糊集可以写成:
$$
\mathcal{F} = \left\{\mathbb{P} \in \mathcal{P}_0\left(\mathbb{R} \times [S]\right) \left\vert
\begin{array}{ll}
(\tilde{z},\tilde{s}) \sim \mathbb{P} &amp;amp; \\\
\mathbb{E}_{\mathbb{P}}[\rho(\tilde{z}, \hat{z}_{\tilde{s}}) \mid \tilde{s} \in [S]] \leq \theta &amp;amp;\\\
\mathbb{P}[\tilde{z} \in [0, \bar{Z}] \mid \tilde{s} = s]  = 1 &amp;amp;\forall s \in [S]  \\\
\mathbb{P}[\tilde{s} = s]  = 1/S &amp;amp; \forall s \in [S]  \\\
\end{array}
\right.
\right\}
$$
其中$\bar{Z}$是商品需求的上限， 而$\hat{z}_{s}$, $s=1, 2, 3, &amp;hellip;, S$代表随机变量$z$的历史经验数据（Empirical data）。这个模糊集定义了所有和经验数据的Wasserstein距离不大于常数$\theta$的所有分布函数，并且可以写成下面的事件式分布模糊集：
$$
\mathcal{G} = \left\{\mathbb{P} \in \mathcal{P}_0\left(\mathbb{R}^2 \times [S]\right)  \left\vert
\begin{array}{ll}
(\tilde{z}, \tilde{u}),\tilde{s}) \sim \mathbb{P} &amp;amp; \label{wass_as} \\\
\mathbb{E}_{\mathbb{P}}[\tilde{u} \mid \tilde{s} \in [S]] \leq \theta &amp;amp;\\\
\mathbb{P}[\tilde{z} \in [0, \bar{Z}], \rho(\tilde{z}, \hat{z}_{\tilde{s}})\leq \tilde{u} \mid \tilde{s} = s]  = 1 &amp;amp; \forall s \in [S]  \\\
\mathbb{P}[\tilde{s} = s]  = 1/S &amp;amp; \forall s \in [S]  \\\
\end{array}
\right.
\right\}
$$
基于上面的事件式分布模糊集，这个报童问题可以写成下面的RSOME程序。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-matlab&#34; data-lang=&#34;matlab&#34;&gt;    &lt;span class=&#34;c&#34;&gt;%% 定义模型参数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                             &lt;span class=&#34;c&#34;&gt;% 商品需求上限&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                  &lt;span class=&#34;c&#34;&gt;% 经验数据的数目&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;Zhat&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;               &lt;span class=&#34;c&#34;&gt;% 生成经验数据&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                &lt;span class=&#34;c&#34;&gt;% 销售价格&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                &lt;span class=&#34;c&#34;&gt;% 预定成本&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;theta&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                    &lt;span class=&#34;c&#34;&gt;% Wasserstein 距离&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建模型，随机变量和决策变量&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rsome&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;报童问题&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;              &lt;span class=&#34;c&#34;&gt;% 创建一个模型model&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                       &lt;span class=&#34;c&#34;&gt;% 定义随机变量z&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;u&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                       &lt;span class=&#34;c&#34;&gt;% 定义辅助随机变量u&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                     &lt;span class=&#34;c&#34;&gt;% 定义决策变量x&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建和定义分布模糊集合&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                 &lt;span class=&#34;c&#34;&gt;% 创建S个情景的分布模糊集&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;                                 
        &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;suppset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;...     &lt;/span&gt;
                     &lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Zhat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;% 定义每个情景s的支撑集&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;end&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exptset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;theta&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;           &lt;span class=&#34;c&#34;&gt;% 定义整体的期望值信息&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                            &lt;span class=&#34;c&#34;&gt;% 每个情景s的概率&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;probset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                   &lt;span class=&#34;c&#34;&gt;% 定义每个情景概率的值&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                          &lt;span class=&#34;c&#34;&gt;% 传递模糊信息到模型&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 定义目标函数和约束条件&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;...&lt;/span&gt;
              &lt;span class=&#34;n&#34;&gt;expect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maxfun&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})));&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;% 最大化目标函数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                   &lt;span class=&#34;c&#34;&gt;% 定义变量边界&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 求解模型&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;solve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                            &lt;span class=&#34;c&#34;&gt;% 求解模型&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;请注意以上程序中的函数\texttt{expect()}代表了表达式的最坏期望。这个例子体现了RSOME工具包的优势：我们可以直观便捷地定义分布模糊集的各类概率分布信息，比如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;我们用$\texttt{P(s).suppset()}$来分别定义每一个情景$\texttt{s}$下的支撑集；&lt;/li&gt;
&lt;li&gt;函数$\texttt{P.exptset()}$定义随机变量期望值的集合表达式；&lt;/li&gt;
&lt;li&gt;模糊集$\texttt{P}$的属性$\texttt{P.prob}$返回一个包含每个情景$\texttt{s}$概率的列向量，并且情景概率的集合可以通过$\texttt{P.probset()}$来定义。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由此可见，RSOME代码有着更好的可读性和通用性。用户可以轻松地将模糊集合的数学表达式用程序表达出来，因此能够更快更方便地求解和调试各类鲁棒优化模型。
{example}&lt;/p&gt;
&lt;h2 id=&#34;用rsome定义事件式近似法则&#34;&gt;用RSOME定义事件式近似法则&lt;/h2&gt;
&lt;p&gt;再前文\ref{sp_intro}中，我们提到在多阶段问题（Multi-stage problems）中，一些决策变量可以根据未来观测到的一部分随机变量的值而动态变化。这类”等待决策（wait-and-see decisions)“可能给建模和求解带来巨大的困难。因此在\ref{RSO}中我们介绍了两种近似处理的方法：一是事件式静态近似法则，也就是在不同的事件下，决策取不同的常数值；另一种称为事件式线性近似法则，在该法则中，决策在不同的事件下为随机变量的不同仿射函数。在实际应用中，我们可以使用RSOME方便灵活地定义这两类近似法则。在定义各类近似法则中，用户可以设定：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一个相互独立又完全穷尽（MECE）的事件集合，使得被定义的决策在不同的事件下动态变化。这样的事件适应（event-wise adaptation)集合可以通过函数$\texttt{evtadapt()}$来实现。&lt;/li&gt;
&lt;li&gt;被定义的决策对随随机变量的仿射适应（affine adaptation）表达式。这个仿射适应表达式可以通过函数$\texttt{affadapt()}$来设定。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;接下来，我们用一个实际的例子来演示如何使用RSOME处理此类问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例7&lt;/strong&gt; {example}
在之前的示例$\ref{newsvendor_example}$中，表达式$\max{p\cdot(x - z), 0}$可以用动态决策近似函数$y(\tilde{s},(\tilde{z}, \tilde{u}))$替代，由此之前的问题可以写成一个两阶段（Two-stage）模型如下：
$$
\begin{array}{rl}
\max &amp;amp;(p - c)\cdot x - \sup\limits_{\mathbb{P}\in\mathcal{F}}\mathbb{E}_{\mathbb{P}}[y(\tilde{s}, (\tilde{z}, \tilde{u}))] \\\
\text{s.t.} &amp;amp;x \geq 0 \\\
&amp;amp; y(\tilde{s}, (\tilde{z}, \tilde{u})) \geq p\cdot(x - z) \\\
&amp;amp; y(\tilde{s}, (\tilde{z}, \tilde{u})) \geq 0 \\\
&amp;amp; y\in \bar{\mathcal{A}}([S], 2)
\end{array}
$$
其中$y\in \bar{\mathcal{A}}([S], 2)$意味着动态决策$y$在每一个情景$s\in[S]$下，都是不同的关于随机变量$z$和$u$的仿射函数。这样的一个两阶段模型可以用如下程序来表达。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-matlab&#34; data-lang=&#34;matlab&#34;&gt;    &lt;span class=&#34;c&#34;&gt;%% 定义模型参数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                             &lt;span class=&#34;c&#34;&gt;% 商品需求上限&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;500&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                  &lt;span class=&#34;c&#34;&gt;% 经验数据的数目&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;Zhat&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;rand&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;               &lt;span class=&#34;c&#34;&gt;% 生成经验数据&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                &lt;span class=&#34;c&#34;&gt;% 销售价格&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;1.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                                &lt;span class=&#34;c&#34;&gt;% 预定成本&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;theta&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;0.01&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                    &lt;span class=&#34;c&#34;&gt;% Wasserstein 距离&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建模型，随机变量和决策变量&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rsome&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;报童问题&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;              &lt;span class=&#34;c&#34;&gt;% 创建一个模型model&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                       &lt;span class=&#34;c&#34;&gt;% 定义随机变量z&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;u&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;random&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                       &lt;span class=&#34;c&#34;&gt;% 定义辅助随机变量u&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                     &lt;span class=&#34;c&#34;&gt;% 定义决策变量x&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;decision&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                     &lt;span class=&#34;c&#34;&gt;% 定义动态决策变量y&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 创建和定义分布模糊集合&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ambiguity&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                 &lt;span class=&#34;c&#34;&gt;% 创建S个情景的分布模糊集&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;                                 
        &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;suppset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Zbar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;...     &lt;/span&gt;
                     &lt;span class=&#34;n&#34;&gt;norm&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Zhat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c&#34;&gt;% 定义每个情景s的支撑集&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;end&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exptset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;theta&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;           &lt;span class=&#34;c&#34;&gt;% 定义整体的期望值信息&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prob&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                            &lt;span class=&#34;c&#34;&gt;% 每个情景s的概率&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;probset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                   &lt;span class=&#34;c&#34;&gt;% 定义每个情景概率的值&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;with&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                          &lt;span class=&#34;c&#34;&gt;% 传递模糊信息到模型&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 定义动态决策的事件适应和仿射适应表达式&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;S&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;evtadapt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                      &lt;span class=&#34;c&#34;&gt;% y随不同的情景s变化&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;end&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;affadapt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                          &lt;span class=&#34;c&#34;&gt;% y线性依赖随机变量z&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;affadapt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                          &lt;span class=&#34;c&#34;&gt;% y线性依赖随机变量u&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 定义目标函数和约束条件&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;expect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;         &lt;span class=&#34;c&#34;&gt;% 最大化目标函数&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                   &lt;span class=&#34;c&#34;&gt;% 定义约束条件&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;w&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;z&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;           &lt;span class=&#34;c&#34;&gt;% 定义约束条件&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;                   &lt;span class=&#34;c&#34;&gt;% 定义变量边界&lt;/span&gt;
    
    &lt;span class=&#34;c&#34;&gt;%% 求解模型&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;solve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;                            &lt;span class=&#34;c&#34;&gt;% 求解模型&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;{example}
这一节主要介绍了RSOME优化建模工具包的基本概念和使用方法。从以上的示例中，我们可以看出，RSOME提供了一个简洁友好的建模环境，让用户可以通过近似数学表达式的程序语言定义复杂的模糊集合动态决策表达式，极大地提高了用户建立和求解各类鲁棒和随机优化模型的效率。关于RSOME工具包的更多细节可以参考官网&lt;a href=&#34;https://sites.google.com/view/rsome&#34;&gt;https://sites.google.com/view/rsome&lt;/a&gt;。&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>

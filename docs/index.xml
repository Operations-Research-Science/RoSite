<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>鲁棒优化电子书 —— 运筹OR帷幄</title>
    <link>https://allenz-me.github.io/RoSite/</link>
    <description>Recent content on 鲁棒优化电子书 —— 运筹OR帷幄</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 09 Jan 2022 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://allenz-me.github.io/RoSite/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>第一章 鲁棒优化简介</title>
      <link>https://allenz-me.github.io/RoSite/post/ch1/</link>
      <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/ch1/</guid>
      
        <description>&lt;p&gt;根据维基百科，鲁棒优化（robust optimization）是最优化理论中的一类用来寻求在不确定（uncertain)环境中使优化问题具有一定程度的鲁棒性（robustness）的方法。其中，不确定性可以通过问题的参数或者解的确定性变异（deterministic variability）来刻画(Wikipedia, 2019)。也就是说鲁棒优化是用来寻求对不确定性免疫的解的一类方法 (Bertsimas and Sim, 2004)。&lt;/p&gt;
&lt;p&gt;在传统的优化模型中，通常假设模型的输入数据是具体的、准确的数值。然而，现实生活中所获得的大部分数据都是具有一定的误差。而有时细微的误差也将导致优化问题的最优解不再最优(suboptimal)或者导致原问题不具有可行解（infeasible）。以&lt;a href=&#34;http://www.netlib.org/&#34;&gt;NETLIB&lt;/a&gt;中题PILOT4为例，其某一约束为：
$$
\begin{aligned}
&amp;amp; \boldsymbol{a}^{\top} \boldsymbol x \equiv-15.79081 x_{826}-8.598819 x_{827}-1.88789 x_{828}-1.362417 x_{829}-1.526049 x_{830}\\
&amp;amp;-0.031883 x_{849}-28.725555 x_{850}-10.792065 x_{851}-0.19004 x_{852}-2.757176 x_{853}\\
&amp;amp;-12.290832 x_{854}+717.562256 x_{855}-0.057865 x_{856}-3.785417 x_{857}-78.30661 x_{858} \\
&amp;amp;-122.163055 x_{859}-6.46609 x_{860}-0.48371 x_{861}-0.615264 x_{862}-1.353783 x_{863}\\
&amp;amp;-84.644257 x_{864}-122.459045 x_{865}-43.15593 x_{866}-1.712592 x_{870}-0.401597 x_{871} \\ &amp;amp;+x_{880}-0.946049 x_{898}-0.946049 x_{916} \geq b \equiv 23.387405.\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;用Cplex解得这个问题的解为：
$$
\begin{array}{lll}
{x_{826}^{\ast}=255.6112787181108} &amp;amp; {x_{827}^{\ast}=6240.488912232100} &amp;amp; {x_{828}^{\ast}=3624.613324098961} \\ {x_{829}^{\ast}=18.20205065283259} &amp;amp; {x_{849}^{\ast}=174397.0389573037} &amp;amp; {x_{870}^{\ast}=14250.00176680900} \\
{x_{871}^{\ast}=25910.00731692178} &amp;amp;  {x_{880}^{\ast}=104958.3199274139}. &amp;amp;
\end{array}
$$&lt;/p&gt;
&lt;p&gt;解$\boldsymbol x^\ast$​​满足$\boldsymbol a^{\top} \boldsymbol x^\ast = b$​​。然而，只要稍微改动$\boldsymbol a$​​中某一项的系数，那么$\boldsymbol a^{\top} \boldsymbol x^\ast \neq b$​​，也即$\boldsymbol x^\ast$​​不再是最优解。&lt;/p&gt;
&lt;p&gt;如何解决这个问题？最直观的方法是，假设每一个系数都在一定范围内变动，从而求一个解使得对所有在这个范围内变动的系数都是最优的。比如，对于约束
$$
ax \leq b,
$$
我们希望它对所有$a \in [\underline{a}, \bar{a}]$​​​都成立，也即原有约束将变成
$$
ax \leq b\quad \forall a \in [\underline{a}, \bar{a}].
$$
这个问题的一般形式首先由Soyster在1973年研究(Soyster, 1973)：对于任意线性规划问题,
$$
\begin{align*}
\max \; &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf{s.t. } \; &amp;amp; \displaystyle  \boldsymbol A \boldsymbol x \leq \boldsymbol{b}, \tag{1.1}\\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0.
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;假设系数矩阵$\boldsymbol A$​中每一列都在一个凸集（convex set）中（也称为列不确定性），也即，$\boldsymbol A_{j} \in \mathcal{U}_{j}$​，那么线性规划问题(1.1)将变成如下问题：
$$
\begin{align*}
\max \; &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf {s.t. } \; &amp;amp; \displaystyle \sum_{j \in [N]} \boldsymbol A_{j} x_{j} \leq \boldsymbol{b} \quad \forall \boldsymbol A_{j} \in \mathcal{U}_{j}, j\in [N],  \tag{1.2}\\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0.
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;然而，此种方法因所得到的解太过于保守（conservative）而饱受诟病。随后，Ben-Tal and Nemirovski (1998, 1999, 2000) 和EI-Ghaoui and Lebret (1997); El Ghaoui et al. (1998)为降低保守性而引进了椭球型不确定集（ellipsoids uncertainty set）。同时也考虑了其他形式的不确定性，比如行不确定性。其中，椭球型不确定集一方面比较难跟现实数据结合，另外一方面，转化（reformulate）之后的模型大都是二阶锥规划（second order cone programming）或者半正定规划（semi-definite programming）问题&amp;mdash;求解起来比较复杂。此外，这种方法依然比较保守。&lt;/p&gt;
&lt;p&gt;2004年，Bertsimas and Sim (2004) 为了克服椭球型不确定集的缺点，引进了预算不确定集（budget uncertainty set），将原问题转化成线性规划问题，并且得出了所得解可行概率的下限，也即所得解对所有约束不可行的概率的上限。&lt;/p&gt;
&lt;p&gt;本书将在第三章介绍不确定性最优化，不同种类的不确定集，以及鲁棒优化理论中很核心的对等式转换理论（robust counterpart）。此书把这种将模型参数假定在给定不确定集中而进行优化问题求解的方法统称为经典鲁棒优化（classical robust optimization）。&lt;/p&gt;
&lt;p&gt;为什么称为经典鲁棒优化？因为经典鲁棒优化构成了现在普遍使用的分布鲁棒优化（distributionally
robust optimization）的基础，同时也是分布鲁棒优化的一种特殊形式。&lt;/p&gt;
&lt;p&gt;如果在实际中决策者不仅仅已知优化模型某些参数（以下称为随机变量，即random variable）的支撑集（support set），还精确已知这些参数服从某一概率分布，那此类优化问题称为随机优化问题（stochastic
programming）：
$$
\begin{align*}
\min\ &amp;amp; \mathbb{E}_{\mathbb{P}} [{g(\boldsymbol x,\tilde{\boldsymbol{\xi}})}]\\
\mathbf{s.t.}\ &amp;amp;  \mathbb{E}_{\mathbb{P}} [{f_i(\boldsymbol x,\tilde{\boldsymbol{\xi}})}] \leq 0\quad \forall i\in[I]. \tag{1.3}
\end{align*}
$$
一般地，我们假设$g(\cdot)$​​​和$f_i(\cdot)$​​​均为凸函数。&lt;/p&gt;
&lt;p&gt;可是，恰恰是随机变量服从某一概率分布这个假设导致很多问题。一方面，模型中的随机变量在生产经营或者模型背景中通常是多种因素作用的结果，这就导致很难准确估计某一随机变量的边际分布，更别说所有随机变量的集中分布了。另一方面，就算已知边际分布或者集中分布，除了很多时候因为随机变量过多而模型维度过大之外，在多阶段问题中，还常常受制于&amp;quot;维度诅咒（curse of dimentionality)&amp;quot;。现今科技发展，各行各业所收集和掌握的数据量呈井喷态势，使得从大量数据中提取一些随机变量的统计信息（比如需求的均值和方差）变得可行。分布鲁棒优化恰好提供了将这些统计信息融入到模型决策中的一种思路。&lt;/p&gt;
&lt;p&gt;具体来说，如果我们将所需要用到的概率统计信息集成到一个集合中，假设为$\mathcal{F}$​，那么$\mathcal{F}$​就是所有拥有这些统计信息的分布的一个集合。我们称这个集合为模糊集（ambiguity set）。在模糊集中，选取一个分布使得在最坏情况下，进行模型求解。这样所求得的解就具有一定的鲁棒性。也即，模型(1.3)将变成：
$$
\begin{align*}
\min\ &amp;amp; \displaystyle\sup_{\mathbb{P} \in \mathcal{F}}~\mathbb{E}_{\mathbb{P}} [{g(\boldsymbol x,\tilde{\boldsymbol{\xi}})}]\\
\mathbf{s.t.}\ &amp;amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{F}}~\mathbb{E}_{\mathbb{P}} [{f_i(\boldsymbol x,\tilde{\boldsymbol{\xi}})}] \leq 0\quad \forall i\in[I].
\end{align*}
$$
我们称模型(1.4)为分布鲁棒优化模型。其中，如果$\mathcal{F} = \{\mathbb{P}\}$，那分布鲁棒模型就是随机优化模型。如果，在$\mathcal{F}$中，我们只知道随机量$\tilde{\boldsymbol{\xi}}$在某一个集合$\mathcal{U}$中，那分布鲁棒模型退化成经典鲁棒模型。本书将在第四章着重介绍不同的模糊集和分布式鲁棒模型的求解方法。&lt;/p&gt;
&lt;p&gt;以上所阐述的经典鲁棒优化模型和分布鲁棒优化模型只适用于单阶段（single stage）问题。而现实中所面临的决策往往是多阶段（multi-stage）的。其中，最经典的莫过于两阶段随机规划模型：
$$
\begin{align*}
\min\ &amp;amp; \boldsymbol c^{\top} \boldsymbol x + \mathbb{E}_{\mathbb{P}} [{g(\boldsymbol x,\tilde{\boldsymbol{\xi}})}]  \tag{1.5}\\
\mathbf{s.t.}\ &amp;amp;  \boldsymbol{Ax} = \boldsymbol b,\\
&amp;amp; \boldsymbol x \geq \boldsymbol{0},
\end{align*}
$$
其中
$$
\begin{align*} \tag{1.6}
g(\boldsymbol x,\boldsymbol \xi) = \min\ &amp;amp; \boldsymbol q^{\top}\boldsymbol{y}\\
\mathbf{s.t.}\ &amp;amp;  \boldsymbol{T}\boldsymbol x + \boldsymbol{W}\boldsymbol y = \boldsymbol h,\\
&amp;amp; \boldsymbol y \geq \boldsymbol{0}.
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;$\boldsymbol \xi \triangleq (\boldsymbol q, \boldsymbol h, \boldsymbol T, \boldsymbol W)$​​​​为第二阶段的输入数据。也即第二阶段的决策不仅依赖于第一阶段决策变量还依赖于随机变量的实现值（realization）。这就导致各阶段之间决策变量和随机变量之间的交互使得问题的复杂度随着阶段的增加而呈指数增长，也即&amp;quot;维度诅咒&amp;quot;。在随机规划中，学者们通过引入决策规则（decision rule）去近似地解决这一问题。但是，因为近似模型表现不好而被&amp;quot;打入冷宫&amp;quot;。而鲁棒优化的出现，让决策规则重新焕发出了勃勃生机。本书将在第五章详细介绍多阶段随机规划问题以及如何使用不同的决策规则和鲁棒优化的方法对其进行近似，并且取得很好的近似效果。&lt;/p&gt;
&lt;p&gt;近年来，随着鲁棒优化在各种不同优化问题求解中的良好表现，其价值越来越被学界和业界所发现。比如，从鲁棒优化的角度去处理具有广泛运用的机会约束问题，可以收到比较好的效果。而最新的研究显示，被广泛运用在机器学习中回归模型（regression）的正则性（regularization）和鲁棒优化在一定条件下具有等价关系。这一发现启发了越来越多的学者将鲁棒优化和机器学习相结合。本书将在第六章讲解鲁棒优化下的机会约束问题演化而出的鲁棒性优化问题，在第七章讲解鲁棒优化和机器学习结合的一些最新研究成果。&lt;/p&gt;
&lt;p&gt;同时，在本书的最后一章，我们将介绍鲁棒模型在不同求解平台上的实现方式。也将在不同的章节中引入不同的案例或算例。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ben-Tal, Aharon and Arkadi Nemirovski&lt;/strong&gt;, “Robust convex optimization,” Mathematics of Operations Research, 1998, 23 (4), 769–805.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ and_ _&lt;/strong&gt; , “Robust solutions of uncertain linear programs,” Operations Research Letters, 1999, 25 (1), 1–13.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_ and_&lt;/strong&gt; , “Robust solutions of linear programming problems contaminated with uncertain data,” Mathematical Programming, 2000, 88 (3), 411–424.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bertsimas, Dimitris and Melvyn Sim&lt;/strong&gt;, “The price of robustness,” Operations Research, 2004, 52 (1), 35–53.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EI-Ghaoui, L and H Lebret&lt;/strong&gt;, “Robust solutions to least-square problems to uncertain data matrices,” SIAM Journal on Matrix Analysis and Applications, 1997, 18, 1035–1064.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ghaoui, Laurent El, Francois Oustry, and Hervé Lebret&lt;/strong&gt;, “Robust solutions to uncertain semidefinite pro- grams,” SIAM Journal on Optimization, 1998, 9 (1), 33–52.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Soyster, Allen L&lt;/strong&gt;, “Technical note—convex programming with set-inclusive constraints and applications to inexact linear programming,” Operations Research, 1973, 21 (5), 1154–1157.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wikipedia&lt;/strong&gt;, “Robust optimization — Wikipedia, The Free Encyclopedia,” 2019. [Online; accessed 16-April- 2019].&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>第二章 鲁棒优化预备知识</title>
      <link>https://allenz-me.github.io/RoSite/post/ch2/</link>
      <pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/ch2/</guid>
      
        <description>&lt;p&gt;在进行系统的鲁棒优化学习之前，我们进行一些预备知识的回顾。本章将对线性规划、凸优化、锥优化以及风险偏好及其度量进行简要介绍。&lt;/p&gt;
&lt;h2 id=&#34;21-线性规划概览linear-optimization&#34;&gt;2.1 线性规划概览（Linear optimization）&lt;/h2&gt;
&lt;p&gt;线性规划（LP）是数学规划中形式最为简单的一种模型。一个线性规划可以写作：
$$
\begin{array}{rl}
\min       &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
{\rm s.t.} &amp;amp; \boldsymbol{A}\boldsymbol x \geq \boldsymbol{b}, \\
&amp;amp; \boldsymbol{x}  \geq \boldsymbol{0}. \\
\end{array}
$$
可见上式中，目标函数和约束都是线性的形式，所以被叫做“线性规划”。虽然它的形式简单，但线性规划的建模能力非常强大，有很多经典的数学建模问题都可以转化为线性规划，也有很多非线性的函数也可以等价转化为线性规划求解。比如对于如下非线性的规划
$$
\begin{array}{rl}
\min &amp;amp; f(\boldsymbol{x}) = \max\limits_{k} \left\{ \boldsymbol{d}^{\top}_k \boldsymbol{x} + c_k \right\} \\
{\rm s.t.} &amp;amp; \boldsymbol{A} \boldsymbol x \geq \boldsymbol{b}.
\end{array}
$$
我们可以等价地将其转化为线性规划
$$
\begin{array}{rl}
\min &amp;amp; z \\
{\rm s.t.} &amp;amp; \boldsymbol{A} \boldsymbol x \geq \boldsymbol{b}, \\
&amp;amp;  z \geq \boldsymbol{d}^{\top}_k \boldsymbol{x} + c_k \quad \forall k.  \\
\end{array}
$$&lt;/p&gt;
&lt;p&gt;当然，在实际解决过程的问题中要十分注意转化是否等价！一个常见的错误就是认为如下的两个数学规划问题是等价的。
$$
\begin{array}{rlrl}
\min &amp;amp; \displaystyle\sum_{j\in [N]} c_j|x_j|  \qquad \qquad \qquad &amp;amp; \min &amp;amp; \displaystyle \sum_{j\in [N]} c_jz_j\\
{\rm s.t.} &amp;amp; \boldsymbol{A} \boldsymbol x \geq \boldsymbol{b}. &amp;amp; {\rm s.t.} &amp;amp; \boldsymbol{A} \boldsymbol x \geq \boldsymbol{b}, \\
&amp;amp; &amp;amp; &amp;amp; x_j \geq - z_j, \\
&amp;amp; &amp;amp; &amp;amp; -x_j \geq -z_j. \\
\end{array}
$$
其实，当第一个规划问题有界，且存在$c_j&amp;lt;0$时，我们可以令线性规划中对应的$z_j\mapsto+\infty$，使得第二个问题最优值趋向于$-\infty$​。此时易见两个问题并非等价。&lt;/p&gt;
&lt;p&gt;说到数学规划问题，就不得不提到对偶（duality）理论。考虑一个（标准形式的）线性规划问题：
$$
\begin{array}{rl}
\min &amp;amp; \boldsymbol{c}^{\top}\boldsymbol x \\
{\rm s.t.} &amp;amp; \boldsymbol A \boldsymbol x = \boldsymbol b, \\
&amp;amp; \boldsymbol x \geq \boldsymbol 0.
\end{array}
$$
我们可以使用拉格朗日乘子将上述问题写成：
$$
\begin{array}{rl}
g(\boldsymbol p) = \min &amp;amp; \boldsymbol{c}^{\top}\boldsymbol x + \boldsymbol p^{\top}( \boldsymbol b -  \boldsymbol A \boldsymbol x)\\
{\rm s.t.}&amp;amp; \boldsymbol x \geq \boldsymbol 0.
\end{array}
$$
令$\boldsymbol x^\ast$为线性规划的最优解，可见
$$
g(\boldsymbol p) \leq \boldsymbol c^{\top}\boldsymbol x^\ast + \boldsymbol p^{\top}( \boldsymbol b -  \boldsymbol A \boldsymbol x^\ast) = \boldsymbol c^{\top} \boldsymbol x^\ast \quad \forall \boldsymbol p.
$$
也就是说，$ g(\boldsymbol p)$是最优目标函数$\boldsymbol c^\top \boldsymbol x^\ast $的一个下界。为了使这个下界尽可能的“紧”一些，我们想要求得$\displaystyle\max_{\boldsymbol p} g(\boldsymbol p)$：
$$
g(\boldsymbol p)=\min_{\boldsymbol x \geq \boldsymbol 0}\ \boldsymbol c^{\top}\boldsymbol x + \boldsymbol p^{\top}(\boldsymbol b - \boldsymbol A \boldsymbol x)
=\boldsymbol p^{\top}\boldsymbol b+\min_{\boldsymbol x\geq \boldsymbol 0}\ (\boldsymbol c - \boldsymbol A^{\top}\boldsymbol p)^{\top}\boldsymbol x.
$$
其中，我们有
$$
\min_{\boldsymbol x\geq \boldsymbol 0}\ (\boldsymbol c - \boldsymbol A^{\top}\boldsymbol p)^{\top}\boldsymbol x =
\begin{cases}
0, &amp;amp; \mbox{如果 } \boldsymbol c^{\top} - \boldsymbol p^{\top}\boldsymbol A \geq \boldsymbol 0, \\
-\infty, &amp;amp; \text{否则}.
\end{cases}
$$
至此，我们推出了原问题（primal）的对偶形式
$$
\begin{array}{rl}
\max &amp;amp; \boldsymbol{b}^{\top}\boldsymbol p \\
{\rm s.t.} &amp;amp; \boldsymbol A^{\top} \boldsymbol p \leq \boldsymbol c. \\
\end{array}
$$&lt;/p&gt;
&lt;p&gt;关于原问题和对偶问题的关系，我们有弱对偶和强对偶两个定理。其中弱对偶表述的是：当$\boldsymbol x$是原问题的可行解且$\boldsymbol p$是对偶问题的可行解时，我们一定有$\boldsymbol b^{\top} \boldsymbol p\leq \boldsymbol c^{\top}\boldsymbol x$。也就是说原问题（min）的最优目标函数都要比对偶问题（max）最优目标函数要大。由此定理可知，如果我们能找到一组可行解$(\boldsymbol x,\boldsymbol p)$使得$\boldsymbol b^{\top} \boldsymbol p=\boldsymbol c^{\top} \boldsymbol x$，那么$\boldsymbol x$和$\boldsymbol p$​就一定分别是原问题和对偶问题的最优解。值得一提的是，弱对偶对任意数学规划问题都成立。而强对偶表述的是：当线性规划有一个最优解时，那么它的对偶问题也有最优解，且两个问题的最优目标函数值相同。注意这里我们加上了线性规划这一条件。在更一般的凸优化中，我们必须要验证Slater condition来确认强对偶是否成立。关于线性规划的详细介绍，可以参阅Bertsimas and Tsitsiklis (1997)。&lt;/p&gt;
&lt;h2 id=&#34;22-凸优化概览convex-optimization&#34;&gt;2.2 凸优化概览（Convex optimization）&lt;/h2&gt;
&lt;p&gt;虽然线性规划的建模能力十分强大，现实生活中很多非线性问题依然无法被LP解决。这个时候我们需要使用非线性规划（NLP）来求出最优解。一个非线性规划可以写作
$$
\begin{array}{rll}
\min &amp;amp; f(\boldsymbol{x}) \\
{\rm s.t.} &amp;amp; g_i(\boldsymbol x) \leq 0 &amp;amp; \forall i=1 \in [m], \\
&amp;amp; h_i(\boldsymbol x) = 0 &amp;amp; \forall i \in [l]. \\
\end{array}
$$
其中，$f(\boldsymbol x):\mathbb R^n\mapsto\mathbb R$，$g_i(\boldsymbol x):\mathbb R^n\mapsto\mathbb R$和$h_i(\boldsymbol x):\mathbb R^n\mapsto\mathbb R$是关于$\boldsymbol x$的（通常连续且可微的）函数。&lt;/p&gt;
&lt;p&gt;在非线性规划问题中，我们通常关注局部最优点和全局最优点。如果对于可行域中的$\boldsymbol x$，对于任意可行域中的$\boldsymbol y$都有$f(\boldsymbol x)\leq f(\boldsymbol y)$，那么$\boldsymbol x$就是全局最小。类似的，如果$f(\boldsymbol x)$比它周围的点都要小，那么$\boldsymbol x$是一个局部最小。（局部最小严格定义是，存在以$\boldsymbol x$为中心的一个开球，使得$f(\boldsymbol x)$​比开球和可行域交集中所有可以取到的函数值都要小。）对于一个一般的非线性规划问题，我们通常很难验证一个点是局部最优还是全局最优。而如果一个非线性规划问题是凸优化问题，这个问题便迎刃而解。&lt;/p&gt;
&lt;p&gt;具体来说，一个函数$f:S\mapsto R$如果满足$f(\lambda \boldsymbol x_1+(1-\lambda)\boldsymbol x_2)\leq \lambda f(\boldsymbol x_1)+(1-\lambda)f(\boldsymbol x_2)$，$\forall \lambda\in[0,1]$, $\boldsymbol x_1, \boldsymbol x_2\in S$，那么这个函数就被称为凸函数。在一个非线性规划问题中，如果$f(\boldsymbol x)$，$g(\boldsymbol x)$和$h(\boldsymbol x)$​​都为凸函数，那么这个NLP就是一个凸优化问题。&lt;/p&gt;
&lt;p&gt;凸优化中一个重要的定理就是，如果$\boldsymbol x^\ast$是$f$的局部最小，那么$\boldsymbol x^\ast$也是$f$可行域中的全局最小。这个性质使得很多算法（例如各种迭代下降算法、内点算法等等）可以找到凸优化问题的全局最优解。我们也可以应用KKT条件来验证一个解是否为凸优化的问题的最优解。凸优化的详细介绍可以参阅Boyd and Vandenberghe (2004)。然而，在一个凸优化问题中，凸函数$f$，$g$和$h$的形式太过多元化。相比之下，任意一个线性规划都可以转化为标准形式（参见第 2.1节）。这样的标准形式可以大大减少推导鲁棒对等式（robust counterpart）时的步骤。那么一个凸优化问题可以转变为“标准形式”吗？为了达到这个目的，我们将在下节中介绍锥优化。&lt;/p&gt;
&lt;h2 id=&#34;23-锥优化概览conic-optimization&#34;&gt;2.3 锥优化概览（Conic optimization）&lt;/h2&gt;
&lt;p&gt;沿用上节的符号系统，我们考虑目标函数$f(\boldsymbol x)$为线性形式的凸优化问题，即$f(\boldsymbol x)=\boldsymbol c^{\top} \boldsymbol x$。无论$g(\boldsymbol x)$和$h(\boldsymbol x)$形式如何，凸优化问题的可行域一定是一个凸集，写作$\mathcal X$​。那么我们考虑的凸优化问题可以表示为：
$$
\begin{array}{rcl}
&amp;amp;\min &amp;amp; \boldsymbol c^{\top}\boldsymbol{x} \\
&amp;amp; {\rm s.t.} &amp;amp; \boldsymbol x \in \mathcal X. \\
\end{array}
$$
这个问题可以等价为如下规划问题
$$
\begin{array}{rcl}
&amp;amp;\min &amp;amp; \boldsymbol c^{\top}\boldsymbol{x} \\
&amp;amp; {\rm s.t.} &amp;amp; y=1, \\
&amp;amp; &amp;amp; (\boldsymbol x,y)\in \mathcal K.
\end{array}
$$
其中，$\mathcal K=\text{cl}\{ (\boldsymbol x,y):\boldsymbol x/y \in \mathcal X, y&amp;gt;0 \}$，$\text{cl}\{\cdot\}$表示一个集合的闭包。之所以写成这种形式，是因为$\mathcal K$是一种叫作“锥”的性质非常好的集合。我们把一个集合$\mathcal K$叫作锥，如果对任意的$\boldsymbol x\in \mathcal  K$，$\lambda \boldsymbol x\in \mathcal K$对所有$\lambda \geq 0$​都成立。&lt;/p&gt;
&lt;p&gt;基于这个变换，第一个问题是：如何把线性规划和锥联系起来？第二个问题是：如果有办法联系起来，我们可以把线性规划的优良性质借鉴过来吗？我们先解决第一个问题——显然，非负$m$维实数域$\mathbb R_+^m$是一个锥。那么，我们可以把一个线性约束等价为
$$
\boldsymbol{A} \boldsymbol x \geq \boldsymbol b \Leftrightarrow \boldsymbol{A}\boldsymbol x - \boldsymbol b \geq \boldsymbol 0 \Leftrightarrow \boldsymbol{A}\boldsymbol x - \boldsymbol b \in \mathcal{K}, \quad \mathcal{K} = \mathbb{R}_{+}^{m}.
$$
而线性规划中很多非常好的数学性质来源于不等号“$\geq$”。具体来说，不等号满足&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;反射性（reflexibility）：$\boldsymbol a \geq \boldsymbol a$；&lt;/li&gt;
&lt;li&gt;反对称性（antisymmetry）：如果$\boldsymbol a \geq \boldsymbol b$且$\boldsymbol b \geq \boldsymbol a$，那么$\boldsymbol a = \boldsymbol b$；&lt;/li&gt;
&lt;li&gt;传递性（transitivity）：如果$\boldsymbol a \geq  \boldsymbol b$且$\boldsymbol b \geq \boldsymbol c$，那么$\boldsymbol a \geq  \boldsymbol c$；&lt;/li&gt;
&lt;li&gt;如果$\boldsymbol a \geq \boldsymbol b$，那么$\lambda \boldsymbol a \geq \lambda \boldsymbol b$对于所有$\lambda \geq 0$成立；&lt;/li&gt;
&lt;li&gt;如果$\boldsymbol a \geq \boldsymbol b$且$\boldsymbol c\geq  \boldsymbol d$，那么$\boldsymbol a+ \boldsymbol c \geq  \boldsymbol b+ \boldsymbol d$。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于这个观察，我们是否可以对于一个任意的锥$\mathcal K$​，定义一个广义的不等式呢？答案是可以的。我们用“$\succeq_{\mathcal K}$​​​”来定义如下的广义不等式关系：
$$
\boldsymbol{A}\boldsymbol x \succeq_{\mathcal{K}} \boldsymbol{b} \Leftrightarrow \boldsymbol{A}\boldsymbol x - \boldsymbol{b} \succeq_{\mathcal{K}} \boldsymbol{0} \Leftrightarrow \boldsymbol{A}\boldsymbol x - \boldsymbol{b} \in \mathcal{K},
$$
$$
\boldsymbol{A}\boldsymbol x \succ_{\mathcal{K}} \boldsymbol{b} \Leftrightarrow \boldsymbol{A}\boldsymbol x - \boldsymbol{b} \succ_{\mathcal {K}} \boldsymbol{0} \Leftrightarrow \boldsymbol{A}\boldsymbol x - \boldsymbol{b} \in \mathrm{int} \mathcal{K},
$$
其中， $\mathrm{int} \mathcal{K}$​表示$\mathcal{K}$​的内部(interior)。&lt;/p&gt;
&lt;p&gt;可以证明，不等关系“$\succeq_{\mathcal K}$​”同样继承了不等号“$\geq$​”的上述所有性质。&lt;/p&gt;
&lt;p&gt;基于这个推导，我们可以将一个（目标函数为线性函数）凸优化问题一般化为锥优化框架
$$
\begin{array}{lll}
\min  &amp;amp; \displaystyle \boldsymbol c^{\top} \boldsymbol x &amp;amp;\\
\text { s.t. } &amp;amp; \displaystyle  \boldsymbol{A} \boldsymbol{x} = \boldsymbol b, \\
&amp;amp; \boldsymbol{x} \succeq_{\mathcal{K}} \boldsymbol{0}.
\end{array}
$$
这个形式可以比作锥优化的“标准形式”。可见它和线性规划的标准形式有诸多相似之处。推导到这里，几个很自然的问题就是，这个问题的对偶形式是什么样的？强对偶在这个问题中成立吗？为了回答这些问题，首先引入对偶锥的概念。对于锥$\mathcal K$，它的对偶锥定义为
$$
\mathcal{K}^{\ast}=\left\{\boldsymbol{y} : \boldsymbol{y}^{\top} \boldsymbol{x} \geq 0, \quad \forall \boldsymbol{x} \in \mathcal{K}\right\}.
$$
有了这个定义，我们来推导锥优化的对偶问题。为了简单起见，我们忽略线性约束，考虑
$$
\begin{array}{rl}
\min &amp;amp; \boldsymbol c^{\top} \boldsymbol x \\
\text { s.t. } &amp;amp; \boldsymbol{A}\boldsymbol x \succeq_{\mathcal {K}} \boldsymbol{b}
\end{array}
$$
的对偶问题。&lt;/p&gt;
&lt;p&gt;注意到，对任意的$\boldsymbol x \succeq_{K} \boldsymbol 0$​和$\boldsymbol y \succeq_{K^{\ast}} \boldsymbol{0}$​，我们有$\boldsymbol x^{\top} \boldsymbol y \geq 0$​。&lt;/p&gt;
&lt;p&gt;我们然后便可以引入拉格朗日乘子使问题等价于
$$
\min_{\boldsymbol x}\max_{\boldsymbol y\in \mathcal K^\ast}\ \boldsymbol c^{\top}\boldsymbol x+\boldsymbol y^{\top}(\boldsymbol b-\boldsymbol A\boldsymbol x).
$$
则对偶函数为
$$
\min_{\boldsymbol x}\ \boldsymbol c^{\top}\boldsymbol x+\boldsymbol y^{\top}(\boldsymbol b-\boldsymbol A\boldsymbol x)=
\begin{cases}
\boldsymbol b^{\top}\boldsymbol y, &amp;amp; \mbox{如果 } \boldsymbol A^{\top} \boldsymbol y=\boldsymbol c, \\
-\infty, &amp;amp; \text{否则}.
\end{cases}
$$
在$\boldsymbol y\in\mathcal K^\ast$中最大化对偶函数，我们可以得到对偶问题
$$
\begin{array}{cl}
\max  &amp;amp; \boldsymbol b^{\top} \boldsymbol y\\
\text { s.t. } &amp;amp; \boldsymbol{A}^{\top}\boldsymbol{y} = \boldsymbol c, \\
&amp;amp; \boldsymbol y \succeq_{\mathcal {K}^{\ast}} \boldsymbol{0}.
\end{array}
$$&lt;/p&gt;
&lt;p&gt;完成了对偶问题的推导，我们需要回答强对偶在这个问题中是否成立。简单来说，我们有如下结论。对于上述锥优化的“标准型”的原问题和对偶问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对偶问题的对偶问题等价于原问题。&lt;/li&gt;
&lt;li&gt;对原问题可行的任意$\boldsymbol x$​以及对对偶问题可行的任意$\boldsymbol y$​，我们有$\boldsymbol c^{\top} \boldsymbol x \geq \boldsymbol b^{\top} \boldsymbol y$​。&lt;/li&gt;
&lt;li&gt;如果原问题有下界，且对某些$\boldsymbol x$​有$\boldsymbol{A}\boldsymbol x - \boldsymbol b \in \mathrm{int} \mathcal K$​严格成立，那么对偶问题可解，且原问题和对偶问题最优目标函数值相等。&lt;/li&gt;
&lt;li&gt;如果原问题或对偶问题有界且严格可行（$\boldsymbol{A}\boldsymbol x - \boldsymbol b \in \mathrm{int} \mathcal K$​），$(\boldsymbol{x}, \boldsymbol{y})$​是最优解与下列任意一条件等价：（i）$\boldsymbol c^{\top} \boldsymbol x = \boldsymbol b^{\top} \boldsymbol y$​；或（ii）$\boldsymbol y^{\top}(\boldsymbol{A}\boldsymbol x - \boldsymbol b) = 0$​​​。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;24-风险偏好及度量risk-preferences-and-risk-measures&#34;&gt;2.4 风险偏好及度量（Risk preferences and risk measures）&lt;/h2&gt;
&lt;p&gt;本节主要介绍关于风险度量的基本知识。现实中，我们来决策做一件事（比如投资）时，在未来得到的回报往往都是不确定的。为了衡量一件事未来的风险和收益，人们引入了风险度量的概念。一件事的收益可以用随机变量来表示。同时，我们令$\mathcal V$​为所有随机变量构成的空间，则其风险度量（risk measure）$\mu$​需要满足两个特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单调性：对于任意的$\tilde r,\tilde s\in \mathcal V$​且$\tilde r \geq \tilde s$​， 那么$\mu[\tilde{r}] \leq \mu[\tilde{s}]$​。这里，$\tilde r \geq \tilde s$​表示的是state-wise dominance。&lt;/li&gt;
&lt;li&gt;平移不变性：对于所有的$c\in \mathbb R$​，$\mu[\tilde{r} + c] \leq \mu[\tilde{r}] - c$​​​​。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;直观来说，单调性表示的意义为：当一件事未来的收益在任何可能性下都高于另一件事，那么它的风险一定是较小的。同时，平移不变性意味着：当一个资产确定性地增加了一定的价值，那么它的风险就会相应减少相同的数值。&lt;/p&gt;
&lt;p&gt;基于上述定义，人们定义了非常多的风险度量。其中一个非常著名的风险度量就是在险价值（Value-at-Risk，VaR）。VaR的数学定义如下：
$$
{\rm VaR}_\alpha[\tilde{r}] := \inf\left\{ m \in \mathbb{R} \mid \mathbb{P}[{ \tilde{r} + m \geq 0}] \geq 1-\alpha \right\}.
$$&lt;/p&gt;
&lt;p&gt;根据上述定义，VaR衡量了在给定概率$\alpha$​下，一份投资可能的损失。例如，一个公司每个月在$\alpha=5\%$​的VaR为一亿元。这意味着公司每个月都有5%的可能性损失超过一亿元。或者说，一个一亿元的损失平均每20个月就要发生一次。根据定义，我们同时可以将VaR和表示受益的随机变量$\tilde r$​的分位数联系起来。下图显示，当一个随机变量5%的分位数为$-0.0263$​时，对应的VaR的数值便为$0.0263$​。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2-1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上图同样能看出，VaR的取值只和单独的分位点值相关。而这样的性质会带来一些不便，比如对于有VaR介入的优化问题，通常来说都很难求解。同时，VaR在某些场合不能很好反应出不同投资的风险。假设我们有两种投资策略，其收益分别如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;资产1：0.95概率收益200万，0.03概率损失100万，0.02概率损失200万；&lt;/li&gt;
&lt;li&gt;资产2：0.95概率收益200万，0.03概率损失100万，0.02概率损失1000万。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显而易见资产2的风险比资产1更大，然而上述两个投资组合的VaR都是100万。为了解决这个问题，人们又提出了条件风险价值（Conditional Value-at-Risk，CVaR）的概念。CVaR计算了超过VaR值的可能损失的期望值，也就是说对于$\tilde r\sim \mathbb{P}$​​，
$$
{\rm CVaR}^\ast_\alpha [\tilde{r}] \triangleq \mathbb{E}_{\mathbb{P}}[{-\tilde{r} \mid -\tilde{r} \geq {\rm VaR}_\alpha (\tilde{r}) }].
$$
这里我们使用CVaR$^\ast$来表示CVaR，因为我们在后文中将推导出CVaR更常用的一个定义。为了区分，我们加上了一个星号上标。上述这个定义使得CVaR对于收益/损失的尾部分布的形状更加敏感。我们根据这个定义也可以看出${\rm CVaR}^\ast_\alpha [\tilde{r}] \geq {\rm VaR}_\alpha (\tilde{r})$。下图显示了CVaR和VaR的联系。我们也可以计算出在之前例子中，资产1的CVaR为140万，而资产2的CVaR为460万。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../2-2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;现在我们假设一项投资其未来的收益只能取$T$个可能的值$r_1,\ldots,r_{T}$。如果我们取$\alpha$使得$\alpha T$刚好为整数，那么CVaR可以等价地表达为
$$
{\rm CVaR}^\ast_\alpha [\tilde{r}]  = \frac{1}{\alpha T} \max_{\mathcal{S} :~ \mathcal{S} \subseteq [T],  \\ |\mathcal{S}| = \alpha T} \sum_{t \in \mathcal{S}} -r_t.
$$
但是这个定义并不通用，因为它不能定义当$\alpha T$不是整数的情况。为此，我们将推导出CVaR更通用的一个定义。注意到上式可等价地推出：
$$
\begin{array}{rcll}
{\rm CVaR}^\ast_\alpha [\tilde{r}]  &amp;amp;=&amp;amp; \displaystyle \frac{1}{\alpha T} \max_{\mathcal{S} :~  \mathcal{S} \subseteq [T], \atop |\mathcal{S}| = \alpha T} \sum_{t \in \mathcal{S}} -r_t \\
&amp;amp;=&amp;amp;  \displaystyle  \frac{1}{\alpha T} \max_{\boldsymbol{z} \in \{0,1\}^T \atop \boldsymbol z^\top \boldsymbol 1 = \alpha T} \sum_{t \in [T]} -r_t z_t \\
&amp;amp;=&amp;amp;  \displaystyle  \frac{1}{\alpha T} \max_{\boldsymbol{z} \in [0,1]^T \atop \boldsymbol z^\top \boldsymbol 1 = \alpha T} \sum_{t \in [T] } -r_t z_t.
\end{array}
$$
我们求出上述问题的对偶问题，得到
$$
\begin{array}{rcl}
{\rm CVaR}_\alpha[\tilde{r}]=&amp;amp;\min &amp;amp; s + \frac{1}{\alpha T} \boldsymbol 1^\top \boldsymbol p \\
&amp;amp;{\rm s.t.}&amp;amp; s\boldsymbol 1 + \boldsymbol p \geq -\boldsymbol r, \\
&amp;amp; &amp;amp; \boldsymbol p \geq \boldsymbol 0,
\end{array}
$$
即
$$
{\rm CVaR}_\alpha [\tilde{r}] = \inf_s \left\{s + \frac{1}{\alpha} \frac{1}{T}\sum_{t \in [T]}(-r_t - s)^+ \right\}.
$$
至此，当$\alpha T$​不为整数时，我们可以根据上述推导定义CVaR为
$$
\begin{equation}\label{eq:cvar}
{\rm CVaR}_\alpha [\tilde{r}] \triangleq \inf_v \left\{v + \frac{1}{\alpha}\mathbb{E}_{\mathbb{P}}[{ (-\tilde{r} - v)^+ }] \right\}. \tag{2.1}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;这也是在优化领域中更常用的关于CVaR的定义。可以证明，在这个定义下依然有$\text{CVaR}_\alpha[\tilde{r}]\geq\text{VaR}_\alpha[\tilde{r}]$。&lt;/p&gt;
&lt;p&gt;我们接下来介绍最优化确定等价收益（Optimized Certainty Equivalent，OCE）。对于不确定的收益$\tilde r$，定义其OCE为 (Ben-Tal and Teboulle, 2007)
$$
S_u(\tilde r)=\sup_{\eta\in \mathbb{R}}\{ \eta+\mathbb{E}_{\mathbb{P}}[u(\tilde r - \eta)] \}.
$$
其中，$u: \mathbb{R}\mapsto \mathbb{R}$为非递减且凹的效用函数，并满足$u(0)=0$，且$1$是$u(r)$在$r=0$时的次梯度（subgradient）。我们可以通过公式这样解释OCE：一个决策者希望在未来有$\tilde r$的回报，而且在现在可以消费部分$\tilde r$。如果他在现在消费了确定的$\eta$的价值，那么$\tilde r$的现值就是$\eta+\mathbb{E}_{\mathbb{P}}[u(\tilde r - \eta)]$。对$\tilde r$进行现在和未来的最优分配，我们即可得到OCE。我们可以通过OCE来定义对应的风险度量。根据Ben-Tal and Teboulle (2007)，$\mu^{OCE}[\tilde{r}]=-S_u(\tilde r)$是一个一致性风险度量（coherent risk measure）。为了把问题放进凸优化框架，我们记$v=-\eta$，$U(x)=-u(-x)$。此时$U:\mathbb R \mapsto \mathbb R$可以看做一个非递减的凸效用函数，而对应的风险度量表示为
$$
\mu^{OCE}[\tilde{r}] = \inf_{v \in \mathbb{R}}\left\{v + \mathbb{E}_{\mathbb{P}}[{U(-\tilde{r} -v)}] \right\}.
$$
对比式(2.1)，我们可以看出CVaR是一种特殊的OCE度量，满足$U(r)=r^+/\alpha$​。&lt;/p&gt;
&lt;p&gt;在鲁棒优化领域，未来收益$\tilde r$​的分布$\mathbb P$​往往是不确定的。如果假设分布$\mathbb P$​处于一个模糊集（ambiguity set）$\mathcal F$​中，那么我们就可以写出在最坏情境（worst case）下对应的风险度量。以OCE举例，它在最坏情况下的风险度量写作
$$
\mu^{OCE}[\tilde{r}] = \inf_{v \in \mathbb{R}}\left\{v + \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[{U(-\tilde{r} -v)} ] \right\}.
$$
这样决策优化问题就变成了一个分布鲁棒优化问题。关于分布鲁棒优化问题的求解，具体可以参见第4章。&lt;/p&gt;
&lt;p&gt;我们最后介绍凸风险度量（convex risk measure）。对于一个风险度量$\mu$​，它是凸风险度量当且仅当对于任意的$\tilde{r},\tilde{s} \in \mathcal{V}$​，有
$$
\mu(\lambda \tilde{r} + (1-\lambda)\tilde{s} ) \leq \lambda \mu(\tilde{r}) + (1-\lambda)\mu(\tilde{s}).
$$
值得一提的是，OCE（包括CVaR）都是凸风险度量。而且，CVaR是所有凸风险度量中对VaR有最紧上界的一个，即如果$\mu[\tilde{r}] \geq {\rm VaR}_\alpha[\tilde{r}]$，$\forall \tilde{r} \in \mathcal{V}$，那么有$\mu[\tilde{r}] \geq {\rm CVaR}_\alpha[\tilde{r}] \geq  {\rm VaR}_\alpha[\tilde{r}]$，$\forall \tilde{r} \in \mathcal{V}$​。
另一个著名的凸风险度量是shortfall risk measure（）。由于Föllmer and Schied,
2002篇幅所限不在此展开。有关于风险度量系统的知识，感兴趣的读者可以参阅Artzner et al. (1999) 和Föllmer and Schied (2002)。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Artzner, Philippe, Freddy Delbaen, Jean-Marc Eber, and David Heath&lt;/strong&gt;, “Coherent measures of risk,” Mathematical Finance, 1999, 9 (3), 203–228.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ben-Tal, Aharon and Marc Teboulle&lt;/strong&gt;, “An old-new concept of convex risk measures: the optimized certainty equivalent,” Mathematical Finance, 2007, 17 (3), 449–476.&lt;/p&gt;
&lt;p&gt;B&lt;strong&gt;ertsimas, Dimitris and John N Tsitsiklis&lt;/strong&gt;, Introduction to Linear Optimization, Athena Scientific Belmont, MA, 1997.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Boyd, Stephen and Lieven Vandenberghe&lt;/strong&gt;, Convex Optimization, Cambridge university press, 2004.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Föllmer, Hans and Alexander Schied&lt;/strong&gt;, “Convex measures of risk and trading constraints,” Finance and Stochastics, 2002, 6 (4), 429–447.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>第三章 经典鲁棒优化</title>
      <link>https://allenz-me.github.io/RoSite/post/ch3/</link>
      <pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/ch3/</guid>
      
        <description>&lt;h2 id=&#34;31-不确定最优化optimization-under-uncertainty&#34;&gt;3.1 不确定最优化（Optimization under uncertainty）&lt;/h2&gt;
&lt;p&gt;在实际生活中不确定性广泛存在，为了更加合理的对不确定问题进行准确描述，不确定性优化逐渐被学界重视。最早在20世纪50年代Bellman、Zadeh和Charnes等人便开始对不确定性优化进行了研究(Chames A, 1959; E, 1970)。在对不确定性优化问题的描述之前，我们先来看一下传统的确定性优化问题：
$$
\begin{equation}
\begin{array}{rl}
\min\ &amp;amp; f(\boldsymbol{x}) \\
\text {s.t.}\ &amp;amp;h(\boldsymbol{x}) \leq 0.
\end{array}
\end{equation}\tag{3.1}
$$
其中，$\boldsymbol{x}$是决策向量，$f(\boldsymbol{x})$为目标函数，$h(\boldsymbol{x})$为约束条件。在（3.1）中，无论是约束条件还是目标函数，其对应的参数都是确定的。然而，在实际问题求解中，模型中一些参数我们很难事先确定。对于一些特定的优化问题而言，一个参数的不同就可能导致原本所求得的最优解变得毫无意义(El Ghaoui, 1998)。为了解决这类问题，不确定性问题的优化求解就变得十分重要。&lt;/p&gt;
&lt;p&gt;随着社会的不断发展，我们所需要求解模型的复杂度不断上升，模型的不确定性也在不断扩大，诸如飞机航班的线路规划、电网的最优调度、物流路径的最优规划等等。在实际生活中，造成模型不确定的根源主要来自以下几个方面：&lt;/p&gt;
&lt;p&gt;1）	数据统计和采集过程造成的数据丢失、数据偏差过大而产生的影响。&lt;/p&gt;
&lt;p&gt;2）	天气等不可抗力因素的干扰，对问题的分析产生的影响。&lt;/p&gt;
&lt;p&gt;3）	认知不全导致现有模型与实际生活中存在偏差产生的影响。&lt;/p&gt;
&lt;p&gt;4）	对于一些难以求解的非凸非线性模型，进行简化描述而产生的影响。&lt;/p&gt;
&lt;p&gt;为了更好地对不确定性优化问题进行描述，我们首先给出不确定性优化数学模型的一般表达：
$$
\begin{equation}
\left\{
\begin{array}{rl}
\min\ &amp;amp; f(\boldsymbol{x}, \tilde{\boldsymbol \xi})\\
\text{s.t}\ &amp;amp; h(\boldsymbol{x}, \tilde{\boldsymbol \xi}) \leq 0\quad
\end{array}
\right\} \quad {\forall~\tilde{\boldsymbol \xi}~\in~ \mathcal{U}.}
\end{equation}\tag{3.2}
$$
在（3.2）中，$\tilde{\boldsymbol \xi}$为不确定参数，$\mathcal{U}$表示不确定参数的集合。为了求解模型（3.2），以Bellman等人的工作为开端，相关学者提出了一系列的求解优化方法，诸如：随机规划(Birge and Louveaux, 2011)、鲁棒优化(Ben-Tal et al., 2009)、灵敏度分析(Ben-Tal et al., 2009)、模糊规划(刘宝碇, 1998)等等。不确定性优化的理论和方法不断地被开发出来。不确定性优化的理论也依据分析阶段的不同被分为事前分析方法和事后分析方法两大类。接下来我们主要对这两大类的不确定理论展开叙述。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事前分析方法&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;模糊规划(Fuzzy programming)&lt;/p&gt;
&lt;p&gt;当$\mathcal{U}$是一个模糊逻辑集合时，模型（3.2）成为了处理软约束&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;规划问题的求解模型，即模糊规划。这类规划是为了应对由于实际生活中，有时无法提供准确的决策的情况下而产生的一类规划求解理论。对于模糊规划问题的详细求解步骤，可以参照文献(刘宝碇, 1998)。在模糊规划中，需要依据决策者的个人经验来获取不确定参数的模糊隶属函数，往往存在较大的主观性，在实际中运用时也需要经过多次调整，存在诸多限制。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;随机规划(Stochastic programming)&lt;/p&gt;
&lt;p&gt;当$\mathcal{U}$是一个随机不确定集合时，上述模型成为了处理随机性数据的规划求解问题，即随机规划。随机规划根据不同的决策规则，可以分为三类：
(a) 期望模型。首先确定不确定参数的分布模型，然后通过选取离散或连续的概率分布函数对不确定参数进行描述，最终通过期望来代替不确定参数，使不确定问题转化为确定性问题并求解。如果目标函数和约束中存在随机参数，只需要将各随机参数转化为期望值，便可以将模型转化为确定性模型进而求解。&lt;/p&gt;
&lt;p&gt;(b) 机会约束规划模型。通俗来讲，机会约束规划模型是指允许决策不满足约束条件，但是决策满足约束条件的概率不低于事先设定的置信水平的规划求解模型。该模型是一种在一定概率下达到最优的理论。该模型需要事先给定置信水平。模型描述如下：
$$
\begin{equation}
\begin{array}{rl}
\min\ &amp;amp; f(\boldsymbol{x}) \\
\text {s.t.}\ &amp;amp; P\{\boldsymbol{h}(\boldsymbol{x}, \tilde{\boldsymbol \xi}) \leq 0) \} \geq \alpha.
\end{array}
\end{equation}\tag{3.3}
$$
(c) 相关机会约束规划模型(Liu, 1997)。相关机会约束规划是当决策者面临多个事件时，希望最大化满足这些事件的概率而产生的一种规划方法。无论是期望模型还是机会约束规划模型，最终都是确定性优化求解并得出准确值。相关机会规划虽然求解结果是确定的，但并不代表一定实现，规划的目的是极大化该事件的实现概率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;事后分析方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;灵敏度分析（sensitivity analysis）是最典型的事后分析方法。灵敏度分析根据需求的不同也被划分为局部灵敏度分析(local sensitivity analysis)和全局灵敏度分析(global sensitivity analysis)。这里以模型（3.4）为例对灵敏度分析展开一个简短的描述：
$$
\begin{equation}
\begin{array}{rll}
Z = \min\ &amp;amp; \boldsymbol{c}^\top\boldsymbol{x} \\
\text {s.t}\ &amp;amp;\boldsymbol{A x} = \boldsymbol{b}, \\
&amp;amp; \boldsymbol{x} \geq \boldsymbol{0}.
\end{array}
\end{equation}\tag{3.4}
$$
由于灵敏度分析应对的是不确定性优化问题，因此有时会遇到需要添加新约束的情况。这种情况下，如果最优解满足新添加的约束，则原模型的最优解仍是新模型的最优解，若不满足新添加的约束，则需要重新计算。但更多的研究内容是数据变化对最优解产生的影响。即：$\boldsymbol A$、$\boldsymbol c$和$\boldsymbol b$变化导致模型最优值$Z$发生的改变。灵敏度分析研究热点问题是，当参数在什么范围内进行波动时，模型的最优解$\boldsymbol{x}^{\ast}$不会发生改变，具体的原理涉及到了基变量、非基变量、对偶单纯性等相关知识，这里不再详细描述，如果有兴趣的读者可以参考(陈宝林, 2005)。灵敏度分析方法虽然相对其他不确定性优化方法而言比较简单，但灵敏度分析方法仅是一个评价分析工具，大大限制了该方法的使用领域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;鲁棒优化（Robust optimization&lt;/strong&gt;）&lt;/p&gt;
&lt;p&gt;鲁棒优化也是一类事前分析方法，之所以单独列出来，是因为鲁棒优化是针对传统优化方法不足，由鲁棒控制理论发展而来替代随机规划和灵敏度分析的方法。在（3.2）中，如果$\mathcal{U}$是一个有界闭集，上述模型成为了处理不确定集合内所有不确定参数的优化问题，即鲁棒优化。相对于传统不确定性优化方法，鲁棒优化有如下优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;鲁棒优化在建模过程中充分考虑了不确定性，并以集合的形式对变量进行描述。相对于随机规划和模糊规划，鲁棒优化不需要不确定参数的分布模型和不确定参数的模糊隶属函数。&lt;/li&gt;
&lt;li&gt;鲁棒优化的约束条件是严格成立的，即只要不确定参数$\tilde{\boldsymbol \xi}$属于不确定集合$\mathcal{U}$，所求出的解都能满足约束条件。即优化模型具有较强的鲁棒性，最优解对参数变化的敏感性低。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;鲁棒优化虽然有着随机规划和模糊规划没有的优势，但是鲁棒优化模型本身是一个半无限优化问题，很难直接进行求解，鲁棒优化的计算结果受限于不确定集$\mathcal{U}$的不同。我们会在3.2小节和3.3小节分别对鲁棒优化中的不确定集$\mathcal{U}$和鲁棒优化对等式及转换理论进行阐述。&lt;/p&gt;
&lt;h3 id=&#34;311-鲁棒优化理论的发展&#34;&gt;3.1.1 鲁棒优化理论的发展&lt;/h3&gt;
&lt;p&gt;1973年，Soyster首次用鲁棒优化的思想来解决线性规划中的不确定性(Soyster, 1973)。虽然该方法基于最坏情况的基础上进行考虑，结果过于保守, 但是Soyster为不确定性优化的发展开拓了全新的思路，开辟了鲁棒优化发展的道路。&lt;/p&gt;
&lt;p&gt;Mulvey等人在1995年首次提出鲁棒优化的概念(M et al., 1995)。他们给出了基于情景集鲁棒优化的一般模型框架，提出了解鲁棒（solution robust）和模型鲁棒（model robust）的概念，通过将目标函数拆分为聚合函数与罚函数来消除不确定参数对结果的影响。在此之后，不断有学者投入到鲁棒优化的研究中，在这方面的奠基之作是在20世纪90年代由以色列学者Ben-Tal和Nemirovski(Ben-Tal and Nemirovski, 1998, 1999)和美国伯克利大学的Ghaoui(Laurent and Herv, 1997)提出。Ben-Tal证明了如果不确定集合$\mathcal{U}$是一个椭球不确定集（后面具体介绍），那么对于一些最重要的一般凸优化问题(线性规划、二次约束规划、半定规划等)，其鲁棒对等式要么是精确的，要么近似是一个可处理的问题，可以采用诸如内点法的算法在多项式时间内求解。除此之外，Ben-Tal给出了一般不确定半定规划问题的计算可处理的近似鲁棒对等式。在此之后，Ben-Tal等人又提出了可调鲁棒优化概念等概念，并被广泛运用到各行各业中。&lt;/p&gt;
&lt;p&gt;21世纪初，Bertsimas和Sim(Bertsimas and Sim, 2004)在Soyster、Ben-Tal和Nemirovski的研究基础上提出了全新的鲁棒优化框架。Bertsimas和Sim的鲁棒优化涵盖了离散优化，最主要的特点是所建立的鲁棒对等式不增加问题求解的复杂度。另一方面，Bertsimas和Sim的鲁棒优化允许出现约束违背(constraint violation)的情况，在这种情况下得到的鲁棒解大概率具有可行性。Bertsimas和Sim的理论由于其易处理性及实用性，受到了学界的广泛认可。&lt;/p&gt;
&lt;h3 id=&#34;312-鲁棒优化研究路线&#34;&gt;3.1.2 鲁棒优化研究路线&lt;/h3&gt;
&lt;p&gt;鲁棒优化自提出以来便受到广泛关注，也不断地被各个领域的学者应用到各行各业中，对于鲁棒优化问题的求解思路也是大同小异。具体如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../3.1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;在前面我们已经提到，当模型(3.2)中的不确定集为闭集合时，(3.2)可以视为一个鲁棒优化模型。此时，目标函数和约束条件中均含有不确定参数，为了更通俗地描述，我们对（3.2）做一些变形：
$$
\begin{equation} \label{model::robust problem}
\begin{aligned}
\min\ &amp;amp; F  \\
\text {s.t.}\ &amp;amp; f(\boldsymbol{x}, \tilde{\boldsymbol \xi}) \leq F &amp;amp;&amp;amp; \forall \tilde{\boldsymbol \xi} \in \mathcal{U}, \\
&amp;amp;h (\boldsymbol{x}, \tilde{\boldsymbol \xi}) \leq 0 &amp;amp;&amp;amp; \forall \tilde{\boldsymbol \xi} \in \mathcal{U}.
\end{aligned}
\end{equation}\tag{3.5}
$$
转换后可以明显看出(应注意转换是否等价，具体参照第二章)，无论原鲁棒优化模型的目标函数是线性还是非线性，是否含不确定参数，都可以由(3.5)表示。但是模型(3.5)通常很难直接求解，为了方便求解我们需要通过数学优化理论将模型(3.5)转换为一个能用商业软件直接求解的问题(以凸优化问题为主)，即&lt;strong&gt;鲁棒对等问题&lt;/strong&gt;(Robust Counterpart)。&lt;/p&gt;
&lt;p&gt;目前，鲁棒优化的研究方向主要体现在不确定集的选取及鲁棒对等转换理论上：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;不确定集的选取。如何选取合适的不确定集对不确定参数进行准确的描述，直接影响了模型的优化结果，而且不同的不确定集所对应的鲁棒对等问题也不同。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;鲁棒对等转换理论。如何把已经构建好的鲁棒优化模型转化成一个在计算上可通过一般商业优化软件直接求解的模型，直接影响了优化时间和优化结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;32-不确定集uncertainty-set&#34;&gt;3.2 不确定集（Uncertainty set）&lt;/h2&gt;
&lt;p&gt;鲁棒优化中，不同的不确定集对结果影响十分明显，当不确定集合越精细、模型复杂度越高，求解越困难。当不确定集合越宽泛时，所求出的最优解越保守，越不经济。为了权衡二者的关系，如何选择一个适合的不确定集合一直是相关学者的一个研究热点。常见的不确定集合主要有如下几类:&lt;/p&gt;
&lt;p&gt;1.盒式不确定集（Box uncertainty set）
$$
\begin{equation}
U_{\infty}=\left\{\boldsymbol \xi :\|\boldsymbol \xi\|_{\infty} \leq \tau \right\}
=\left\{\boldsymbol \xi :\left|\boldsymbol \xi_{i}\right| \leq \tau\ \forall i \in [N] \right\}
\end{equation}\tag{3.6}
$$
盒式不确定集合是最简单的不确定集合，也被称作区间集。由于鲁棒优化是考虑最坏情况下的优化求解方法，对于一些模型可能会出现所有不确定参数都在区间集上下界进行优化的情况，然而实际中该情况发生的概率极低或不会发生，很容易出现过度保守的情况。&lt;/p&gt;
&lt;p&gt;2.椭球不确定集（Ellipsoidal uncertainty set）(Ben-Tal et al., 2009; Boyd and Vandenberghe, 2006)：椭球集/椭球交集
$$
\begin{equation}
U_{2}=\bigg\{\boldsymbol \xi : \sum_{i \in [N]} \tilde{\xi}_{i}^{2} \leq \Omega^{2}\bigg\} = \left\{\boldsymbol \xi :\|\boldsymbol \xi\|_{2} \leq \Omega\right\}
\end{equation}\tag{3.7}
$$&lt;/p&gt;
&lt;p&gt;$$
\begin{equation}
U_{2}=\left\{\boldsymbol \xi :(\boldsymbol \xi-\overline{\boldsymbol{u}})^\top R^{-1}(\boldsymbol \xi-\overline{\boldsymbol{u}}) \leq \Omega^{2}\right\}
\end{equation}\tag{3.8}
$$&lt;/p&gt;
&lt;p&gt;在Ben-Tal的经典著作《Robust Optimization》称式(3.7)为椭球不确定集合，式(3.8)为椭球交集不确定集合。在Boyd的经典著作《Convex Optimization》中称(3.8)为椭球集，(3.7)为退化的椭球。为了方便描述，本文以Ben-tal的描述为准。上述公式中，$\boldsymbol \xi$ 为不确定参数向量，$\overline{\boldsymbol{u}}$为不确定参数的期望或预测值向量，$R$为协方差矩阵，$\Omega$为不确定度，用以刻画不确定参数扰动范围。相对于椭球集，椭球交集能更准确地对不确定参数进行描述，但是椭球交集在求解二次优化问题、锥二次优化、半定规划问题时难以直接求解，Ben-tal已经证明了这些优化问题中使用椭球交集时是NP-hard问题。如果采用椭球集，在线性规划、二次优化问题和锥二次优化时可以转化为可处理问题，但是在半定规划中，仍需满足诸多限制才能求解。椭球不确定集虽然可以很好地表示很多类型集合，方便数据输入，在一定程度上可以体现不确定参数之间的关联性。但是椭球不确定集会增加问题求解的复杂度，因此应用不够广泛。&lt;/p&gt;
&lt;p&gt;3.多面体不确定集（Polyhedral uncertainty set）
$$
\begin{equation}
U_{1}=\left\{\boldsymbol \xi : \sum_{i \in [N]}\left| \xi_{i}\right| \leq \Gamma,|\boldsymbol \xi| \leq e\right\} = \left\{\boldsymbol \xi :\|\boldsymbol \xi\|_{1} \leq \Gamma,|\boldsymbol \xi| \leq e\right\}
\end{equation}\tag{3.9}
$$
多面体集合(Bertsimas and Thiele, 2006)可以看作是椭球集合的一种特殊表现形式(Ben-Tal and Nemirovski, 1999)。尽管多面体不确定集难以刻画不确定参数间的相关性，但其具有线性结构、易于控制不确定度，在实际工程问题中广受青睐(Bertsimas and Thiele, 2006)。&lt;/p&gt;
&lt;p&gt;4.基数/预算不确定集（Budget uncertainty set）
$$
\begin{equation}
U_{1}=\left\{\boldsymbol \xi : \displaystyle\sum_{i \in [N]} \left| \frac{\xi_{i}-\widehat{\xi_{i}}}{\overline{\xi_{i}}-\underline{\xi_{i}}} \right| \leq \Gamma,| \boldsymbol{\xi} | \leq e\right\}
\end{equation}\tag{3.10}
$$
式中，$\overline{\xi_{i}}，\underline{\xi_{i}}$分别表示不确定参数的上下界，$\widehat{\xi_{i}}$表示$\xi_{i}$的预测值。最先提出这种不确定集合的是Bertsimas和Sim (Bertsimas and Sim, 2004)，由于这种不确定集合是基于不确定参数偏移量的相对值进行构建的，能够对更精确描述参数的波动情况，因此也被称为基数不确定集(R et al., 2010; Baringo and Baringo, 2017; Bertsimas et al., 2010)。&lt;/p&gt;
&lt;p&gt;5.数据驱动不确定集（Data-driven uncertainty set）&lt;/p&gt;
&lt;p&gt;无论是采用盒式还是椭球式不确定集，都会出现所得到的解过于保守的情况，为了解决解的过度保守，一些学者根据历史数据进行不确定集的构造，也被称为数据驱动不确定集。数据驱动不确定集的构建，是使用统计假设检验的置信区间来精确描述不确定参数 的分布 。在04年Bertsimas、Sim和09年Ben-Tal等人的研究中，假定不确定参数为，其分布不能精确获得。最初始的研究是基于数据结构特性做出的先验假设。这些方法假设是没有依赖的，但是不会认为 边界分布是确定的。13年Bertsimas对数据驱动不确定集合的构造进行了进一步的改进。Bertsimas假设数据S有独立分布，这些S可以为不确定参数的分布 添加更多的细节。并且通过这些细节信息，设计一个概率保证的集合，相对于传统的集合，新的集合更小，所求出的结果也不是那么的精确。关于数据驱动的先验假设和假设检验可以参照Bertsimas的研究(Bertsimas et al., 2018)。&lt;/p&gt;
&lt;p&gt;除去以上常见的不确定集合，一些学者为了适应不同的情况以及更精确地对不确定参数进行描述，还衍生出了很多种组合不确定集合，具体如：盒式+椭球式不确定集、盒式+多面体不确定集、盒式+椭球式+多面体不确定集等等。&lt;/p&gt;
&lt;h2 id=&#34;33-鲁棒对等问题robust-counterpart&#34;&gt;3.3 鲁棒对等问题（Robust counterpart）&lt;/h2&gt;
&lt;p&gt;让我们先回到模型 (3.5)：
$$
\begin{equation*}
\begin{aligned}
\min\ &amp;amp; F  \\
\text {s.t.}\ &amp;amp; f(\boldsymbol{x}, \boldsymbol \xi) \leq F &amp;amp;&amp;amp; \forall \boldsymbol \xi \in \mathcal{U}, \\
&amp;amp;h (\boldsymbol{x}, \boldsymbol \xi) \leq 0 &amp;amp;&amp;amp; \forall \boldsymbol \xi \in \mathcal{U}.
\end{aligned}
\end{equation*}
$$&lt;/p&gt;
&lt;p&gt;在这个模型中，假如 $\boldsymbol \xi$ 有 $N$ 个可能的取值 $\mathcal{U} = \{\boldsymbol \xi_1, \ldots, \boldsymbol \xi_N\}$，那么给定 $\boldsymbol x$ 和 $F$，约束$
f(\boldsymbol{x}, \boldsymbol \xi) \leq F\ \forall \boldsymbol \xi \in \mathcal{U}
$
就等价于
$$
f(\boldsymbol{x}, \boldsymbol \xi_i) \leq F \quad \forall i \in [N],
$$
共$N$个约束。相应的，$h (\boldsymbol{x}, \boldsymbol \xi) \leq 0\ \forall \boldsymbol \xi \in \mathcal{U}$ 也等价于
$$
h(\boldsymbol{x}, \boldsymbol \xi_i) \leq 0 \quad \forall i \in [N],
$$
共 $N$ 个约束。&lt;/p&gt;
&lt;p&gt;然而，如3.2小节所描述，常见的不确定集合大部分都是连续集 (continuous set) 而非离散集 (discrete set), 也即对于模型(3.5)来说，它将有无限多个约束，由此产生了一个半无限规划模型。显然，这是难以直接求解的。为了对鲁棒优化问题进行求解，我们需要对原模型做出一定程度的转化，使得转化后模型能够通过商业软件直接进行求解。在这方面做出重要突破的学者有Allen L. Soyster、Aharon Ben-Tal、Arkadi Nemirovski、Dimitris Bertsimas和Melvyn Sim等。&lt;/p&gt;
&lt;p&gt;实际上，对于任意形如
$$
g(\boldsymbol x, \boldsymbol \xi) \leq 0 \quad \forall \boldsymbol \xi \in \mathcal{U},
$$
的约束，我们都可以等价地将其写为：
$$
\sup_{\boldsymbol \xi \in \mathcal{U}} g(\boldsymbol x, \boldsymbol \xi) \leq 0.
$$
当函数$g$和集合$\mathcal{U}$满足一定条件时，不等式左边的问题可以转化为线性规划问题、凸优化问题、或者是锥优化问题。相应地，所对应的约束转化为线性约束、凸约束、或者锥约束。从而使得模型(3.5)能用商业软件进行求解。&lt;/p&gt;
&lt;p&gt;一般地，我们定义形如
$$
g(\boldsymbol x, \boldsymbol \xi) \leq 0 \quad \forall \boldsymbol \xi \in \mathcal{U}
$$
的式子为鲁棒约束 (robust constraint)。而将模型 (3.5)称为经典鲁棒优化模型，将其转化之后可以直接用商业软件进行求解的模型称为鲁棒对等问题 (robust counterpart)。而整个转化的过程大多数时候依赖于对偶理论。举例如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;font color=green&gt;示例3.1：&lt;/font&gt;&lt;/strong&gt; 考虑如下鲁棒优化问题
$$
\begin{equation}\label{model::example 1}
\begin{array}{rll}
\min &amp;amp; \boldsymbol c^\top \boldsymbol x \\
\mbox{s.t.} &amp;amp; b_0 + \boldsymbol x^\top \boldsymbol \xi \geq 0 \quad \forall \boldsymbol \xi \in \mathcal{U},\\
&amp;amp; \boldsymbol x \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.11}
$$&lt;/p&gt;
&lt;p&gt;其中$\mathcal{U} = \{\boldsymbol \xi: \boldsymbol A \boldsymbol \xi = \boldsymbol b, \boldsymbol \xi \geq 0\}$.&lt;/p&gt;
&lt;p&gt;约束 $b_0 + \boldsymbol x^\top \boldsymbol \xi \geq 0\ \forall \boldsymbol \xi \in \mathcal{U}$ 等价于$
b_0 + \inf_{\boldsymbol \xi \in \mathcal{U}}\ \boldsymbol x^\top \boldsymbol \xi \geq 0
$。对于不等式左边的问题$
\inf_{\boldsymbol \xi \in \mathcal{U}} \boldsymbol x^\top \boldsymbol \xi
$，由2.1可知其对偶问题为：
$$
\begin{aligned}
\sup &amp;amp;\quad \boldsymbol b^\top \boldsymbol p \\
\mbox{s.t.} &amp;amp;\quad \boldsymbol A^\top \boldsymbol p \leq \boldsymbol x.
\end{aligned}
$$
也即约束 $b_0 + \boldsymbol x^\top \boldsymbol \xi \geq 0\ \forall \boldsymbol \xi \in \mathcal{U}$ 等价于
$$
b_0 + \sup_{\boldsymbol A^\top \boldsymbol p \leq \boldsymbol x}\ \boldsymbol b^\top \boldsymbol p \geq 0 \Leftrightarrow b_0 + \boldsymbol b^\top \boldsymbol p \geq 0\quad \exists \boldsymbol p \mbox{ s.t. } \boldsymbol A^\top \boldsymbol p \leq \boldsymbol x.
$$
由此，可以得到问题 (3.11) 的鲁棒对等问题为：
$$
\begin{equation}\label{model::example 1 RC}
\begin{array}{rll}
\min &amp;amp; \boldsymbol c^\top \boldsymbol x \\
\mbox{s.t.} &amp;amp; b_0 + \boldsymbol b^\top \boldsymbol p \geq 0,\\
&amp;amp; \boldsymbol A^\top \boldsymbol p \leq \boldsymbol x, \\
&amp;amp; \boldsymbol x \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.12}
$$&lt;/p&gt;
&lt;h2 id=&#34;34-经典鲁棒模型&#34;&gt;3.4 经典鲁棒模型&lt;/h2&gt;
&lt;p&gt;接下来，我们将以Bertsimas and Sim (2003)为蓝本，简要介绍在鲁棒优化理论发展过程中经典的的三个模型：他们分别来自Soyster (1973)、Ben-Tal and Nemirovski (1999)和Bertsimas and Sim (2003)。&lt;/p&gt;
&lt;h3 id=&#34;341-soyster的鲁棒模型&#34;&gt;3.4.1 Soyster的鲁棒模型&lt;/h3&gt;
&lt;p&gt;如第一章所介绍，Soyster假设以下线性规划问题中
$$
\begin{equation}\label{model::LP}
\begin{array}{rl}
\max &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf { s.t. } &amp;amp; \displaystyle  \boldsymbol A \boldsymbol x \leq \boldsymbol{b},\\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0,
\end{array}
\end{equation}\tag{3.13}
$$
系数矩阵$\boldsymbol A$的每一列都在一个凸集中（也称为列不确定性），也即，$\boldsymbol A_{j} \in \mathcal{U}_{j}$，那么线性规划问题(3.13)将变成如下问题：
$$
\begin{equation}\label{model::Soyester}
\begin{array}{rl}
\max &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf { s.t. } &amp;amp; \displaystyle \sum_{j \in [N]} \boldsymbol A_{j} x_{j} \leq \boldsymbol{b} \quad \forall \boldsymbol A_{j} \in \mathcal{U}_{j}, j\in [N], \\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.14}
$$
其所对应的鲁棒对等问题为
$$
\begin{equation}\label{model::Soyester RC}
\begin{array}{rl}
\max &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf { s.t. } &amp;amp; \displaystyle \sum_{j \in [N]} \bar{\boldsymbol A}_{j} x_{j} \leq \boldsymbol{b}, \\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.15}
$$&lt;/p&gt;
&lt;p&gt;其中，$\bar{a}_{ij} = \sup_{\boldsymbol A_{j} \in \mathcal{U}_{j}} a_{ij}$。也即，对于每一个参数$a_{ij}$都取其在不确定集范围内的最大值。而这样得到的解虽然具有鲁棒性，但是同时也非常保守。&lt;/p&gt;
&lt;h3 id=&#34;342-ben-tal-和-nemirovski-的鲁棒模型&#34;&gt;3.4.2 Ben-Tal 和 Nemirovski 的鲁棒模型&lt;/h3&gt;
&lt;p&gt;Ben-Tal和Nemirovski也认同$a_{ij}$具有不确定性。但是不同于Soyster (1973)，Ben-Tal and Nemirovski (2000)假设$\boldsymbol{A}$的第 $i (i \in [M])$ 行中，只有部分系数&amp;mdash;用$\mathcal{J}_i$表示&amp;mdash;具有不确定性。如果我们用$\tilde{a}_{ij}$表示具有不确定性的系数，且$\tilde{a}_{ij} = a_{ij} + \hat{a}_{ij}\xi_{ij}$。其中, $\hat{a}_{ij}$ 为波动范围，$\xi_{ij}$为在$[-1,1]$内对称分布的随机变量，且满足$\|\boldsymbol \xi_i\|_2 \leq \Omega$。也即
$$
\begin{equation}\label{model::Bental Nemirovski}
\begin{array}{rl}
\max &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf { s.t. } &amp;amp; \displaystyle \sum_{j \in [N]} (a_{ij} + \xi_{ij}\hat{a}_{ij}) x_{j} \leq b_i \quad \forall \boldsymbol \xi_i \in \mathcal{U}:=\{\boldsymbol \xi: \|\boldsymbol \xi\|_2 \leq \Omega\}, i\in [M], \\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.16}
$$
其所对应的鲁棒对等问题为
$$
\begin{equation}
\begin{array}{rl}
\max &amp;amp; \boldsymbol{c}^{\top} \boldsymbol{x} \\
\mathbf { s.t. } &amp;amp; \displaystyle \sum_{j \in [N]} a_{ij} x_{j} + \Omega \sqrt{\sum_{j \in \mathcal{J}_i} \hat{a}_{ij}^2 x_{j}^2} \leq b_i, \\
&amp;amp; \boldsymbol{x} \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.17}
$$&lt;/p&gt;
&lt;p&gt;在此问题中，$\Omega$为一给定的常量，并无直观的意义。求解结果高度依赖于常量$\Omega$。此外，此问题虽然可以通过调节$\Omega$来避免Soyster (1973)的极端保守情况，仍然比较保守。同时，此问题为二阶锥规划问题，求解起来稍显繁琐。&lt;/p&gt;
&lt;h3 id=&#34;343-bertsimas-和sim-的鲁棒模型&#34;&gt;3.4.3 Bertsimas 和Sim 的鲁棒模型&lt;/h3&gt;
&lt;p&gt;为了克服 Soyster (1973)的保守性和Ben-Tal and Nemirovski (2000)中使用椭球不确定集而导致二阶锥规划问题，对于系数矩阵 &lt;em&gt;&lt;strong&gt;A&lt;/strong&gt;&lt;/em&gt; 中的第$i$行，Bertsimas and Sim (2004)提出了预算不确定集(budget uncertainty set):
$$
\mathcal{U}_i = \{\boldsymbol \xi_i: |\xi_{ij}| \leq 1, j \in [N], \|\boldsymbol \xi_i \|_1 \leq \Gamma_i \}.
$$
其中，$\Gamma_{i} \in [0,|\mathcal{J}_i|]$, $|\mathcal{J}_i|$表示第$i$行中不确定的参数个数。 也即，通过引入参数$\Gamma_{i}$来调节模型的保守程度。
假设不确定的参数个数不超过$\lfloor\Gamma_{i}\rfloor$个，其中$\lfloor\Gamma_{i}\rfloor$是小于等于$\Gamma_{i}$的最大整数，并且假设$a_{ij}$的波动范围为$(\Gamma_{i}-\lfloor\Gamma_{i}\rfloor) \hat{a}_{ij}$，Bertsimas和Sim提出以下鲁棒优化模型：
$$
\begin{equation}
\begin{array}{rl}
\max &amp;amp;\boldsymbol c^\top \boldsymbol{x}\\
{\rm s.t.} &amp;amp; \sum\limits_{j \in [N]} a_{ij} x_{j} + \underset{\big\{ \left. \mathcal{S}_i\cup \{ t_{i} \} \right| \mathcal{S}_i\subseteq \mathcal{J}_i, |\mathcal{S}_i|=\lfloor \Gamma_{i}\rfloor ,t_{i}\in \mathcal{J}_i \backslash \mathcal{S}_i \big\}} {\mathop{\max }}\, \bigg\{ \sum\limits_{j\in \mathcal{S}_i} \hat{a}_{ij}y_{j} + \left( \Gamma_{i} -\left\lfloor\Gamma_{i} \right\rfloor  \right) \hat{a}_{it_{i}} y_{t} \bigg\}\le b_{i} \quad \forall i \in [M], \\
&amp;amp;-y_{j} \leq x_{j} \leq y_{j} \quad \forall j \in [N], \\
&amp;amp;\boldsymbol{l} \leq \boldsymbol{x} \leq \boldsymbol{u}, \\
&amp;amp;\boldsymbol{y} \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.18}
$$
当$\Gamma_{i}$为整数时，此时$\Gamma_{i}=\lfloor\Gamma_{i}\rfloor$，对第$i$个约束，有如下形式:
$$
\begin{equation}
\sum\limits_{j \in [N]} a_{ij} x_{j} + \underset{\left\{ \left. \mathcal{S}_i\cup \{ t_{i} \} \right| \mathcal{S}_i\subseteq \mathcal{J}_i, |\mathcal{S}_i|=\lfloor \Gamma_{i}\rfloor ,t_{i}\in \mathcal{J}_i \backslash \mathcal{S}_i \right\}} {\mathop{\max }}\, \left\{ \sum\limits_{j\in \mathcal{S}_i} \hat{a}_{ij}y_{j} \right\}\le b_{i}
\end{equation}\tag{3.19}
$$
当$\Gamma_{i}$的值为0时，变量的系数均为标称值，约束变为名义问题（nominal problem）。当$\Gamma_{i}$取最大值$\lfloor\Gamma_{i}\rfloor$时，此时所有的不确定元素均不为标称值，模型等价于Soyster模型。当$\Gamma_{i}$的值介于最大值和最小值之间变动时，模型的保守度也相应变动。当$\Gamma_{i}$的值为$\Omega_{i} \sqrt{\sum_{j \in \mathcal{J}_i}\left(\hat{a}_{ij}^{2} x_{j}^{2}\right)}$时，约束违背（具体参考考Bertsimas and Sim 2004）的概率边界值与Ben-tal一致。因此，当$\Gamma_{i}$的值过小时，鲁棒优化模型保守性差，较大概率发生约束违背。当$\Gamma_{i}$的值过大时，计算结果过于保守。模型(3.18)是非线性模型，不能直接求解，Bertsimas和Sim对模型做出了如下转化：
$$
\begin{equation}
\begin{array}{rll}
\max &amp;amp;\boldsymbol c^\top \boldsymbol{x} \\
{\rm s.t.}\ &amp;amp;\displaystyle \sum_{j \in [N]} a_{ij} x_{j} + z_{i}\Gamma_{i} + \sum_{j \in \mathcal{J}_i} p_{ij} \leq b_{i} \quad &amp;amp;\forall i \in [M], \\
&amp;amp; z_{i} + p_{ij} \geq \hat{a}_{ij} y_{j} \quad &amp;amp;\forall j \in \mathcal{J}_i, i \in [M], \\
&amp;amp; -y_{j} \leq x_{j} \leq y_{j} \quad &amp;amp;\forall j \in [N], \\
&amp;amp; l_j \leq x_j \leq u_j \quad &amp;amp;\forall j \in [N],\\
&amp;amp; p_{ij} \geq 0 \quad &amp;amp;\forall j \in \mathcal{J}_i, i \in [M],\\
&amp;amp; y_j \geq 0 \quad &amp;amp;\forall j \in [N], \\
&amp;amp; z_{i} \geq 0 \quad &amp;amp;\forall i \in [M].
\end{array}
\end{equation}\tag{3.20}
$$
模型转化的理论依据是对偶理论，具体的证明过程在作者稿件中有详细描述，有兴趣的读者可以自行翻阅，这里不再赘述。在此基础上，Bertsimas and Sim (2003)提出了鲁棒离散优化的模型:
$$
\begin{equation} \label{model::robust model discrete}
\begin{array}{rll}
\max &amp;amp;\boldsymbol c^\top \boldsymbol{x} + \mathop {\max }\limits_{\left\{ {\left. \mathcal{S}_0 \right|\mathcal{S}_0 \subseteq \mathcal{J}_0,\left| \mathcal{S}_0 \right| \leqslant \Gamma _0} \right\}} \left\{ \sum\limits_{j \in \mathcal{S}_0} d_j\left| x_j \right|  \right\}\\
{\rm s.t.}\ &amp;amp;\sum\limits_{j \in [N]}a_{i j}x_{j}+\mathop {\max }\limits_{\left\{ {\left. {\mathcal{S}_i \cup \left\{ t_i \right\}} \right|\mathcal{S}_i \subseteq \mathcal{J}_i,\left| \mathcal{S}_i \right| = \left\lfloor \Gamma_i \right\rfloor, t_i \in \mathcal{J}_i\backslash \mathcal{S}_i} \right\}} \left\{ \sum\limits_{j \in \mathcal{S}_i} \hat{a}_{ij}\left| x_j \right| + \left( \Gamma_i - \left\lfloor \Gamma_i \right\rfloor \right)\hat{a}_{i{t_i}}\left| x_{t_i} \right| \right\} \le b_{i} \quad &amp;amp;\forall i \in [M], \\
&amp;amp; x_j \in \mathbb{Z} &amp;amp; \forall j \in [N].
%&amp;amp;\boldsymbol{l} \leq \boldsymbol{x} \leq \boldsymbol{u}, \\
%&amp;amp;-y_j \leq x_j \leq y_j \quad &amp;amp;\forall j \in [N], \\
%&amp;amp;\boldsymbol{y} \geq \boldsymbol 0
\end{array}
\end{equation}\tag{3.21}
$$
其中，$\Gamma_{0}$是区间$[0,|\mathcal{J}_0|]$内的整数，$\mathcal{J}_0=\{j|d_{j}&amp;gt;0\}$, $|\mathcal{J}_0|$是$\boldsymbol c$中不确定元素的个数。不同于Bertsimas and Sim (2004)，Bertsimas and Sim (2003)考虑了目标函数的不确定性。对于目标函数中的$\boldsymbol c$，允许变化的不确定元素有$\Gamma_{0}$个，取值为 $\mathop {\boldsymbol c^\top}\limits_{j \in \mathcal{S}_0}  + \mathop {\max }\limits_{\left\{ {\left. {\mathcal{S}_0} \right|\mathcal{S}_0 \subseteq \mathcal{J}_0,\left| {\mathcal{S}_0} \right| \leqslant {\Gamma _0}} \right\}} \sum\limits_{j \in \mathcal{S}_0} {{d_j}} $，其余均为标称值。&lt;/p&gt;
&lt;p&gt;同样的，模型(3.21)也需要经过处理才能求解，处理后的混合整数规划模型如下所示：
$$
\begin{equation}
\begin{array}{rll}
\max &amp;amp;\displaystyle \boldsymbol c^\top \boldsymbol{x} + z_{0} \Gamma_{0}+\sum_{j \in \mathcal{J}_0} p_{0j} \\
{\rm s.t.}\ &amp;amp;\displaystyle \sum_{j \in [N] } a_{ij} x_{j}+ z_{i} \Gamma_{i}+\sum_{j \in \mathcal{J}_i} p_{ij} \leq b_{i} \quad &amp;amp;\forall i \in [M], \\
&amp;amp; z_{0}+p_{0j} \geq d_{j} y_{j} \quad &amp;amp;\forall j \in \mathcal{J}_0,\\
&amp;amp; z_{i}+p_{ij} \geq \hat{a}_{ij} y_{j} \quad &amp;amp;\forall j \in \mathcal{J}_i,  i \in [M],\\
&amp;amp; p_{ij} \geq 0 \quad &amp;amp;\forall j \in \mathcal{J}_i, i \in [M], \\
&amp;amp; z_{i} \geq \boldsymbol 0 \quad &amp;amp;\forall i \in [M] \cup \{0\}, \\
&amp;amp; x_{i} \in \mathbb{Z} \quad &amp;amp;\forall i \in [M],\\
&amp;amp;\boldsymbol{l} \leq \boldsymbol{x} \leq \boldsymbol{u},\\
&amp;amp;-\boldsymbol{y} \leq \boldsymbol{x} \leq \boldsymbol{y}, &amp;amp;\\
&amp;amp;\boldsymbol{y} \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.22}
$$&lt;/p&gt;
&lt;p&gt;接下来，我们节选Bertsimas and Sim (2004)中的组合优化的例子来简要探讨鲁棒优化的具体运用。考虑如下的组合优化模型，
$$
\begin{equation} \label{model::portfolio}
\begin{array}{rl}
\max &amp;amp;\displaystyle \boldsymbol{p}^\top\boldsymbol{x} - \phi (\boldsymbol \sigma . \boldsymbol x )^\top (\boldsymbol \sigma . \boldsymbol x )\\
{\rm s.t.} &amp;amp;\boldsymbol{x}^\top \boldsymbol{1} = 1, \\
&amp;amp; \boldsymbol x \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.23}
$$&lt;/p&gt;
&lt;p&gt;其中，$x_i$定义决策变量代表每支股票的投资比例, $p_i$ 和 $\sigma_{i}$分别为股票$i$的期望回报率与回报率标准差，$\phi$是控制风险和回报之间交易的一个参数。&lt;/p&gt;
&lt;p&gt;考虑$N = 150$支股票，假如第$i$支股票的回报率的期望$p_i$和标准差$\sigma_i$分别为$p_{i}=1.15+i \frac{0.05}{150}, \quad \sigma_{i}=\frac{0.05}{450} \sqrt{2 i N(N+1)}$，且假设$\phi=5$来平衡投资的回报期望和风险。模型(3.23)所对应的鲁棒优化模型为：
$$
\begin{equation} \label{model:portfolio_robust}
\begin{array}{rl}
\max\ &amp;amp;z\\
{\rm s.t.}\ &amp;amp; z \leq \boldsymbol{p}^\top \boldsymbol{x}+\underset{\left\{ \left. \mathcal{S}_i\cup \left\{ t_i \right\} \right|\mathcal{S}_i\subseteq \mathcal{J}_i,\left| \mathcal{S}_i \right|=\left\lfloor {{\Gamma }_{i}}
\right\rfloor ,t_i\in \mathcal{J}_i\backslash \mathcal{S}_i \right\}}{\mathop{\max}}\,\left\{ \sum\limits_{j\in \mathcal{S}_i}\sigma_{j}x_{j}+\left( \Gamma_{i}-\left\lfloor \Gamma_{i} \right\rfloor  \right)\sigma_{i}x_{t_i} \right\}, \\
&amp;amp;\boldsymbol{x}^\top \boldsymbol{1} = 1, \\
&amp;amp;\boldsymbol x \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.24}
$$
其鲁棒对等模型为：
$$
\begin{equation}
\begin{array}{rl}
\max\ &amp;amp;z\\
{\rm s.t.}\ &amp;amp; z \leq \boldsymbol{p}^\top \boldsymbol{x} - \left ( \sum_{i \in [N]} Q_{i}+\Gamma_i m_i \right ), \\
&amp;amp;Q_{i}+m_{i}\geq \sigma_{i}x_{i} \quad \forall i \in [N],\\
&amp;amp;\boldsymbol{x}^\top \boldsymbol{1} = 1, \\
&amp;amp;\boldsymbol x, \boldsymbol Q, \boldsymbol m \geq \boldsymbol 0.
\end{array}
\end{equation}\tag{3.25}
$$
此外，根据Bertsimas and Sim (2004)中的&lt;strong&gt;Proposition 1&lt;/strong&gt;：
$$
\underset{\left\{ \left. \mathcal{S}_i\cup \left\{ t_i \right\} \right|\mathcal{S}_i\subseteq \mathcal{J}_i,\left| \mathcal{S}_i \right|=\left\lfloor \Gamma_i \right\rfloor ,t_i\in \mathcal{J}_i\backslash \mathcal{S}_i \right\}}{\mathop{\max }}\,\left\{ \sum\limits_{j\in \mathcal{S}_i}\hat{a}_{i j}y_{j}+\left( \Gamma_i-\left\lfloor \Gamma_i \right\rfloor  \right){a}_{it_i}y_{t_i} \right\}
$$
等价为以下的线性优化模型：
$$
\begin{equation}
\begin{array}{rl}
\beta_{i}\left(\boldsymbol{x}^{\ast}, \Gamma_{i}\right)=\max  &amp;amp; \sum_{j \in \mathcal{J}_i} \hat{a}_{i j}\left|x_{j}^{\ast}\right| z_{i j} \\
\text { s.t.} &amp;amp; \displaystyle \sum_{j \in \mathcal{J}_i} z_{i j} \leq \Gamma_{i} \\
&amp;amp; 0 \leq z_{i j} \leq 1 \quad \forall j \in \mathcal{J}_i
\end{array}
\end{equation}\tag{3.26}
$$
也即，我们可将模型(3.24)写为
$$
\begin{array}{rl}
\max &amp;amp;\min\limits_{\pmb{z}\in \mathcal{U}}\ \boldsymbol{p}^\top\boldsymbol{x} - \boldsymbol x^\top (\boldsymbol \sigma . \boldsymbol z )  \\
{\rm s.t.} &amp;amp;\boldsymbol{x}^\top \boldsymbol{1} = 1, \\
&amp;amp;\boldsymbol x \geq \boldsymbol 0.
\end{array}
$$
在该模型中，随机变量$\pmb{z}$代表实际股票回报率和期望值间的偏差。这个随机变量被约束在一个预算不确定集（Budget uncertainty set）$\mathcal{U}$中：
$$
\begin{align}
\mathcal{U} = \left\{\pmb{z}|\ 0\leq z_{i j} \leq 1,  \sum_{j \in \mathcal{J}_i} z_{i j} \leq \Gamma_{i} \right\} %\rightarrow
\end{align}\tag{3.27}
$$
大部分鲁棒优化问题都可以用优化工具直接求解。我们将在本书后续章节介绍相关内容。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A, Cooper WW Chames&lt;/strong&gt;, Chance-Constrained Programming, INFORMS, 1959.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Baringo, Luis and Ana Baringo&lt;/strong&gt;, “A Stochastic Adaptive Robust Optimization Approach for the Generation and Transmission Expansion Planning,” IEEE Transactions on Power Systems, 2017, PP (99), 1–1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ben-Tal, A. and A. Nemirovski&lt;/strong&gt;, “Robust Convex Optimization,” Mathematics of Operations Research, 1998, 23 (4), 769–805.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_and_&lt;/strong&gt;, “Robust solutions of uncertain linear programs,” Operations Research Letters, 1999, pp. 1–13.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ben-Tal, Aharon and Arkadi Nemirovski&lt;/strong&gt;, “Robust solutions of linear programming problems contaminated with uncertain data,” Mathematical Programming, 2000, 88 (3), 411–424.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_, Laurent El Ghaoui, and Arkadi Nemirovski&lt;/strong&gt;, Robust Optimization 2009.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bertsimas, Dimitris and Aurľlie Thiele&lt;/strong&gt;, “Robust and Data-Driven Optimization: Modern Decision Making Under Uncertainty,” Tutorials in Operations Research, 04 2006, 4.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_and Melvyn Sim&lt;/strong&gt;, “Robust discrete optimization and network flows,” Mathematical Programming, 2003, 98(1-3), 49–71.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_and_&lt;/strong&gt;, “The Price of Robustness,” Operations Research, 2004, 52 (1), 35–53.
&lt;strong&gt;Bertsimas, Dimitris J., David B. Brown, and Constantine Caramanis&lt;/strong&gt;, “Theory and Applications of Robust Optimization,” Siam Review, 2010, 53 (3), 464–501.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bertsimas, Dimitris, Vishal Gupta, and Nathan Kallus&lt;/strong&gt;, “Data-driven robust optimization,” Mathematical Programming, 2018, 167 (2), 235–292.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Birge, John R and Francois Louveaux&lt;/strong&gt;, Introduction to stochastic programming 2011.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Boyd, Stephen and Lieven Vandenberghe&lt;/strong&gt;, “Convex optimization,” IEEE Transactions on Automatic Control, 2006, 51 (11), 1859–1859.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;E, Bellmann R.&lt;/strong&gt;, “Decision Making in a Fuzzy Environment,” Management science, 1970, (17).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ghaoui, Laurent Oustry Francois Lebret El&lt;/strong&gt;, “Robust Solutions to Uncertain Semidefinite Programs,” SIAM Journal on Optimization, 1998, 9(1), 33–52.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Laurent, El Ghaoui I. and Lebret I. Herv&lt;/strong&gt;, “Robust Solutions To Least-Squares Problems With Uncertain Data,” in “International Workshop on Recent Advances in Total Least Squares Techniques &amp;amp; Errors-in-variables Modeling” International Workshop on Recent Advances in Total Least Squares Techniques &amp;amp;
Errors-in-variables Modeling 1997.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Liu, Baoding&lt;/strong&gt;, “Dependent-chance programming: A class of stochastic optimization,” Computers &amp;amp; Mathematics with Applications, 1997, 34 (12), 89–104.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;M, Mulvey J., Vanderbei R. J, and Zenios S. A&lt;/strong&gt;, “Zenios S A . Robust Optimization of Large-Scale Systems,” Operations Research, 1995, 43 (2), 264–281.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;R, Jiang, Zhang M, and Li G&lt;/strong&gt;, “Two-StageRobust Power Grid Optimization Problem,” Social Science Electronic Publishing, 2010.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Soyster, Allen L.&lt;/strong&gt;, “Technical Note-Convex Programming with Set-Inclusive Constraints and Applications to Inexact Linear Programming.,” Operations Research, 1973, 21 (5), 1154–1157.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;刘宝碇&lt;/strong&gt;, 随机规划与模糊规划, 清华大学出版社, 1998.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;陈宝林&lt;/strong&gt;, 最优化理论与算法, 清华大学出版社, 2005.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;指约束条件中，等式或不等式两边含有模糊集合，因而不能像精确数学里一样判定等式成立或者不成立。&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
      
    </item>
    
    <item>
      <title>第四章 分布鲁棒优化（模糊集、机会约束问题、分布鲁棒线性优化）</title>
      <link>https://allenz-me.github.io/RoSite/post/ch4/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/ch4/</guid>
      
        <description>&lt;p&gt;现实世界的优化问题指在满足相关约束条件的前提下，确定一组决策变量的值，使预设的目标函数值最优。相关研究成果（理论、模型、算法、应用）在管理科学、金融工程、军事指挥等领域发挥着巨大指导作用，创造了巨大的社会经济价值。&lt;/p&gt;
&lt;p&gt;由于本书定位为入门级、科普级，本章将以优化问题中一类简单但重要的线性优化（亦称线性规划）问题为例，阐述&lt;strong&gt;分布鲁棒优化&lt;/strong&gt;的基本思想、基本模型、基本结论。感兴趣的读者需细读相关文献以获得更深入广泛的理解。&lt;/p&gt;
&lt;p&gt;线性规划问题 (4.1) 中，决策变量为 $\boldsymbol{x} \in \mathbb{R}^I$，环境参数包括费用向量 $\boldsymbol{a}_0 \in \mathbb{R}^I$、约束条件左端项系数向量 $\boldsymbol{a}_m \in \mathbb{R}^I$、右端项系数 $b_m \in \mathbb{R}$，这些参数为确定值。线性规划可用于解决许多现实问题，例如投资组合优化、生产计划、最短路等问题。
$$
\begin{equation}
\label{ro.mod.lo}
\begin{array}{rll}
\displaystyle \min_{\boldsymbol{x}} &amp;amp; \boldsymbol{a}_0^\top \boldsymbol{x}, \\
\mbox{s.t.} &amp;amp; \boldsymbol{a}_m^\top \boldsymbol{x} \le b_m, &amp;amp; m \in [M]. \tag{4.1}
\end{array}
\end{equation}
$$
现实世界中描述未来发生事件的环境参数在优化/规划/计划阶段往往不确定，例如未来某商品需求量、两地间旅行时长、某股票回报率等。为了让优化结果对现实更具指导意义，在优化模型中考虑环境参数的不确定性至关重要。&lt;/p&gt;
&lt;p&gt;在不确定环境下，(4.1) 中对于某一 $m \in [M]$ 的约束式变成了
$$
\begin{equation}
\label{dro.con.1}
\boldsymbol{a}(\tilde{\boldsymbol{\varepsilon}})^\top\boldsymbol{x} \le  b(\tilde{\boldsymbol{\varepsilon}}). \tag{4.2}
\end{equation}
$$
其中，为了阐述方便，忽略下标 $m$；随机变量 $\tilde{\boldsymbol{\varepsilon}}$ 表示影响环境参数的随机因素（例如，旅行时长受天气、交通灯时长等随机因素影响），假设 $\boldsymbol{a}(\tilde{\boldsymbol{\varepsilon}})$ 和 $b(\tilde{\boldsymbol{\varepsilon}})$ 皆为 $\tilde{\boldsymbol{\varepsilon}}$ 的仿射函数，即
$\boldsymbol{a}(\tilde{\boldsymbol{\varepsilon}}) \triangleq \boldsymbol{a}^0 + \sum_{j \in [J]}\boldsymbol{a}^j \tilde{\varepsilon}_j, b(\tilde{\boldsymbol{\varepsilon}}) \triangleq b^0 + \sum_{j \in [J]}b^j \tilde{\varepsilon}_j$，
则有
$$
\begin{equation*}
\boldsymbol{a}(\tilde{\boldsymbol{\varepsilon}})^\top \boldsymbol{x} - b(\tilde{\boldsymbol{\varepsilon}})
= \underbrace{(\boldsymbol{a}^{0})^\top\boldsymbol{x} - b^0}_{=y^0(\boldsymbol{x})} + \sum_{j \in [J]}\big(\underbrace{(\boldsymbol{a}^{j})^\top\boldsymbol{x} - b^j}_{=y^j(\boldsymbol{x})}\big)\tilde{\varepsilon}_j = y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})&#39;\tilde{\boldsymbol{\varepsilon}}.
\end{equation*}
$$
因此，约束式 (4.2) 等价于
$$
\begin{equation}
\label{dro.con.2}
y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0. \tag{4.3}
\end{equation}
$$
不确定环境下的线性规划从技术上主要关注如何处理约束式 (4.3)。因其左端项为随机变量而右端项为实数，故通常意义上无法直接比较大小，“$\le$” 符号用在此处不够严谨。对此，本章主要介绍两种典型处理方式，第4.2节基于&lt;strong&gt;分布鲁棒机会约束规划&lt;/strong&gt;思想，介绍如何处理
$$
\begin{equation}
\label{dro.con.cc}
\mathbb{P} [y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0] \ge 1 - \epsilon, \quad \forall \mathbb{P} \in \mathscr{F}, \tag{4.4}
\end{equation}
$$
也就是约束 (4.3) 成立的概率不小于 $1 - \epsilon$，其中阈值 $\epsilon \in [0, 1]$ 典型取值为 1% 或 5%。第4.3节基于&lt;strong&gt;分布鲁棒线性优化&lt;/strong&gt;范式，介绍如何处理
$$
\begin{equation}
\label{dro.con.lo}
\mathbb{E}_{\mathbb{P}} [y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}}] \le 0, \quad \forall \mathbb{P} \in \mathscr{F}, \tag{4.5}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;也就是约束 (4.3) 需在其左端项通过均值来度量的情况下满足。&lt;/p&gt;
&lt;p&gt;事实上，目标函数参数不确定性亦可纳入约束讨论，因为通过引入辅助决策变量 $t \in \mathbb{R}$，(4.1)等价于
$$
\begin{array}{rll}
\displaystyle \min_{t, \boldsymbol{x}} &amp;amp; t, \\
\mbox{s.t.} &amp;amp; \boldsymbol{a}_0^\top \boldsymbol{x} \le t, \\
&amp;amp;\boldsymbol{a}_m^\top \boldsymbol{x} \le b_m, &amp;amp; m \in [M].
\end{array}
$$
进而将目标函数中不确定参数 $\boldsymbol{a}_0$ 置于约束中。&lt;/p&gt;
&lt;p&gt;约束式 (4.4) 和 (4.5) 中，随机变量 $\tilde{\boldsymbol{\varepsilon}}$ 服从联合概率分布 $\mathbb{P}$，而 $\mathbb{P}$ 本身也不确定，属于模糊集 $\mathscr{F}$；第4.1节将介绍模糊集相关内容。分布鲁棒优化采取保守策略，令这两个约束条件对模糊集中所有概率分布皆满足，它也是因此得名&amp;mdash;“鲁棒”的内涵是考虑最坏情况，而“分布”表明最坏情况的主体是环境参数的分布函数。望本章内容能抛砖引玉，启发读者研究和处理更复杂的形式，并用于解决实际问题。&lt;/p&gt;
&lt;h2 id=&#34;41--模糊集ambiguity-set&#34;&gt;4.1  模糊集（Ambiguity set）&lt;/h2&gt;
&lt;p&gt;问题环境中随机参数的分布函数往往难以从现实世界直接获取。鉴于此，分布鲁棒优化方法假设其分布函数并不明确，而是处于一个&lt;strong&gt;模糊集&lt;/strong&gt;(ambiguity set) 中。模糊集通过随机变量的不完全分布信息构建而成。特别地，它还需保证相应分布鲁棒优化模型在计算上可处理 (tractable)，也就是现实规模问题可在允许时间范围内求解。&lt;/p&gt;
&lt;p&gt;从数学上说，分布鲁棒优化囊括随机规划(stochastic programming) 和传统鲁棒优化(robust optimization)为特殊形式，因此分布鲁棒优化更具一般性。当环境变量 $\tilde{\boldsymbol{\varepsilon}}$ 的分布函数 $\mathbb{P}_0$ 可获知时，可令模糊集为单元素集 $\mathscr{F}_S \triangleq \{\mathbb{P}_0\}$，则分布鲁棒优化退化为随机规划；当仅知环境变量的不确定集 $\Xi$ 时，可令模糊集为 $\mathscr{F}_R \triangleq \mathscr{P}_0(\Xi)$，即支撑集为 $\Xi$ 的所有概率分布函数之集合，则分布鲁棒优化退化为经典鲁棒优化。&lt;/p&gt;
&lt;p&gt;按照描述分布函数的信息种类划分，目前相关研究主要提出了两类模糊集。&lt;/p&gt;
&lt;h3 id=&#34;411-基于广义矩信息generalized-moment-information的模糊集&#34;&gt;4.1.1 基于广义矩信息（generalized moment information）的模糊集&lt;/h3&gt;
&lt;p&gt;在统计学中，矩 (moment) 表征随机变量的分布。对于随机变量 $\tilde{\varepsilon}$，其 $n$ 阶矩被定义为 $\mathbb{E}_\mathbb{P}[\tilde{\varepsilon}^n]$，$n \ge 1$。因此，随机变量一阶矩为均值，表征其位置 (location)，二阶矩与方差有关，表征其散度 (dispersion)，三阶矩表征其偏斜度，等等。&lt;/p&gt;
&lt;p&gt;更广义地，还可利用其它形式表征随机变量的位置、散度、偏斜度等特性。例如，绝对离差均值  $\mathbb{E}_{\mathbb{P}}[|\tilde{\varepsilon} - \mu|]$ 可表征 $\tilde{\varepsilon}$ 的散度，其中 $\mu$ 为其均值。再如，半绝对离差均值 $\mathbb{E}_{\mathbb{P}}[(\tilde{\varepsilon} - \mu)^+]$ 和 $\mathbb{E}_{\mathbb{P}}[(\mu - \tilde{\varepsilon})^+]$ 可从某种程度刻画 $\tilde{\varepsilon}$ 的偏斜度，其中 $(x)^+ \triangleq \max\{x, 0\}$。&lt;/p&gt;
&lt;p&gt;早期研究往往假设随机参数的概率分布无法准确获取，但其部分广义矩信息（和支撑集）可获取或估计，于是根据这些信息构建模糊集。例如，通过 $\tilde{\boldsymbol{\varepsilon}}$ 的均值 $\boldsymbol{\mu}$ 和协方差矩阵 $\boldsymbol{\Sigma}$ 构成的模糊集 (Ghaoui et al., 2003; Popescu, 2007; Chen and Sim, 2009)  为
$$
\begin{equation}
\label{eq.dro.as.mv}
\mathscr{F}_{MV} = \left\{
\mathbb{P} \in \mathscr{P}_0(\mathbb{R}^J)
\left|\begin{array}{l}
\tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P} \\
\mathbb{E}_\mathbb{P}[\tilde{\boldsymbol{\varepsilon}}] = \boldsymbol{\mu} \\
\mathbb{E}_\mathbb{P}[(\tilde{\boldsymbol{\varepsilon}} -\boldsymbol{\mu}) (\tilde{\boldsymbol{\varepsilon}} - \boldsymbol{\mu})&#39;] = \boldsymbol{\Sigma} \\ \tag{4.6}
\end{array}
\right.
\right\}.
\end{equation}
$$
如果进一步考虑支撑集 $\Xi$，则模糊集为 $\mathscr{F}_{MVS} = \mathscr{F}_{MV} \cap \mathscr{P}_0(\Xi)$. 但研究表明，基于 $\mathscr{F}_{MVS}$ 的分布鲁棒优化模型一般不可处理 (Bertsimas and Popescu, 2005; Natarajan et al., 2011)。而如果给定的 $\boldsymbol{\Sigma}$ 不是准确协方差而是协方差的上界时，则模糊集为
$$
\begin{equation}
\label{eq.dro.as.moment}
\mathscr{F}_{M} = \left\{
\mathbb{P} \in \mathscr{P}_0(\Xi)
\left|
\begin{array}{l}
\tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P} \\
\mathbb{E}_\mathbb{P}[\tilde{\boldsymbol{\varepsilon}}] = \boldsymbol{\mu} \\
\mathbb{E}_\mathbb{P}[(\tilde{\boldsymbol{\varepsilon}} -\boldsymbol{\mu}) (\tilde{\boldsymbol{\varepsilon}} - \boldsymbol{\mu})&#39;] \preceq \boldsymbol{\Sigma}
\end{array} \tag{4.7}
\right.
\right\},
\end{equation}
$$
其中 “$\preceq$”为半正定锥空间意义上的小于等于，也就是 $\boldsymbol{X} \preceq \boldsymbol{Y}$ 意味着 $\boldsymbol{Y} - \boldsymbol{X}$ 为半正定矩阵。有趣的是，基于 $\mathscr{F}_{M}$ 的分布鲁棒线性优化模型却可处理(Wiesemann et al., 2014; Hanasusanto et al., 2015)。&lt;/p&gt;
&lt;p&gt;Delage and Ye (2010) 研究了 $\mathscr{F}_{M}$ 的一个变种
$$
\begin{equation}
\label{eq.dro.as.moment.dy}
\mathscr{F}_{DY} = \left\{
\mathbb{P} \in \mathscr{P}_0(\Xi)
\left|
\begin{array}{l}
\tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P} \\
(\mathbb{E}_{\mathbb{P}}[\tilde{\boldsymbol{\varepsilon}}] - \boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbb{E}_{\mathbb{P}}[\tilde{\boldsymbol{\varepsilon}}] - \boldsymbol{\mu}) \le \gamma_1 \\
\mathbb{E}_\mathbb{P}[(\tilde{\boldsymbol{\varepsilon}} -\boldsymbol{\mu}) (\tilde{\boldsymbol{\varepsilon}} - \boldsymbol{\mu})&#39;] \preceq \gamma_2 \boldsymbol{\Sigma}
\end{array} \tag{4.8}
\right.
\right\},
\end{equation}
$$
其中第一个约束指 $\tilde{\boldsymbol{\varepsilon}}$ 的均值处于一个以 $\boldsymbol{\mu}$ 为球心的椭球中，$\gamma_1 \ge 0$ 和 $\gamma_2 \ge 1$ 为两个参数。从数据驱动的视角看，假设 $\tilde{\boldsymbol{\varepsilon}}$ 客观上服从概率分布 $\mathbb{P}_0$，但无法观测该分布，而仅能观测其 $N$ 组样本/历史数据/观测值 $(\hat{\boldsymbol{\varepsilon}}_\omega)_{\omega \in [N]}$，令
$$
\boldsymbol{\mu} \triangleq \frac{1}{N}\sum_{\omega \in [N]} \hat{\boldsymbol{\varepsilon}}_\omega, \qquad \boldsymbol{\Sigma} \triangleq \frac{1}{N} \sum_{\omega \in [N]} (\hat{\boldsymbol{\varepsilon}}_\omega - \boldsymbol{\mu}) (\hat{\boldsymbol{\varepsilon}}_\omega - \boldsymbol{\mu})^\top,
$$
且 $\gamma_1$ 和 $\gamma_2$ 通过与样本量 $N$ 和参数 $\delta &amp;gt; 0$ 有关的某函数给定时（随着 $N \rightarrow \infty$，有 $\gamma_1 \rightarrow 0$ 和 $\gamma_2 \rightarrow 1$），则 Delage and Ye (2010) 证明了在统计学上 $\mathbb{P}_0 \in \mathscr{F}_{DY}$ 的置信度大于等于 $1 - \delta$。&lt;/p&gt;
&lt;p&gt;并非任意基于广义矩信息（和支撑集）的模糊集都能保证相应分布鲁棒优化模型可处理。Wisemann，Kuhn 和 Sim 提出了一种具有一般性的模糊集表达形式，能囊括 $\mathscr{F}_M$ 和 $\mathscr{F}_{DY}$ 为其特殊形式，能建模许多其它的广义矩信息，如绝对离差、半方差、高阶矩等，且（在一些技术性假设条件下）对于分布鲁棒线性优化在计算上可处理 (Wiesemann et al., 2014; Hanasusanto et al., 2015)。其形式为
$$
\begin{equation}
\label{eq.dro.as.wks}
\mathscr{F}_{WKS} = \left\{
\mathbb{P} \in \mathscr{P}_0(\mathbb{R}^J \times \mathbb{R}^L)
\left|
\begin{array}{ll}
(\tilde{\boldsymbol{\varepsilon}}, \tilde{\boldsymbol{u}}) \sim \mathbb{P} \\
\mathbb{E}_\mathbb{P}[\boldsymbol{A}\tilde{\boldsymbol{\varepsilon}} + \boldsymbol{B} \tilde{\boldsymbol{u}}] = \boldsymbol{b} \\
\mathbb{P}[(\tilde{\boldsymbol{\varepsilon}}, \tilde{\boldsymbol{u}}) \in \Xi_k] \in [\underline{p}_k, \overline{p}_k], \forall k \in [K]
\end{array}
\right.
\right\},
\end{equation} \tag{4.9}
$$
其中 $\mathbb{P}$ 为 $\tilde{\boldsymbol{\varepsilon}}$ 和辅助随机变量 $\tilde{\boldsymbol{u}}$ 的联合概率分布，$\boldsymbol{A} \in \mathbb{R}^{J \times Q}$，$\boldsymbol{B} \in \mathbb{R}^{L \times Q}$，$\boldsymbol{b} \in \mathbb{R}^Q$；置信集合 $\Xi_k$ 给定为
$$
\begin{equation}
\label{eq.support.set}
\Xi_k = \{
(\boldsymbol{\varepsilon}, \boldsymbol{u}) \in \mathbb{R}^J \times \mathbb{R}^L |
\boldsymbol{C}_k \boldsymbol{\varepsilon} + \boldsymbol{D}_k \boldsymbol{u} \preceq_{\mathscr{K}_k} \boldsymbol{c}_k
\},
\end{equation} \tag{4.10}
$$&lt;/p&gt;
&lt;p&gt;其中 $\boldsymbol{C}_k \in \mathbb{R}^{J \times R}$，$\boldsymbol{D}_k \in \mathbb{R}^{L \times R}$，$\boldsymbol{c} \in \mathbb{R}^R$，而 $\mathscr{K}_k$ 代表某一真锥 (proper cone)，如非负象限、二阶锥、半正定锥等。在此，“$\preceq_{\mathscr{K}_k}$”是在该锥空间意义上的小于等于；关于锥和相应的锥规划 (conic programming) 问题相关介绍，可参见  Ben-Tal and Nemirovski (2001)。对于表示概率界的 $\underline{\boldsymbol{p}},\overline{\boldsymbol{p}} \in [0, 1]^K$，有 $\underline{\boldsymbol{p}} \le \overline{\boldsymbol{p}}$。&lt;/p&gt;
&lt;p&gt;模糊集 $\mathscr{F}_{WKS}$ 巧妙之处在于引入了辅助随机变量 $\tilde{\boldsymbol{u}}$，这为计算上的可处理性提供了一种有效途径，如下例所示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;示例4.1&lt;/strong&gt;：通过 $\tilde{\boldsymbol{\varepsilon}}$ 的均值 $\boldsymbol{\mu}$ 、绝对离差均值上界 $\boldsymbol{\sigma}$、半绝对离差均值上界 $\boldsymbol{h}$ 及满足 (4.10)形式的支撑集 $\Xi$ 构成的模糊集为
$$
\begin{equation}
\label{eq.dro.as.mad}
\mathscr{F}_{MAD} = \left\{
\mathbb{P} \in \mathscr{P}_0(\Xi)
\left|
\begin{array}{l}
\tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P} \\
\mathbb{E}_\mathbb{P}[\tilde{\boldsymbol{\varepsilon}}] = \boldsymbol{\mu} \\
\mathbb{E}_\mathbb{P}[|\tilde{\boldsymbol{\varepsilon}} -\boldsymbol{\mu}|] \le \boldsymbol{\sigma} \\
\mathbb{E}_\mathbb{P}[(\tilde{\boldsymbol{\varepsilon}} -\boldsymbol{\mu})^+] \le \boldsymbol{h}
\end{array}
\right.
\right\},
\end{equation} \tag{4.11}
$$
其中 $|\tilde{\boldsymbol{\varepsilon}}|$ 代表对向量 $\tilde{\boldsymbol{\varepsilon}}$ 的每个元素分别取绝对值构成的向量，取正符 $(\tilde{\boldsymbol{\varepsilon}})^+$ 亦然。目前虽无法直接处理基于 $\mathscr{F}_{MAD}$ 的分布鲁棒优化模型，但如引入辅助变量，$\mathscr{F}_{MAD}$ 则变成
$$
\begin{equation}
\label{eq.dro.as.ma}
\mathscr{F}_{MADL} = \left\{
\mathbb{P} \in \mathscr{P}_0(\bar{\Xi})
\left|
\begin{array}{l}
(\tilde{\boldsymbol{\varepsilon}}, \tilde{\boldsymbol{u}}, \tilde{\boldsymbol{v}}) \sim \mathbb{P} \\
\mathbb{E}_\mathbb{P}[\tilde{\boldsymbol{\varepsilon}}] = \boldsymbol{\mu} \\
\mathbb{E}_\mathbb{P}[\tilde{\boldsymbol{u}}] = \boldsymbol{\sigma} \\
\mathbb{E}_\mathbb{P}[\tilde{\boldsymbol{v}}] = \boldsymbol{h}
\end{array}
\right.
\right\},
\end{equation} \tag{4.12}
$$&lt;/p&gt;
&lt;p&gt;其中，扩展的支撑集为
$$
\bar{\Xi} = \{(\boldsymbol{\varepsilon}, \boldsymbol{u}, \boldsymbol{v}) | \boldsymbol{\varepsilon} \in \Xi,  \boldsymbol{u} \ge \boldsymbol{\varepsilon} -\boldsymbol{\mu}, \boldsymbol{u} \ge \boldsymbol{\mu} - \boldsymbol{\varepsilon}, \boldsymbol{v} \ge \boldsymbol{\varepsilon} - \boldsymbol{\mu}, \boldsymbol{v} \ge \boldsymbol{0}\}.
$$
在此，$\mathscr{F}_{MADL}$ 即为 $\mathscr{F}_{WKS}$ 的一个特例，因此变得可处理；对于具体处理方法，可参见 Wiesemann et al. (2014); Hanasusanto et al. (2015)。类似地，前文提到的 $\mathscr{F}_{DY}$ 和 $\mathscr{F}_{M}$ 以及文献中更多有趣的形式 （例如，Bertsimas et al., 2019），也可借助辅助变量化为 $\mathscr{F}_{WKS}$ 的形式。&lt;/p&gt;
&lt;h3 id=&#34;412--基于统计距离-statistical-distance-的模糊集&#34;&gt;4.1.2  基于统计距离 (statistical distance) 的模糊集&lt;/h3&gt;
&lt;p&gt;在大数据时代背景下，问题环境中随机参数的历史数据越来越容易获取。为了获得随机参数概率分布，一种自然的想法是通过历史数据对应的经验分布来近似描述真实概率分布。经验分布是建立在 $N$ 条历史数据点上的离散均匀分布，它视每一条历史数据 $\hat{\boldsymbol{\varepsilon}}_\omega$ 为随机变量的一个支撑点，出现概率为$1/N$，即
$$
\hat{\mathbb{P}}[\tilde{\boldsymbol{\varepsilon}}^\dagger = \hat{\boldsymbol{\varepsilon}}_\omega] = \frac{1}{N}, ~ \forall \omega \in [N].
$$
其中 $\tilde{\boldsymbol{\varepsilon}}^\dagger$ 表示 $\tilde{\boldsymbol{\varepsilon}}$ 对应的经验随机变量。&lt;/p&gt;
&lt;p&gt;但经验分布并不等同于真正概率分布，分布鲁棒优化的思想是假设真正概率分布与经验分布在概率空间中的统计距离不超过某一阈值，并以此构建模糊集。
基于此思想，如何定义两个概率分布间的统计距离成为了关键，它不仅需要具有良好的统计学意义，而且需要保证相应的分布鲁棒优化模型可处理。在此例举两种典型形式。&lt;/p&gt;
&lt;p&gt;第一是基于$\phi$-散度 ($\phi$-divergence) 的模糊集，定义为
$$
\begin{equation}
\label{eq.dro.as.pd}
\mathscr{F}_{\phi} = \left\{
\mathbb{P} \in \mathscr{P}_0(\mathbb{R}^J)
\left|
\begin{array}{l}
\tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P}, \tilde{\boldsymbol{\varepsilon}}^\dagger \sim \hat{\mathbb{P}}, \\
D_\phi(\mathbb{P}||\hat{\mathbb{P}}) \le \theta
\end{array}
\right.
\right\},
\end{equation} \tag{4.13}
$$
其中 $D_\phi(\mathbb{P}||\hat{\mathbb{P}})$ 表示所认为的真正分布 $\mathbb{P}$ 对于经验分布 $\hat{\mathbb{P}}$ 的 &lt;strong&gt;$\phi$-散度&lt;/strong&gt;（“距离”），定义如 (4.14)；而 $\theta &amp;gt; 0$ 为给定的“距离”上界。&lt;/p&gt;
&lt;p&gt;$$
\begin{equation}
D_\phi(\mathbb{P}||\hat{\mathbb{P}}) = \sum_{\omega \in [N]} \hat{\mathbb{P}}(\omega) \phi \left(\frac{\mathbb{P}(\omega)}{\hat{\mathbb{P}}(\omega)}\right) \tag{4.14}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;在 (4.14)中，$\phi:\mathbb{R}_+ \mapsto \mathbb{R}$ 为满足以下条件的凸函数：$\phi(1) = 0$，对于 $x &amp;gt; 0$ 有 $0\phi(x/0)\triangleq x \lim_{t \rightarrow +\infty} \phi(t) / t$，且 $0\phi(0 / 0) \triangleq 0$；$\mathbb{P}(\omega)$ 表示概率分布 $\mathbb{P}$ 中第 $\omega \in [N]$ 个观测值发生的概率。可见，该模糊集要求真正的概率分布函数支撑集与经验分布支撑集相同，也就无法考量到历史数据以外的点/场景，而仅仅是将历史数据发生的概率从经验分布的各 $1/N$ 变成了更具“鲁棒性”的值。&lt;/p&gt;
&lt;p&gt;示例4.2：在此例举一种研究相对较多的 $\phi$ 函数形式：当 $\phi(x) = x \log x - x + 1$ 时，$\phi$散度具体化为 (4.15)，名为&lt;strong&gt;Kullback-Leibler 散度&lt;/strong&gt;(KL divergence)，又名&lt;strong&gt;相对熵 (relative entropy)&lt;/strong&gt;。
$$
\begin{equation}
D_{KL}(\mathbb{P}||\hat{\mathbb{P}}) = \sum_{\omega \in [N]} \mathbb{P}(\omega) \log \left(\frac{\mathbb{P}(\omega)}{\hat{\mathbb{P}}(\omega)}\right) \tag{4.15}
\end{equation}
$$
为后文阐述方便，将其模糊集记为 $\mathscr{F}_{KL}$，也就是 (4.13)中的将 $D_\phi$ 具体化为 $D_{KL}$。对于更多的 $\phi$ 函数形式，可参见 Ben-Tal et al. (2013); Jiang and Guan (2016)。&lt;/p&gt;
&lt;p&gt;第二是基于 Wasserstein 距离的模糊集，定义为
$$
\begin{equation}
\mathscr{F}_W = \left\{ \mathbb{P} \in \mathscr{P}_0(\Xi)
~\left|~
\begin{array}{l}
\displaystyle \tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P}, \tilde{\boldsymbol{\varepsilon}}^\dagger \sim \hat{\mathbb{P}}, \\
\displaystyle d_W(\mathbb{P}, \hat{\mathbb{P}}) \le \theta, \\
\end{array}\right.
\right\}. \tag{4.16}
\end{equation}
$$
此模糊集囊括了概率空间中以 Wasserstein 距离为度量标准，以经验分布 $\hat{\mathbb{P}}$ 为球心，以 $\theta \in \mathbb{R}_+$ 为半径的球中所有的概率分布。Esfahani and Kuhn (2018)的研究表明，记真实但未知的概率分布为 $\mathbb{P}_0$，则当 $\theta$ 通过与样本量 $N$ 和参数 $\mathbb{E}ta \in (0,1)$ 有关的某函数取值时（随着 $N \rightarrow \infty$，有 $\theta \rightarrow 0$），从统计学上可证明 $\mathbb{P} \in \mathscr{F}_W$ 的置信度大于等于 $1 - \mathbb{E}ta$。&lt;strong&gt;Wasserstein 距离&lt;/strong&gt; $d_W:\mathcal{P}_0(\Xi) \times \mathcal{P}_0(\Xi) \mapsto [0, +\infty)$ 表示所考虑的分布与经验分布在概率空间中的一种距离，定义为
$$
\begin{equation}
\begin{array}{rll}
d_W(\mathbb{P}, \hat{\mathbb{P}})  = \inf &amp;amp; \displaystyle \mathbb{E}_{\bar{\mathbb{P}}} \big[\lVert \tilde{\boldsymbol{\varepsilon}} - \tilde{\boldsymbol{\varepsilon}}^\dagger \rVert \big] \\
\mbox{s.t.}	&amp;amp; \displaystyle \big(\tilde{\boldsymbol{\varepsilon}}, \tilde{\boldsymbol{\varepsilon}}^\dagger\big) \sim \bar{\mathbb{P}}, \\
&amp;amp; \displaystyle \tilde{\boldsymbol{\varepsilon}} \sim \mathbb{P}, \\
&amp;amp; \displaystyle \tilde{\boldsymbol{\varepsilon}}^\dagger \sim \hat{\mathbb{P}}, \\
&amp;amp; \displaystyle \bar{\mathbb{P}}\big[ (\tilde{\boldsymbol{\varepsilon}}, \tilde{\boldsymbol{\varepsilon}}^\dagger) \in \Xi \times \Xi \big] = 1,
\end{array}
\end{equation} \tag{4.17}
$$
其中的 $\bar{\mathbb{P}}$ 表示 $\tilde{\boldsymbol{\varepsilon}}$ 和 $\tilde{\boldsymbol{\varepsilon}}^\dagger$ 的\emph{联合概率分布}，$\lVert \cdot \rVert$ 表示范数。根据定义，可直观地将 Wasserstein 距离视为从真实分布 $\mathbb{P}$ 向经验分布 $\hat{\mathbb{P}}$ 移动概率质量 (probability mass) 的最小费用。上述定义准确说是&lt;strong&gt;1型 Wasserstein 距离&lt;/strong&gt;，对于更一般的 Wasserstein 距离定义及更详细深入的介绍可参见Esfahani and Kuhn (2018); Gao and Kleywegt (2016); Zhao and Guan (2018)。&lt;/p&gt;
&lt;h2 id=&#34;42-机会约束问题chance-constraint&#34;&gt;4.2 机会约束问题（Chance constraint）&lt;/h2&gt;
&lt;p&gt;机会约束规划是指当优化问题环境参数为随机变量时，在以一定概率满足约束条件的情况下进行优化。自从Charnes and Cooper (1959) 提出来以来，该框架在管理科学等各领域得到了广泛研究与应用。作为抛砖引玉，本节讨论如何处理分布鲁棒、独立机会约束(4.4)，读者可进而自行研究更一般也更难处理的联合机会约束 (4.18)：
$$
\begin{equation}
\mathbb{P} [y_m^0(\boldsymbol{x}) + \boldsymbol{y}_m(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0, ~\forall m \in [M]] \ge 1 - \epsilon, \quad \forall \mathbb{P} \in \mathscr{F},
\end{equation} \tag{4.18}
$$&lt;/p&gt;
&lt;p&gt;其中的 $M$ 个约束同时成立的概率不小于 $1 - \epsilon$。&lt;/p&gt;
&lt;p&gt;从计算角度看，约束式 (4.4) 左端项可等价表示为
$$
\begin{equation}
\mathbb{E}_\mathbb{P}\big[\mathbb{1}\{y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0\}\big],
\end{equation} \tag{4.19}
$$
其中，$\mathbb{1}\{\cdot\}$ 为指示函数，当其事件发生取值为1，否则为0。指示函数为非凸函数，导致 (4.19) 对 $\boldsymbol{x}$ 或 $\tilde{\boldsymbol{\varepsilon}}$ 而言皆为非凸函数，除个别特殊情况（如 $\tilde{\boldsymbol{\varepsilon}}$ 服从联合正态分布）外难以处理。事实上，即便给定决策变量 $\boldsymbol{x}$ 和概率分布 $\mathbb{P}$，计算 (4.4) 左端项的概率值一般而言已是 NP 难问题，更何况还要基于此对 $\boldsymbol{x}$ 进行优化 (Nemirovski and Shapiro, 2006)。而有趣的是，在给定某些模糊集 $\mathscr{F}$ 的情况下，(4.4) 却可处理。&lt;/p&gt;
&lt;p&gt;接下来讲述如何在分布鲁棒优化框架下对机会约束式 (4.4) 进行处理。易知，约束式 (4.4) 等价于
$$
\begin{equation}
\displaystyle \inf_{\mathbb{P} \in \mathscr{F}}\mathbb{P}[y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0] \ge 1 - \epsilon. \tag{4.20}
\end{equation}
$$
当 (4.20) 中模糊集取 $\mathscr{F} \triangleq \mathscr{F}_{MV}$ 且其中的 $\boldsymbol{\mu} \triangleq \boldsymbol{0}$ 时， Ghaoui et al. (2003) 的研究表明，(4.20) 等价于
$$
\begin{equation}
\label{eq.dro.cc.mv.eq}
\displaystyle y^0(\boldsymbol{x}) + \sqrt{\frac{1 - \epsilon}{\epsilon}} \sqrt{\boldsymbol{y}(\boldsymbol{x})^\top\boldsymbol{\Sigma} \boldsymbol{y}(\boldsymbol{x})} \le 0. \tag{4.21}
\end{equation}
$$
这里，令 $\boldsymbol{\mu} \triangleq \boldsymbol{0}$ 并不失一般性，因为如果 $\boldsymbol{\mu} \not= \boldsymbol{0}$ 则可通过变量替换的方法，令 $\tilde{\boldsymbol{\xi}} \triangleq \tilde{\boldsymbol{\varepsilon}} - \boldsymbol{\mu}$ 并将 $\tilde{\boldsymbol{\xi}}$ 视为 (4.20) 中的 $\tilde{\boldsymbol{\varepsilon}}$。有趣的是，(4.21) 恰好等价于传统鲁棒优化约束式
$$
\begin{equation}
\label{eq.ro}
\displaystyle y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top \boldsymbol{\varepsilon} \le 0, \quad \forall \boldsymbol{\varepsilon} \in \Xi(\epsilon), \tag{4.22}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;其中，不确定集为椭球形，给定为
$$
\Xi(\epsilon) \triangleq \left\{\boldsymbol{\varepsilon} \in \mathbb{R}^J \left|~\lVert \boldsymbol{\Sigma}^{1/2}\boldsymbol{\varepsilon}\rVert_2 \le \sqrt{\frac{1-\epsilon}{\epsilon}} \right. \right\}.
$$
关于 (4.21)与(4.22)的关系，可参见 Natarajan et al. (2009)。&lt;/p&gt;
&lt;p&gt;当 (4.20) 中模糊集取 $\mathscr{F} \triangleq \mathscr{F}_{MVS}$ 时，分布鲁棒机会约束规划一般不可处理。研究者们提出了基于&lt;strong&gt;条件风险值&lt;/strong&gt; (Conditional Value-at-Risk) 的近似方法进行处理，感兴趣的读者可参见  Chen et al. (2010); Zymler et al. (2013) 等。&lt;/p&gt;
&lt;p&gt;当 $\mathscr{F} \triangleq \mathscr{F}_{WKS}$ 且其中 $K = 1, \underline{p}_1 = \overline{p}_1 = 1$ 时，Hanasusanto et al. (2015) 证明了 (4.20) 等价于如下一系列锥优化约束：
$$
\begin{array}{lll}
\mathbb{E}ta + \boldsymbol{b}^\top \boldsymbol{\gamma} \ge (1 - \epsilon) \tau,
&amp;amp; \mathbb{E}ta + \boldsymbol{c}_1^\top \boldsymbol{\phi} \le \tau,
&amp;amp; \mathbb{E}ta + \boldsymbol{c}_1^\top \boldsymbol{\psi} \le -y^0(\boldsymbol{x}), \\
\boldsymbol{A}^\top \boldsymbol{\gamma} = \boldsymbol{C}_1^\top \boldsymbol{\phi},
&amp;amp; \boldsymbol{B}^\top \boldsymbol{\gamma} = \boldsymbol{D}_1^\top \boldsymbol{\phi}, \\
\boldsymbol{A}^\top \boldsymbol{\gamma} + \boldsymbol{y}(\boldsymbol{x}) = \boldsymbol{C}_1^\top \boldsymbol{\psi},
&amp;amp; \boldsymbol{B}^\top \boldsymbol{\gamma} = \boldsymbol{D}_1^\top \boldsymbol{\psi}, \\
\mathbb{E}ta \in \mathbb{R}, \boldsymbol{\gamma} \in \mathbb{R}^L, \tau \in \mathbb{R}_+,
&amp;amp;  \boldsymbol{\phi}, \boldsymbol{\psi} \in \mathscr{K}_1^\ast
\end{array}
$$&lt;/p&gt;
&lt;p&gt;其中 $\mathscr{K}_1^\ast$ 表示 $\mathscr{K}_1$ 的对偶锥 (Ben-Tal and Nemirovski, 2001)。考虑到 $\mathscr{F}_M$ 和 $\mathscr{F}_{DY}$ 均为 $\mathscr{F}_{WKS}$ 的特例，当 $\mathscr{F} \triangleq \mathscr{F}_M$ (其中支撑集为 (4.10)的形式) 或 $\mathscr{F} \triangleq \mathscr{F}_{DY}$ 时，(4.4)可等价转化成锥优化约束形式。&lt;/p&gt;
&lt;p&gt;作为 Hanasusanto et al. (2015) 的扩展，Xie and Ahmed (2018) 考虑了更一般的模糊集，研究了分布鲁棒独立机会约束规划和联合机会约束规划的等价凸优化形式。对于考虑均值、散度上界、支撑集的一类模糊集，Hanasusanto et al. (2017) 研究了其分布鲁棒联合机会约束规划的计算复杂度及求解方法。&lt;/p&gt;
&lt;p&gt;当 (4.20) 中模糊集取 $\mathscr{F} \triangleq \mathscr{F}_{KL}$ 时，Jiang and Guan (2016) 的研究表明，(4.20) 等价于
$$
\begin{equation}
\label{eq.dro.cc.kl.eq}
\displaystyle \hat{\mathbb{P}}[y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0] \ge 1 - \bar{\epsilon}.
\end{equation} \tag{4.23}
$$&lt;/p&gt;
&lt;p&gt;其中，
$$
\bar{\epsilon} \triangleq 1 - \inf_{t \in (0, 1)} \frac{e^{-\theta}t^{1 - \epsilon} - 1}{t - 1}.
$$
由此可见，它与随机规划中基于采样平均近似 (sample average approximation) 的机会约束式 (4.24) 相比，仅仅是具有不同的概率界 $\bar{\epsilon}$ 而已。此外，对于一般的$\phi$散度形式下分布鲁棒联合机会约束规划的处理方法，可详见  Jiang and Guan (2016)。
$$
\begin{equation}
\label{eq.dro.cc.saa}
\displaystyle \hat{\mathbb{P}}[y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}} \le 0] \ge 1 - \epsilon. \tag{4.24}
\end{equation}
$$
作为常用技巧，(4.24)可通过引入0-1辅助决策变量的方法等价转换为
$$
\begin{equation}
\label{eq.dro.cc.saa.eq}
\begin{array}{ll}
\displaystyle y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\hat{\boldsymbol{\varepsilon}}_\omega\le M_0 (1 - z_\omega), &amp;amp; \forall \omega \in [N], \\
\displaystyle \frac{\sum_{\omega \in [N]} z_\omega}{N} \ge 1 - \epsilon, \\
\boldsymbol{z} \in \{0, 1\}^N.
\end{array}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;其中，$M_0$ 为一个足够大的实数。观察可知，当$y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top\hat{\boldsymbol{\varepsilon}}_\omega\le 0$ 时，$z_\omega$ 可取值 1，代表该约束在第 $\omega$ 个场景中成立，否则不得不取值 0。&lt;/p&gt;
&lt;p&gt;当 $\mathscr{F} \triangleq \mathscr{F}_W$ 时，Chen et al. (2018); Xie (2019) 讨论了如何处理分布鲁棒（独立和联合）机会约束规划问题，他们用不同的方法得到了相同的结论。此时，独立机会约束(4.20)等价于如下混合 0-1 锥优化约束
$$
\begin{array}{ll}
\epsilon N t - \boldsymbol{e}^\top \boldsymbol{s} \ge \theta N \lVert \boldsymbol{y}(\boldsymbol{x}) \rVert_\ast, \\
\boldsymbol{y}(\boldsymbol{x})^\top \hat{\boldsymbol{\varepsilon}}_\omega - y^0(\boldsymbol{x}) + M_0 z_\omega \ge t - s_\omega, &amp;amp; \forall \omega \in [N], \\
M_0(1 - z_\omega) \ge t - s_\omega, &amp;amp; \forall \omega \in [N], \\
t \in \mathbb{R}, \boldsymbol{z} \in \{0, 1\}^N, \boldsymbol{s} \in \mathbb{R}^{N}.
\end{array}
$$
其中 $\boldsymbol{e}$ 代表长度为 $N$、元素全为 1 的向量，$\lVert \cdot \rVert_\ast$ 为 (4.17)中 $\lVert \cdot \rVert$ 对应的对偶范数 (Boyd et al., 2004)。&lt;/p&gt;
&lt;h2 id=&#34;43-分布鲁棒线性优化distributionally-robust-linear-optimization&#34;&gt;4.3 分布鲁棒线性优化（Distributionally robust linear optimization）&lt;/h2&gt;
&lt;p&gt;现实世界中很多优化问题可建模或近似为线性规划问题。线性约束不仅本身可描述许多现实问题的资源约束，而且可建模或近似更复杂的资源约束。作为抛砖引玉，本节讨论如何处理分布鲁棒线性优化约束式 (4.5})，读者可进而自行研究更一般也更难处理的非线性约束，例如：
$$
\begin{equation}
\label{dro.con.pl}
\mathbb{E}_{\mathbb{P}} \big[\max_{k \in [K]} \{y_k^0(\boldsymbol{x}) + \boldsymbol{y}_k(\boldsymbol{x})^\top\tilde{\boldsymbol{\varepsilon}}\}\big] \le 0, \quad \forall \mathbb{P} \in \mathscr{F},
\end{equation} \tag{4.26}
$$
其左端项为关于 $\boldsymbol{x}$ 和 $\tilde{\boldsymbol{\varepsilon}}$ （各自）的分段线性凸函数；此形式出现在许多管理科学问题中，如库存管理 (See and Sim, 2010; Mamani et al., 2017)、预约调度  (Mak et al., 2015; Kong et al., 2013; Qi, 2017)、带时间窗的车辆路径问题  (Zhang et al., 2019)，等等。&lt;/p&gt;
&lt;p&gt;接下来探讨如何处理分布鲁棒线性优化约束式 (4.5)。易知，它等价于
$$
\begin{equation}
\label{dro.con.lo.eq}
\sup_{\mathbb{P} \in \mathscr{F}} \mathbb{E}_\mathbb{P}[y^0(\boldsymbol{x}) + \boldsymbol{y}(\boldsymbol{x})^\top \tilde{\boldsymbol{\varepsilon}}] \le 0.
\end{equation} \tag{4.27}
$$
处理该约束的关键是考察左端项中优化问题
$$
\begin{equation}
\label{dro.mod}
Z_P(\boldsymbol{x}) = \sup_{\mathbb{P} \in \mathscr{F}} \mathbb{E}_\mathbb{P}[\boldsymbol{y}(\boldsymbol{x})^\top \tilde{\boldsymbol{\varepsilon}}]
\end{equation} \tag{4.28}
$$&lt;/p&gt;
&lt;p&gt;的对偶问题。注意，该优化问题中 $\boldsymbol{x}$ 被视为给定参数，而概率分布 $\mathbb{P}$ 才是决策变量。抽象地，(4.28) 的对偶问题形式为
$$
\begin{equation}
\label{dro.mod.dual}
Z_D(\boldsymbol{x}) = \inf_{\boldsymbol{p} \in \mathscr{P}(\boldsymbol{x})} f(\boldsymbol{p}).
\end{equation}
$$
其中 $\boldsymbol{p}$ 为对偶决策变量，$\mathscr{P}(\boldsymbol{x})$ 为其可行域，$f(\boldsymbol{p})$ 为目标函数，$\boldsymbol{y}(\boldsymbol{x})$ 作为参数被包含于 $\mathscr{P}(\boldsymbol{x})$ 中。在某些条件下，强对偶定理对此成立，则 $Z_P = Z_D$。于是，(4.27) 等价于
$$
\begin{equation}
\label{eq.dro.lo.eq}
\begin{array}{ll}
y^0(\boldsymbol{x}) + f(\boldsymbol{p}) \le 0, \\
\boldsymbol{p} \in \mathscr{P}(\boldsymbol{x}).
\end{array} \tag{4.30}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;因此，技术上主要关注如何在取不同模糊集 $\mathscr{F}$ 的情况下求解 (4.28) 的对偶问题并证明强对偶定理成立。&lt;/p&gt;
&lt;p&gt;当 $\mathscr{F} \triangleq \mathscr{F}_{MV}$ 或 $\mathscr{F} \triangleq \mathscr{F}_{MVS}$ 时，由于已知 $\tilde{\boldsymbol{\varepsilon}}$ 的均值 $\boldsymbol{\mu}$，故 (4.28)等价于 $Z_P(\boldsymbol{x}) = \boldsymbol{y}(\boldsymbol{x})^\top \boldsymbol{\mu}$。Popescu (2007) 针对 $\mathscr{F} \triangleq \mathscr{F}_{MV}$ 且 (4.28) 目标函数变为某一类非线性函数的情形，研究了其等价模型与求解方法。&lt;/p&gt;
&lt;p&gt;当 (4.28)中 $\mathscr{F} \triangleq \mathscr{F}_{DY}$ 时，则在某些技术性条件下，Delage and Ye (2010)  推导出其对偶问题 (4.29) 的具体形式：
$$
\begin{equation}
\label{dro.mod.dy.dual}
\begin{array}{rll}
\displaystyle Z_D(\boldsymbol{x}) = \min_{\boldsymbol{Q}, \boldsymbol{q}, r, t} &amp;amp; r + t \\
\mbox{s.t.} &amp;amp; r \ge \boldsymbol{y}(\boldsymbol{x})^\top \boldsymbol{\varepsilon} - \boldsymbol{\varepsilon}^\top \boldsymbol{Q} \boldsymbol{\varepsilon} - \boldsymbol{\varepsilon}^\top \boldsymbol{q},  \forall \boldsymbol{\varepsilon} \in \Xi, \\
&amp;amp; t \ge (\gamma_2 \boldsymbol{\Sigma} + \boldsymbol{\mu} \boldsymbol{\mu}^\top) \bullet \boldsymbol{Q} + \boldsymbol{\mu}^\top \boldsymbol{q} + \sqrt{\gamma_1} \lVert \boldsymbol{\Sigma}^{1/2} (\boldsymbol{q} + 2 \boldsymbol{Q} \boldsymbol{\mu}) \rVert, \\
&amp;amp; \boldsymbol{Q} \succeq \boldsymbol{0},
\end{array} \tag{4.31}
\end{equation}
$$
其中 ``$\bullet$&#39;&#39; 表示矩阵间的弗罗贝尼乌斯内积。注意到 (4.31) 中的第一个约束实则为（传统）鲁棒优化约束，因此求解 $\mathscr{F}_{DY}$ 模糊集下的分布鲁棒优化问题 (4.28) 等价于求解鲁棒优化问题 (4.31)，而上一章已讲述如何求解鲁棒优化问题。&lt;/p&gt;
&lt;p&gt;当 (4.28) 中 $\mathscr{F} \triangleq \mathscr{F}_{WKS}$ 时，则在某些技术性条件下，Wiesemann et al. (2014)推导出其对偶问题 (4.29) 的具体形式：
$$
\begin{equation}
\label{dro.mod.wks.dual}
\begin{array}{rll}
\displaystyle Z_D(\boldsymbol{x}) = \min_{\boldsymbol{\mathbb{E}ta}, \boldsymbol{\eta}, \boldsymbol{\lambda}, \boldsymbol{\phi}} &amp;amp; \displaystyle \boldsymbol{b}^\top \boldsymbol{\mathbb{E}ta} + \sum_{k \in [K]} \overline{\boldsymbol{p}}_k \boldsymbol{\eta}_k - \underline{\boldsymbol{p}}_k \boldsymbol{\lambda}_k \\
\mbox{s.t.} &amp;amp; \displaystyle \boldsymbol{c}_k^\top \boldsymbol{\phi}_k \le \sum_{k&#39; \in \mathcal{A}(k)} (\boldsymbol{\eta}_{k&#39;} - \boldsymbol{\lambda}_{k&#39;}), &amp;amp; \forall k \in [K], \\
&amp;amp; \boldsymbol{C}_k^\top \boldsymbol{\phi}_k + \boldsymbol{A}^\top \boldsymbol{\mathbb{E}ta} = \boldsymbol{y}(\boldsymbol{x}), &amp;amp; \forall k \in [K], \\
&amp;amp; \boldsymbol{D}_k^\top \boldsymbol{\phi}_k + \boldsymbol{B}^\top \boldsymbol{\mathbb{E}ta} = \boldsymbol{0}, &amp;amp; \forall k \in [K], \\
&amp;amp; \boldsymbol{\phi}_k \in \mathscr{K}_k^\ast, &amp;amp; \forall k \in [K],
\end{array} \tag{4.32}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;其中，$\mathcal{A}(k) \triangleq \{k&#39; \in [K]~|~ \Xi_{k&#39;} \mbox{严格包含于} \Xi_{k} \}$，$\mathscr{K}_k^\ast$ 表示 $\mathscr{K}$ 的对偶锥 。&lt;/p&gt;
&lt;p&gt;当 (4.28)中 $\mathscr{F} \triangleq \mathscr{F}_{KL}$ 时，则在某些技术性条件下，Hu and Hong (2013)推导出其对偶问题 (4.29) 的具体形式：
$$
\begin{equation}
\label{dro.mod.kl.dual}
\begin{array}{rll}
\displaystyle Z_D(\boldsymbol{x}) = \min_{\alpha \ge 0} &amp;amp; \alpha \log \mathbb{E}_{\hat{\mathbb{P}}}[e^{\boldsymbol{y}(\boldsymbol{x})^\top \tilde{\boldsymbol{\varepsilon}}^\dagger / \alpha}] + \alpha \theta.
\end{array} \tag{4.33}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;其中的目标函数为凸函数，因此可用内点法  (Ben-Tal et al., 2013) 或分段线性函数逼近(Long and Qi, 2014)等方法进行处理。&lt;/p&gt;
&lt;p&gt;当 (4.28)中 $\mathscr{F} \triangleq \mathscr{F}_{W}$ 且其中的支撑集为 $\Xi \triangleq \{\boldsymbol{\varepsilon} \in \mathbb{R}^I~|~\boldsymbol{C}\boldsymbol{\varepsilon} \le \boldsymbol{d}\}$ 时，则在某些技术性条件下，Esfahani and Kuhn (2018) 推导出其对偶问题 (4.29) 的具体形式：
$$
\begin{equation}
\label{dro.mod.w.dual}
\begin{array}{rll}
\displaystyle Z_D(\boldsymbol{x}) = \inf_{\lambda, \boldsymbol{s}, \boldsymbol{\gamma}} &amp;amp;\displaystyle \lambda \theta + \frac{1}{N} \sum_{\omega \in [N]} s_\omega \\
\mbox{s.t.} &amp;amp; \boldsymbol{y}(\boldsymbol{x})^\top \hat{\boldsymbol{\varepsilon}}_\omega + \boldsymbol{\gamma}_\omega^\top (\boldsymbol{d} - \boldsymbol{C} \hat{\boldsymbol{\varepsilon}}_\omega) \le s_\omega, &amp;amp; \forall \omega \in [N], \\
&amp;amp; \lVert \boldsymbol{C}^\top \boldsymbol{\gamma}_\omega - \boldsymbol{y}(\boldsymbol{x}) \rVert_\ast \le \lambda, &amp;amp; \forall \omega \in [N], \\
&amp;amp; \boldsymbol{\gamma}_\omega \ge \boldsymbol{0} &amp;amp; \forall \omega \in [N].
\end{array} \tag{4.34}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;将以上各结果嵌入到 (4.30)即可得到 (4.27)的等价形式，进而求解鲁棒线性规划问题。&lt;/p&gt;
&lt;p&gt;事实上，Popescu (2007); Delage and Ye (2010); Wiesemann et al. (2014); Esfahani and Kuhn (2018) 的研究均解决了 (4.26) 的等价转化问题，而上述结论针对 (4.27)，只是(4.26) 中 $K = 1$ 时的特例，感兴趣的读者可细读他们的论文。&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ben-Tal, Aharon and Arkadi Nemirovski,&lt;/strong&gt; Lectures on modern convex optimization: analysis, algorithms, and engineering applications, Vol. 2, Siam, 2001.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ , Dick Den Hertog, Anja De Waegenaere, Bertrand Melenberg, and Gijs Rennen,&lt;/strong&gt; “Robust solutions of optimization problems affected by uncertain probabilities,” Management Science, 2013, 59 (2), 341–357.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bertsimas, Dimitris and Ioana Popescu,&lt;/strong&gt; “Optimal inequalities in probability theory: A convex optimization approach,” SIAM Journal on Optimization, 2005, 15 (3), 780–804.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ , Melvyn Sim, and Meilin Zhang&lt;/strong&gt;, “Adaptive distributionally robust optimization,” Management Science, 2019, 65 (2), 604–618.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Boyd, Stephen, Stephen P Boyd, and Lieven Vandenberghe&lt;/strong&gt;, Convex optimization, Cambridge university press, 2004.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Charnes, Abraham and William W Cooper,&lt;/strong&gt; “Chance-constrained programming,” Management Science, 1959, 6 (1), 73–79.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chen, Wenqing and Melvyn Sim,&lt;/strong&gt; “Goal-driven optimization,” Operations Research, 2009, 57 (2), 342–357.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ , __ ,&lt;/strong&gt; &lt;strong&gt;Jie Sun, and Chung-Piaw Teo&lt;/strong&gt;, “From CVaR to uncertainty set: Implications in joint chance-constrained optimization,” Operations Research, 2010, 58 (2), 470–485.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chen, Zhi, Daniel Kuhn, and Wolfram Wiesemann,&lt;/strong&gt; “Data-driven chance constrained programs over Wasser- stein balls,” Available at arXiv:1809.00210, 2018.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Delage, Erick and Yinyu Ye,&lt;/strong&gt; “Distributionally robust optimization under moment uncertainty with application to data-driven problems,” Operations Research, 2010, 58 (3), 595–612.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Esfahani, Peyman Mohajerin and Daniel Kuhn,&lt;/strong&gt; “Data-driven distributionally robust optimization using the Wasserstein metric: Performance guarantees and tractable reformulations,” Mathematical Programming, 2018, 171 (1-2), 115–166.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gao, Rui and Anton J Kleywegt,&lt;/strong&gt; “Distributionally robust stochastic optimization with Wasserstein distance,” Available at arXiv:1604.02199, 2016.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ghaoui, Laurent El, Maksim Oks, and Francois Oustry,&lt;/strong&gt; “Worst-case value-at-risk and robust portfolio optimization: A conic programming approach,” Operations Research, 2003, 51 (4), 543–556.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hanasusanto, Grani A, Vladimir Roitch, Daniel Kuhn, and Wolfram Wiesemann,&lt;/strong&gt; “A distributionally robust perspective on uncertainty quantification and chance constrained programming,” Mathematical Programming, 2015, 151 (1), 35–62.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ , __ , __, and __ ,&lt;/strong&gt; “Ambiguous joint chance constraints under mean and dispersion information,” Operations Research, 2017, 65 (3), 751–767.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hu, Zhaolin and Lj Hong&lt;/strong&gt;, “Kullback-Leibler Divergence -Constrained Distributionally Robust Optimization,” Optimization Online, 2013, (2), 1–34.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Jiang, Ruiwei and Yongpei Guan,&lt;/strong&gt; “Data-driven chance constrained stochastic program,” Mathematical Pro- gramming, 2016, 158 (1-2), 291–327.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kong, Qingxia, Chung-Yee Lee, Chung-Piaw Teo, and Zhichao Zheng,&lt;/strong&gt; “Scheduling arrivals to a stochastic service delivery system using copositive cones,” Operations Research, 2013, 61 (3), 711–726.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Long, Daniel Zhuoyu and Jin Qi,&lt;/strong&gt; “Distributionally robust discrete optimization with Entropic Value-at-Risk,” Operations Research Letters, 2014, 42 (8), 532–538.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mak, Ho-Yin, Ying Rong, and Jiawei Zhang,&lt;/strong&gt; “Appointment scheduling with limited distributional informa- tion,” Management Science, 2015, 61 (2), 316–334.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mamani, Hamed, Shima Nassiri, and Michael R Wagner,&lt;/strong&gt; “Closed-form solutions for robust inventory management,” Management Science, 2017, 63 (5), 1625–1643.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Natarajan, Karthik, Chung Piaw Teo, and Zhichao Zheng,&lt;/strong&gt; “Mixed 0-1 linear programs under objective uncertainty: A completely positive representation,” Operations Research, 2011, 59 (3), 713–728.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ , Dessislava Pachamanova, and Melvyn Sim,&lt;/strong&gt; “Constructing Risk Measures from Uncertainty Sets,” Oper- ations Research, 2009, 57 (5), 1129–1141.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nemirovski, Arkadi and Alexander Shapiro,&lt;/strong&gt; “Convex approximations of chance constrained programs,” SIAM Journal on Optimization, 2006, 17 (4), 969–996.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Popescu, Ioana,&lt;/strong&gt; “Robust mean-covariance solutions for stochastic optimization,” Operations Research, 2007, 55 (1), 98–112.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Qi, Jin,&lt;/strong&gt; “Mitigating delays and unfairness in appointment systems,” Management Science, 2017, 63 (2), 566–583.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;See, Chuen-Teck and Melvyn Sim,&lt;/strong&gt; “Robust approximation to multiperiod inventory management,” Operations Research, 2010, 58 (3), 583–594.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wiesemann, Wolfram, Daniel Kuhn, and Melvyn Sim,&lt;/strong&gt; “Distributionally robust convex optimization,” Oper- ations Research, 2014, 62 (6), 1358–1376.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Xie, Weijun&lt;/strong&gt;, “On distributionally robust chance constrained programs with Wasserstein distance,” Mathematical Programming, 2019, pp. 1–41.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__ and Shabbir Ahmed,&lt;/strong&gt; “On deterministic reformulations of distributionally robust joint chance constrained optimization problems,” SIAM Journal on Optimization, 2018, 28 (2), 1151–1182.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zhang, Yu, Roberto Baldacci, Melvyn Sim, and Jiafu Tang,&lt;/strong&gt; “Routing optimization with time windows under uncertainty,” Mathematical Programming, 2019, 175 (1-2), 263–305.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zhao, Chaoyue and Yongpei Guan,&lt;/strong&gt; “Data-driven risk-averse stochastic optimization with Wasserstein metric,” Operations Research Letters, 2018, 46 (2), 262–267.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zymler, Steve, Daniel Kuhn, and Berç Rustem,&lt;/strong&gt; “Distributionally robust joint chance constraints with second- order moment information,” Mathematical Programming, 2013, 137 (1-2), 167–198.&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>第五章 多阶段问题与线性决策规则</title>
      <link>https://allenz-me.github.io/RoSite/post/ch5/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://allenz-me.github.io/RoSite/post/ch5/</guid>
      
        <description>&lt;p&gt;第三章和第四章分别介绍了经典鲁棒优化和分布鲁棒优化的方法和模型。然而这些方法和模型主要针对单阶段（single stage）的问题。而在企业或者决策者面对的问题中，很大一部分都是多阶段的（Multi-stage）。也即，决策者需要在一定的时间内，按时间顺序进行多个决策，且决策时只知过去已发生的随机变量（random variable）而无法预知未来的。多阶段问题的这些特性，使得对相应问题的建模和求解特别复杂。在优化领域，一般是用随机规划或者动态规划进行建模和求解。然而，随机规划和动态规划都遭受``维度诅咒&amp;quot;（curse of dimensionality）。&lt;/p&gt;
&lt;p&gt;针对随机规划和动态规划的这个致命缺点，鲁棒优化用一些决策规则（decision rule）进行规避。现有的决策规则已经可以达到很好的近似效果，甚至在某些条件下有一些决策规则可以达到最优。&lt;/p&gt;
&lt;p&gt;在这一章，我们将聚焦于如何用这些决策规则对多阶段问题（主要是两阶段问题）进行求解。在此之前，我们先着重介绍两阶段的随机规划问题。&lt;/p&gt;
&lt;p&gt;备注：正如后面会讨论，决策规则近来越来越多地被改称为近似规则（recourse approximation）。如若称为决策规则，则有后面阶段的决策将根据规则直接得到之嫌。而实际上，如果直接使用决策规则对后面阶段决策进行决策，其效果非常不可控。大多时候，模型会表现非常差。在模型的实施过程中，往往都是用滚动法（rolling horizon），也即，在知道这一期的不确定性之后，将现在系统的状态当成初始状态，重新对模型进行求解，以获得下一期的最优决策。从这个角度来说，我们使用一定的规则去\textit{近似}未来的决策和不确定性之间的关系，从而达到简化模型的效果。&lt;/p&gt;
&lt;h2 id=&#34;51-随机规划stochastic-programming&#34;&gt;5.1 随机规划（Stochastic programming）&lt;/h2&gt;
&lt;p&gt;为了更好地理解随机规划，我们举例如下。
&lt;strong&gt;示例 5.1（单阶段库存管理模型）&lt;/strong&gt;：小王前不久在小区开了一个小卖部。他发现，小区对苹果的需求$\tilde{d}$满足分布$F(\cdot)$。他每天需要决定向20里外小张定$x$斤苹果。每斤苹果的进货单价为$c$，销售价格为$p$。若库存不足,也即真实需求$d$大于订货量$x$，居民可以先下单，等有货了再送过去。针对这种情况，小王一般会给一定的折扣。折算下来，每一斤苹果将增加$b$的成本。而如果订货量太多，也即$x - d \geq 0$，苹果可能会变质，折算下来一斤苹果将增加$h$的成本。小王的利润为：
$$
\pi(x, d) = p\min\{x, d\} - cx - b(d- x)^+ - h(x - d)^+.
$$
小王想最大化他的期望利润，也即他将要解以下问题:
$$
\begin{align}
\max\ &amp;amp; \mathbb{E}_{\mathbb{P}}[\pi(x,\tilde{d})]\\
\mathrm{s.t.}\ &amp;amp; x \geq 0  \tag{5.1}
\end{align}
$$
示例5.1就是一个在商业环境中随处可见的随机规划问题：在已知随机分布和满足一定的约束的情况下，进行决策使得期望利润最大化。一般地，随机规划关注以下问题:
$$
\begin{align*}
\min\ &amp;amp;\mathbb{E}_{\mathbb{P}}[g(\boldsymbol{x},\tilde\xi)]\\
\mathbf{s.t.}\ &amp;amp;  \mathbb{E}_{\mathbb{P}}[f_i(\boldsymbol x,\tilde\xi)] \leq 0 \quad \forall i\in[I].
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;其中，$\tilde\xi$  为随机变量。&lt;/p&gt;
&lt;p&gt;示例5.1是一个单阶段的问题。但是，如果我们把卖多少苹果，$\min\{x,d\}$，当成决策$y$，那示例5.1就变成了一个两阶段的问题：第一阶段，决定定多少苹果，之后观测到需求；第二阶段，决定卖多少苹果。也即，模型(5.1)可以写成
$$
\begin{align*}
\max\ &amp;amp; -c x - b\mathbb{E}_{\mathbb{P}}[\tilde{d}] - h x + \mathbb{E}_{\mathbb{P}}[g(x,\tilde{d})]\\
\mathrm{s.t.}\ &amp;amp; x \geq 0
\end{align*}
$$
其中，
$$
\begin{align*}
g(x, d) = \max\ &amp;amp; (p + b + h)y\\
\mathrm{s.t.}\ &amp;amp; y \leq x,\\
&amp;amp; y \leq d\notag.
\end{align*}
$$
此模型可归类于由Dantzig (1955)首先引入的经典的（线性）两阶段随机规划问题（two stage stochastic programming）： 第一阶段的决策变量为$\boldsymbol x\in \mathbb{R}^{N_1}$，也称为“现时决策（here-and-now decision）”。不失一般性，假设$ \boldsymbol x$的可行集为$\mathcal{X} = \{\boldsymbol x:\boldsymbol{Ax} = \boldsymbol b,\, \boldsymbol x \geq \boldsymbol 0\}$。与$\boldsymbol x$相关的成本参数$\boldsymbol c \in \mathbb{R}^{N_1}$。之后，随机变量$\tilde \xi\in \mathcal{W} \in \mathbb{R}^{I_1}$实现为$\boldsymbol \xi$。其中$\mathcal{W}$为$\tilde{\xi}$的支撑集。第二阶段决策变量为$\boldsymbol y$，也称“等待决策（wait-and-see decision）”。其相应的成本参数为$\boldsymbol q\in \mathbb{R}^{N_2}$。此两阶段随机规划问题模型如下：
$$
\begin{equation}
\begin{aligned}
\min\ &amp;amp; \boldsymbol c^{\top} \boldsymbol x + \mathbb{E}_{\mathbb{P}}[g(\boldsymbol x,\tilde{\boldsymbol\xi})],\\
\mathbf{s.t.}\ &amp;amp;  \boldsymbol{A}\boldsymbol x = \boldsymbol b,\\
&amp;amp; \boldsymbol x \geq \boldsymbol 0,
\end{aligned} \tag{5.2}
\end{equation}
$$
其中
$$
\begin{equation}\label{model::Two Stage SP model--dependent}
\begin{aligned}
g(\boldsymbol x,\boldsymbol \xi) = \min\ &amp;amp; \boldsymbol q^{\top}\boldsymbol{y},\\
\mathbf{s.t.}\ &amp;amp;  \boldsymbol{T}(\boldsymbol \xi)\boldsymbol x + \boldsymbol{W}\boldsymbol y = \boldsymbol h(\boldsymbol \xi),\\
&amp;amp; \boldsymbol y \geq \boldsymbol 0.
\end{aligned}\tag{5.3}
\end{equation}
$$
模型5.3中，$\boldsymbol{T} \in \mathcal{R}^{I_1, M\times N_1}, \boldsymbol h \in \mathcal{R}^{I_1,M}$是 $\boldsymbol\xi \in \mathcal{W}$的函数。在接下来的讨论中，我们假设他们仿射依赖于$\boldsymbol \xi \in \mathbb{R}^{I_1}$：
$$
\boldsymbol{T}(\boldsymbol \xi) = \boldsymbol T^0 + \sum_{i\in[I_1]}\boldsymbol T^i\boldsymbol \xi_i, \quad \boldsymbol{b}(\boldsymbol \xi) = \boldsymbol b^0 + \sum_{i\in[I_1]}\boldsymbol b^i\boldsymbol \xi_i,
$$&lt;/p&gt;
&lt;p&gt;其中，$\boldsymbol T^0,\ldots,\boldsymbol T^{I_1} \in \mathbb{R}^{M \times N_1}$，$\boldsymbol b^0,\ldots,\boldsymbol b^{I_1} \in \mathbb{R}^{M}$。&lt;/p&gt;
&lt;p&gt;另外，矩阵$\boldsymbol W$称为补偿矩阵（recourse matrix）。第二阶段的模型(5.3)不一定总是有可行解。但是如果 $\boldsymbol W$是完全补偿的（complete recourse）&amp;mdash;对任意的$\boldsymbol z \in \mathbb{R}^M$，存在$\boldsymbol y\in \mathbb{R}^{N_2}$使得$\boldsymbol W \boldsymbol y \geq \boldsymbol z$&amp;mdash;那么可以保证对于所有$\boldsymbol x\in \mathbb{R}^{N_1}$和$\boldsymbol \xi \in \mathbb{R}^{I_1}$，模型(5.3)都有可行解。然而完全补偿的假设过于苛刻，有些问题不一定具有这个性质。通常情况下，我们会假设模型(5.3)对于所有的$\boldsymbol x\in \mathcal{X}$和$\boldsymbol \xi \in \mathcal{W}$都有可行解，也即模型(5.3)具有相对完全补偿（relatively complete recourse）。&lt;/p&gt;
&lt;p&gt;然而，两阶段随机模型具有以下难点:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大量变量和约束。&lt;/li&gt;
&lt;li&gt;难以获得$\boldsymbol{\tilde{ \xi}}$的集中分布。&lt;/li&gt;
&lt;li&gt;难以评估（evaluate）目标函数。尤其当$\boldsymbol{\tilde{ \xi}}$的维度较大时。&lt;/li&gt;
&lt;li&gt;难以获得一个第一阶段的可行解$\boldsymbol x$能够保证第二阶段的解$\boldsymbol y$也是可行的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上难点，使得最简单的两阶段随机规划问题是一个$N P$-难的问题；而如果阶段大于2，这个问题则是一个$\mathrm{PSPACE}$-难的问题(Dyer and Stougie, 2006)。为了部分解决以上的这些问题，我们接下来介绍动态鲁棒优化和近似决策规则。&lt;/p&gt;
&lt;h2 id=&#34;52-动态鲁棒优化dynamic-robust-optimization&#34;&gt;5.2 动态鲁棒优化（Dynamic robust optimization）&lt;/h2&gt;
&lt;p&gt;在两阶段随机规划问题(5.2)中，假如$\boldsymbol{\tilde\xi}$的分布$\mathbb{P}$的具体分布未知，但是可以构建某个模糊集$\mathcal{P}$使得真实的分布在这个集合中，那么我们可以得到以下动态鲁棒优化模型：
$$
\begin{equation}\label{model::Two Stage Robust model}
\begin{aligned}
\min\ &amp;amp;  \boldsymbol c^{\top}  \boldsymbol x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}[g( \boldsymbol x,\boldsymbol{\tilde\xi})],\\
\mathbf{s.t.}\ &amp;amp;   \boldsymbol{A} \boldsymbol x =  \boldsymbol b,\\
&amp;amp;  \boldsymbol x \geq  \boldsymbol 0,
\end{aligned} \tag{5.4}
\end{equation}
$$
其中
$$
\begin{equation}%\label{model::Two Stage SP model--dependent}
\begin{aligned}
g( \boldsymbol x, \boldsymbol \xi) = \min\ &amp;amp;  \boldsymbol q^{\top} \boldsymbol{y}\\
\mathbf{s.t.}\ &amp;amp;   \boldsymbol{T}( \boldsymbol \xi) \boldsymbol x +  \boldsymbol{W} \boldsymbol y =  \boldsymbol h( \boldsymbol \xi),\\
&amp;amp;  \boldsymbol y \geq  \boldsymbol 0.
\end{aligned}
\end{equation}
$$
我们可以等价地把模型(5.4)写成：
$$
\begin{equation}\label{model::Two Stage Robust model1}
\begin{aligned}
Z^\ast = \min\ &amp;amp;  \boldsymbol c^{\top}  \boldsymbol x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}[\boldsymbol q^{\top} \boldsymbol{y}(\boldsymbol{\tilde\xi})],\\
\mathbf{s.t.}\ &amp;amp;   \boldsymbol A  \boldsymbol x =  \boldsymbol b,\\
&amp;amp; \boldsymbol{T}( \boldsymbol \xi) \boldsymbol x +  \boldsymbol{W} \boldsymbol y( \boldsymbol \xi) =  \boldsymbol h( \boldsymbol \xi)\,\,\forall  \boldsymbol \xi \in \mathcal{W},\\
&amp;amp; \boldsymbol y \in \mathcal{R}^{I_1, N_2},\\
&amp;amp; \boldsymbol x \geq  \boldsymbol 0.
\end{aligned}\tag{5.5}
\end{equation}
$$
然而，模型(5.5)一般来说是不可解的，因为$ \boldsymbol y$是$ \boldsymbol \xi $的任意一个函数。如果我们假设$ \boldsymbol y$和$ \boldsymbol\xi$之间的映射是可知的，比如是仿射或者二次的，那么模型(5.5)是否可能有解呢？答案是肯定的。&lt;/p&gt;
&lt;p&gt;备注：模型(5.2)是一个分布鲁棒优化的两阶段模型。由第三章和第四章可知，当模糊集只包含随机变量的支撑集时，分布鲁棒优化模型退化成传统的鲁棒优化模型。因此，这一章节只讨论分布鲁棒优化下的多阶段问题和线性决策规则。&lt;/p&gt;
&lt;h2 id=&#34;53-线性决策规则linear-decision-rule&#34;&gt;5.3 线性决策规则（Linear decision rule）&lt;/h2&gt;
&lt;p&gt;线性决策规则（LDR）是一种在动态优化模型中，假设当前阶段的决策&lt;strong&gt;线性&lt;/strong&gt;依赖于（之前阶段）随机变量的决策机制。也即，这是对决策变量和随机变量之间复杂关系的一种近似。相对应的，也有非线性的决策规则，比如二次决策规则（Quadratic Decision Rule, Ben-Tal et al. 2009）和多项式决策规则（Polynomial Decision Rules, Bertsimas et al. 2011）。&lt;/p&gt;
&lt;p&gt;决策规则的提出旨在降低随机规划问题中的维度。有关于早期决策规则和随机规划结合的文献可参考Garstka and Wets等人1974年写的综述。然而，由于此近似所得模型过于保守而被弃用。之后，Ben-Tal et al. (2004)创造性地将LDR和鲁棒优化相结合，使得线性决策规则焕发出勃勃生机。 具体地，对于模型(5.5)我们可以假设$ \boldsymbol y$是$ \boldsymbol \xi$的仿射函数，
$$
\boldsymbol{y}( \boldsymbol \xi) =  \boldsymbol y^0 + \sum_{i\in[I_1]} \boldsymbol y_i^1\xi_i.
$$
不失一般性，我们定义以下集合
$$
\mathcal{L}^{I,N} = \bigg\{ \boldsymbol y \in \mathcal{R}^{I,N} \Big| \begin{array}{l}
\exists  \boldsymbol y^0,  \boldsymbol y_i^1, i \in [I_1]:\\
\boldsymbol y ( \boldsymbol \xi) =  \boldsymbol y^0 + \displaystyle\sum_{i\in[I_1]}  \boldsymbol y_i^1 \xi_i
\end{array}\bigg\}.
$$
在线性规则下，模型(5.5)可以写成
$$
\begin{equation}\label{model::Two Stage Robust model LDR}
\begin{aligned}
Z^L = \min\ &amp;amp;  \boldsymbol c^{\top}  \boldsymbol x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}[ \boldsymbol q^{\top} \boldsymbol{y}(\boldsymbol{\tilde\xi})],\\
\mathbf{s.t.}\ &amp;amp;   \boldsymbol A  \boldsymbol x =  \boldsymbol b,\\
&amp;amp; \boldsymbol{T}( \boldsymbol \xi) \boldsymbol x +  \boldsymbol{W} \boldsymbol y( \boldsymbol \xi) =  \boldsymbol h( \boldsymbol \xi)\,\,\forall  \boldsymbol \xi \in \mathcal{W},\\
&amp;amp; \boldsymbol y \in \mathcal{L}^{I_1,N_2}, \boldsymbol x \geq  \boldsymbol 0.
\end{aligned} \tag{5.6}
\end{equation}
$$
由此，我们可以得到模型(5.5)的一个上界。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理5.1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​	$$Z^{\ast} \leq Z^L$$&lt;/p&gt;
&lt;p&gt;既然是上界，那么很自然的问题是，这个近似的效果如何？近似之后的问题和原问题的差距多大？什么条件下这两个问题是一样的，也即，什么条件可以保证线性决策规则是最优的？对于前两个问题，据笔者所知，暂时没有一般性的结论。而对于第三个问题，Iancu et al. (2013)给出了模糊集中只包含随机变量的支撑集时，线性决策规则最优的条件和技术性假设。 Bertsimas et al. (2010) 和Bertsimas and Goyal (2012)探讨了某几种特殊的多阶段问题中LDR最优的条件。 而对于下一小节要介绍的拓展式线性决策规则（ELDR），Bertsimas et al. (2019)证明了当第二阶段的决策变量为一维时，ELDR为最优。He et al. (2020)证明了ELDR对于车辆调度问题（vehicle repositioning problem)在满足一定的技术性假设条件下，对于任意维度的补偿决策都是最优的。对于第五小节要介绍的情景仿射补偿近似规则，Perakis et al. (2020)证明了在三阶段的定价和库存模型中，当只考虑一个产品时，事件式近似法则是最优的。而对于多个产品的情况，从数值例子来看，也接近于最优。&lt;/p&gt;
&lt;p&gt;LDR的运用使得多阶段的鲁棒优化问题受到了越来越多的学者的关注。然而，线性决策规则有一个很明显的缺点，近似模型太保守或者容易使得模型不可解。比如，Chen et al. (2008)指出，当$ \boldsymbol \xi$的支撑集$\mathcal{W} = (-\infty, + \infty)$时，
$$
\boldsymbol{y}( \boldsymbol \xi) =  \boldsymbol y^0 + \sum_{i\in[I_1]} \boldsymbol y_i^1\xi_i \geq  \boldsymbol 0,
$$
可以得到$ \boldsymbol y_i^1 =  \boldsymbol 0, \forall i \in [I_1]$。此时，$ \boldsymbol y( \boldsymbol \xi ) =  \boldsymbol y^0$是静态的（Static policy），而不是动态地依赖于$ \boldsymbol \xi$。 这就很容易导致所得的解过于保守或者模型不可解。比如考虑如下的随机优化问题：
$$
\begin{align*}
\min\,&amp;amp; \mathbb{E}_{\mathbb{P}}[y_1( \boldsymbol \xi) + y_2( \boldsymbol \xi)]\\
\textrm{s.t.}\, &amp;amp; y_1( \boldsymbol \xi) - y_2( \boldsymbol \xi) = h( \boldsymbol \xi),\\
&amp;amp; y_1( \boldsymbol \xi) \geq 0, y_2( \boldsymbol \xi) \geq 0.
\end{align*}
$$&lt;/p&gt;
&lt;p&gt;如果$ \boldsymbol \xi$的支撑集$\mathcal{W} = (-\infty, + \infty)$，那么$y_1( \boldsymbol \xi) = y_1^0, y_2( \boldsymbol \xi) = y_2^0$。而此时，等式$y_1( \boldsymbol \xi) - y_2( \boldsymbol \xi) = h( \boldsymbol \xi)$将无法被满足。有鉴于此，Chen et al. (2008)提出了偏转线性决策规则（Deflected Linear Decision Rule, DLDR）和分离线性决策规则（Segregated Linear Decision Rule,SLDR）。进一步地，See and Sim (2010)提出了截断线性决策规则（Truncated linear decision rule），Goh and Sim (2010)则将DLDR和SLDR扩展到双偏转线性决策规则（Bideflected Linear Decision Rule）和广义分离线性决策规则（Generalized Segregated Linear Decision Rule）。&lt;/p&gt;
&lt;p&gt;对于LDR在多阶段问题中的更多的运用，读者可以阅读Delage and Iancu (2015) 和Georghiou et al. (2019)。&lt;/p&gt;
&lt;p&gt;下面，我们举个LDR在多阶段鲁棒库存管理中的例子(See and Sim, 2010; Bertsimas et al., 2019)。
&lt;strong&gt;示例5.2（多阶段库存管理模型）:&lt;/strong&gt; 假如示例5.1中的小王每天都要定苹果。总共要定$T$天。所有的成本都是波动的，也即都跟$t\in [T]$相关。假如第$t$天早上的库存水平（inventory level）为$y_t$，那么第$t + 1$天的库存水平$y_{t + 1}$可以通过$y_t, x_t$和$d_t$得到：
$$
y_{t+1} = y_{t} + x_t - d_t.
$$
假设需求是随机变量$\boldsymbol{\tilde z}$的函数
$$
d_t(\boldsymbol{\tilde{z}}_t) = \tilde{z}_t + \alpha \tilde{z}_{t - 1} + \cdots + \alpha \tilde{z}_1 + \mu,
$$
其中，$\alpha \in [0,1], \boldsymbol{\tilde{z}}_t \triangleq (\tilde{z}_1, \ldots, \tilde{z}_t)$。$\tilde{z}_t$的期望为零且$\tilde{z}_t$ 和$\tilde{z}_s (s \neq t, s,t \in [T])$ 两两互不相关(uncorrelated)。那么，我们可以把小王这$T$天的问题写成如下鲁棒优化模型:
$$
\begin{array}{lll}
\min\, &amp;amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{P}} \mathbb{E}_{\mathbb{P}}\left[\sum_{t \in [T]} c_tx_t(\boldsymbol{\tilde{z}}_{t - 1}) + v_{t}(\boldsymbol{\tilde{z}}_{t}))\right]\\
\textrm{s.t.}\, &amp;amp; y_{t+1}( \boldsymbol z_t) = y_{t}( \boldsymbol z_{t - 1}) + x_t( \boldsymbol z_{t - 1}) - d_t( \boldsymbol z_{t}) &amp;amp; \forall  \boldsymbol z \in \mathcal{W}, t \in [T],\\
&amp;amp;v_t( \boldsymbol z_t) \geq h_ty_{t + 1}( \boldsymbol z_{t}) &amp;amp; \forall  \boldsymbol z \in \mathcal{W}, t \in [T],\\
&amp;amp;v_t( \boldsymbol z_t) \geq -b_ty_{t + 1}( \boldsymbol z_{t}) &amp;amp; \forall  \boldsymbol z \in \mathcal{W}, t \in [T],\\
&amp;amp;0 \leq x( \boldsymbol z_{t - 1}) \leq \bar{x}_t &amp;amp; \forall  \boldsymbol z \in \mathcal{W}, t \in [T],\\
&amp;amp;x_t \in \mathcal{L}^{t - 1,1}, y_{t + 1} \in \mathcal{L}^{t,1}, v_t \in \mathcal{L}^{t,1} &amp;amp; \forall t \in [T].
\end{array}
$$&lt;/p&gt;
&lt;h2 id=&#34;54-拓展式线性决策规则extended-linear-decision-rule&#34;&gt;5.4 拓展式线性决策规则(Extended linear decision rule)&lt;/h2&gt;
&lt;p&gt;在章节4.1.1中，我们介绍了基于广义矩信息的模糊集。其中，Wiesemann et al. (2014)巧妙地引入了辅助随机变量$\boldsymbol{\tilde{ u}}$使得升维之后的模糊集（lifted ambiguity set）中的约束皆化为线性约束，而将非线性部分转移到了支撑集中。相应地，在模型(5.5)中,如果假设$ \boldsymbol y$是$ \boldsymbol \xi$和$ \boldsymbol u$的仿射函数，也即
$$
\mathcal{L}^{I + J,N} = \bigg\{ \boldsymbol y \in \mathcal{R}^{I + J,N} \Big| \begin{array}{l}
\exists  \boldsymbol y^0,  \boldsymbol y_i^1,  \boldsymbol y_j^2 \in \mathbb{R}^N, \forall i \in [I], j \in [J]:\\
\displaystyle  \boldsymbol y ( \boldsymbol \xi,  \boldsymbol u) =  \boldsymbol y^0 + \sum_{i\in[I]}  \boldsymbol y_i^1 \xi_i + \sum_{j\in[J]}  \boldsymbol y_j^2 u_j
\end{array}\bigg\}.
$$
我们称之为拓展式线性决策规则(Extended Linear Decision Rule, ELDR)。&lt;/p&gt;
&lt;p&gt;在ELDR下，模型(5.5)可以写成
$$
\begin{equation}\label{model::Two Stage Robust model ELDR}
\begin{aligned}
Z^E = \min\ &amp;amp;  \boldsymbol c^{\top}  \boldsymbol x + \sup_{\mathbb{P} \in \mathcal{P}}\mathbb{E}_{\mathbb{P}}[ \boldsymbol q^{\top} \boldsymbol{y}(\boldsymbol{\tilde\xi}, \boldsymbol{\tilde{u}})],\\
\mathbf{s.t.}\ &amp;amp;   \boldsymbol A  \boldsymbol x =  \boldsymbol b,\\
&amp;amp; \boldsymbol{T}( \boldsymbol \xi) \boldsymbol x +  \boldsymbol{W} \boldsymbol y( \boldsymbol \xi, \boldsymbol{\tilde{u}}) =  \boldsymbol h( \boldsymbol \xi)\,\,\forall  \boldsymbol \xi \in \mathcal{W},\\
&amp;amp; \boldsymbol y \in \mathcal{L}^{I_1 + I_2,N_2}, \boldsymbol x \geq  \boldsymbol 0.
\end{aligned}
\end{equation}
$$&lt;/p&gt;
&lt;p&gt;由此，我们可以得到一个比LDR更好的近似模型。
&lt;strong&gt;定理5.2&lt;/strong&gt;
$Z^{\ast} \leq Z^E \leq Z^L$.
详细的证明请参考Bertsimas et al. (2019).&lt;/p&gt;
&lt;h2 id=&#34;55-事件式近似法则event-wise-affine-recourse-approximation&#34;&gt;5.5 事件式近似法则(Event-wise affine recourse approximation)&lt;/h2&gt;
&lt;p&gt;Chen et al. (2019)提出了鲁棒随机优化（Robust Stochastic Optimization, RSO）模型的统一框架。在这个框架中，定义静态决策$ \boldsymbol{w} \in \mathbb{R}^{J_w}$，连续随机变量$\boldsymbol{\tilde{z}}$， 和离散随机变量$\tilde{s}$。定义只取决于离散随机变量$\tilde{s}$的动态决策$ \boldsymbol{x}(s):[S] \mapsto \mathbb{R}^{J_x}$,以及同时取决于连续随机变量$\boldsymbol{\tilde{z}}$和离散随机变量$\tilde{s}$的动态决策$ \boldsymbol{y}(s, \boldsymbol{z}): [S] \times \mathbb{R}^{I_z} \mapsto \mathbb{R}^{J_y}$。与线性近似法则类似，对应离散随机变量的不同取值，动态决策$ \boldsymbol{y}(s, \boldsymbol{z})$为连续随机变量$\boldsymbol{\tilde{z}}$的不同的线性函数：
$$
\boldsymbol{y}(s, \boldsymbol{z})  \triangleq  \boldsymbol{y}^0(s) + \sum_{i \in [I_z]}  \boldsymbol{y}^i(s) z_i.
$$
其中，系数$ \boldsymbol{y}^0(s),\dots, \boldsymbol{y}^{I_z}(s)$是最终模型的实际决策变量。&lt;/p&gt;
&lt;p&gt;定义线性映射
$$
\left\{
\begin{array}{rcl}
\boldsymbol{a}_m(s, \boldsymbol{z}) &amp;amp;\triangleq&amp;amp;  \boldsymbol{a}_{ms}^0 + \sum_{i \in [I_z]}  \boldsymbol{a}_{ms}^i z_i, \\
\boldsymbol{b}_m(s, \boldsymbol{z}) &amp;amp;\triangleq&amp;amp;  \boldsymbol{b}_{ms}^0 + \sum_{i \in [I_z]}  \boldsymbol{b}_{ms}^i z_i, \\
\boldsymbol{c}_m(s) &amp;amp;\triangleq&amp;amp;   \boldsymbol{c}_{ms}, \\
d_m(s, \boldsymbol{z}) &amp;amp;\triangleq&amp;amp; d_{ms}^0 + \sum_{i \in [I_z]} d_{ms}^i z_i,
\end{array}\
\right. ~~~\forall m \in [M] \cup \{0\}.
$$
其中，参数维度如下
$$
\boldsymbol{a}_{ms}^i \in \mathbb{R}^{J_w},  \boldsymbol{b}_{ms}^i \in \mathbb{R}^{J_x},  \boldsymbol{c}_{ms} \in \mathbb{R}^{J_y},  d_{ms}^i \in \mathbb{R} ~~~\forall i \in [I_z] \cup \{0\}, ~s \in [S].
$$&lt;/p&gt;
&lt;p&gt;RSO模型的目标函数取分布集合$\mathcal{F}$（稍后介绍）下的最坏期望
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[ \boldsymbol{a}^\prime_0(\tilde s, \tilde{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_0(\tilde s, \tilde{z}) \boldsymbol{x}(\tilde s) +  \boldsymbol{c}^\prime_0(\tilde s) \boldsymbol{y}(\tilde s, \tilde{z}) + d_0(\tilde s, \tilde{z})].
$$&lt;/p&gt;
&lt;p&gt;RSO模型主要包含两类约束。第一类“硬”线性约束($m \in \mathcal{M}_1$)为一般鲁棒约束，需要在随机变量任意可能的取值下均满足：
$$
\boldsymbol{a}^\prime_m(s, \boldsymbol{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_m(s, \boldsymbol{z}) \boldsymbol{x}(s) +  \boldsymbol{c}^\prime_m(s) \boldsymbol{y}(s, \boldsymbol{z}) + d_m(s, \boldsymbol{z}) \leq 0 ~~~\forall  \boldsymbol{z} \in  \mathcal{Z}_s, ~s \in [S].
$$
第二类“软”线性约束($m \in \mathcal{M}_2$)与目标函数类似，考虑分布集合$\mathcal{F}$下的最坏期望，并要求该最坏期望不为正：
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[{ \boldsymbol{a}^\prime_m(\tilde s, \tilde{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_m(\tilde s, \tilde{z}) \boldsymbol{x}(\tilde s) +  \boldsymbol{c}^\prime_m(\tilde s) \tilde{y}(\tilde s, \tilde{z}) + d_m(\tilde s, \tilde{z})} ]\leq 0 ~~~\forall m \in \mathcal{M}_2.
$$&lt;/p&gt;
&lt;p&gt;除以上两类约束之外，在离散随机变量的不同取值下，RSO还包含非线性约束（如凸约束，整数约束等）
$$
\boldsymbol{r}(s) \triangleq \left( \boldsymbol{w}, \boldsymbol{x}(s), \boldsymbol{y}^0(s),\dots, \boldsymbol{y}^{I_z}(s) \right) \in \mathcal{X}_s ~~~\forall s \in [S],
$$&lt;/p&gt;
&lt;h3 id=&#34;551-事件式近似法则&#34;&gt;5.5.1 事件式近似法则&lt;/h3&gt;
&lt;p&gt;记离散随机变量$\tilde{s}$的取值范围为$[S]$。特别地，离散随机变量$\tilde{s}$每一个取值$s$对应一个情景$s$。定义由情景组成的一个非空集合为一个事件$\mathcal{E} \subseteq [S]$。如此，全部情景的一个划分（partition）定义了一个相互独立（mutually exclusive）又完全穷尽（collectively exhaustive）的MECE事件集合，记为$\mathcal{C}$。相应地，满足$\mathcal{H}_{\mathcal{C}}(s) = \mathcal{E}$ 函数$\mathcal{H}_{\mathcal{C}}:[S] \mapsto \mathcal{C}$确定了情景$s$在一个MECE事件集合中唯一所属的事件$\mathcal{E}$。&lt;/p&gt;
&lt;p&gt;给定一个MECE事件集合，事件式静态近似法则定义如下
$$
\mathcal{A}\left(\mathcal{C}\right)
\triangleq \left\{x : [S] \mapsto \mathbb{R} ~\left|~
\begin{array}{l}&lt;br&gt;
x(s) =  x^\mathcal{E}, ~\mathcal{E} = \mathcal{H}_\mathcal{C}(s) \\
\mbox{for some}~ x^\mathcal{E} \in \mathbb{R}
\end{array}\right. \right\},
$$
亦即，不同事件下，静态决策不同。&lt;/p&gt;
&lt;p&gt;类似地，事件式线性近似法则定义如下
$$
\bar{\mathcal{A}}\left(\mathcal{C}, \mathcal{I}\right) \triangleq \left\{ y : [S]  \times \mathbb{R}^{I_z}  \mapsto \mathbb{R} ~\left|~
\begin{array}{l}&lt;br&gt;
y(s, \boldsymbol{z}) =
\displaystyle  y^0(s) + \sum_{i \in \mathcal{I}} y^i(s) z_i  \\
\mbox{for some}~ y^0, y^i \in \mathcal{A}(\mathcal{C}), i \in \mathcal I
\end{array}\right. \right\}
$$
其中，信息集合$\mathcal I \subseteq [I_z]$为连续随机变量$\tilde{z}$的部分索引(indices)，声明了连续随机变量$\tilde{z}$中，事件式线性近似法则所能线性依赖的成分。事件式线性近似法则声明了在不同事件下，动态决策不同，并且动态决策为连续随机变量$ \tilde{z}$的线性函数。&lt;/p&gt;
&lt;p&gt;基于事件式近似法则，完整的RSO模型如下
$$
\begin{array}{cll}
\min &amp;amp;\displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[ \boldsymbol{a}^\prime_0(\tilde s, \tilde{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_0(\tilde s, \tilde{z}) \boldsymbol{x}(\tilde s) +  \boldsymbol{c}^\prime_0(\tilde s) \boldsymbol{y}(\tilde s, \tilde{z}) + d_0(\tilde s, \tilde{z})] \\
{\rm s.t.} &amp;amp;
\boldsymbol{a}^\prime_m(s, \boldsymbol{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_m(s, \boldsymbol{z}) \boldsymbol{x}(s) +  \boldsymbol{c}^\prime_m(s) \boldsymbol{y}(s, \boldsymbol{z}) + d_m(s, \boldsymbol{z}) \leq 0 &amp;amp;~\forall  \boldsymbol{z} \in  \mathcal{Z}_s, ~s \in [S], ~m \in \mathcal{M}_1, \\
&amp;amp; \displaystyle \sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[ \boldsymbol{a}^\prime_m(\tilde s, \tilde{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_m(\tilde s, \boldsymbol{z}) \boldsymbol{x}(\tilde s) +  \boldsymbol{c}^\prime_m(\tilde s) \boldsymbol{y}(\tilde s, \tilde{z}) + d_m(\tilde s, \tilde{z})] \leq 0 &amp;amp;~\forall m \in \mathcal{M}_2, \\
&amp;amp;\left( \boldsymbol{w}, \boldsymbol{x}(s), \boldsymbol{y}^0(s),\dots, \boldsymbol{y}^{I_z}(s) \right) \in \mathcal{X}_s &amp;amp;~\forall s \in [S]\\
&amp;amp; x_j \in \mathcal{A}(\mathcal{C}^j_x) &amp;amp;~\forall j \in [J_x], \\
&amp;amp; y_j \in \bar{\mathcal{A}}(\mathcal{C}^j_y, \mathcal{I}^j_y) &amp;amp;~\forall j \in [J_y].
\end{array}
$$
其中，$\mathcal{C}^j_x, j \in [J_x]$， $\mathcal{C}^j_y, j \in [J_y]$为MECE事件集合, $\mathcal{I}^j_y, j \in [J_y]$为信息集合。&lt;/p&gt;
&lt;h3 id=&#34;552-事件式分布模糊集&#34;&gt;5.5.2 事件式分布模糊集&lt;/h3&gt;
&lt;p&gt;事件式分布模糊集刻画了连续随机变量$ \tilde{z}$和离散随机变量$\tilde{s}$的联合分布的分布性质，包含了联合分布的分布信息。事件式分布模糊集取如下一般形式
$$
\label{eventwise_as}
\mathcal{F} = \left\{\mathbb{P} \in \mathcal{P}_0\left(\mathbb{R}^{I_z} \times [S]\right) ~\left\vert~
\begin{array}{ll}
( \tilde{z},\tilde s) \sim \mathbb{P}\\
\mathbb{E}_{\mathbb{P}}[ \tilde{z} \mid \tilde s \in \mathcal{E}_k] \in \mathcal{Q}_k &amp;amp;~\forall k \in [K] \\
\mathbb{P}[ \tilde{z} \in \mathcal{Z}_s \mid \tilde s = s]  = 1 &amp;amp;~\forall s \in [S]  \\
\mathbb{P}[\tilde s = s]  = p_s &amp;amp;~\forall s \in [S]  \\
\mbox{for some }  \boldsymbol{p} \in \mathcal{P}&lt;br&gt;
\end{array}
\right.
\right\}
$$
其中，$\mathcal{E}_k, k \in [K]$为不同事件（注意，这些事件不需要组成MECE事件集合），$\mathcal{Z}_s, s \in [S]$, $\mathcal{Q}_k, k \in [K]$, 和$\mathcal{P} \subseteq \{ \boldsymbol{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$为封闭的凸集合。事件式分布模糊集声明了&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不同事件（$\mathcal{E}_k$）下连续随机变量$ \tilde{z}$的事件期望（即条件期望）。&lt;/li&gt;
&lt;li&gt;不同情景（$s$）下连续随机变量$ \tilde{z}$的支撑集合（即条件支撑集合）。&lt;/li&gt;
&lt;li&gt;不同情景（$s$）发生的概率。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;不确定集合$\mathcal{Q}_k, k \in [K]$和$\mathcal{P} \subseteq \{ \boldsymbol{p} \in \mathbb{R}^S_{++} \mid  \sum_{s \in [S]}p_s  = 1\}$分别允许条件信息（1）和（3）亦可以是不确定的。&lt;/p&gt;
&lt;p&gt;Chen et al. (2019)证明了事件式分布模糊集有非常好的普适性。它可以描述随机优化中常用的确定的离散分布（deterministic discrete distribution），以及分布鲁棒优化中用到的不确定的离散分布（uncertain discrete distribution）, 确定的（或不确定的）混合分布（mixture distribution），基于矩信息的分布模糊集（moments ambiguity set），以及数据驱动下（1）基于机器学习聚类或分类算法的分布模糊集（K-means ambiguity set）与（2）基于Wasserstein距离的分布模糊集（Wasserstein ambiguity set）。&lt;/p&gt;
&lt;h3 id=&#34;553-经典鲁棒优化转化&#34;&gt;5.5.3 经典鲁棒优化转化&lt;/h3&gt;
&lt;p&gt;给定情景$s$，RSO模型中目标函数和“软（硬）”约束实际上是决策变量和连续随机变量$ \tilde{z}$的取值$ \boldsymbol{z}$的双线性函数。因为，我们可以将它们方便地记为
$$
{ \boldsymbol{a}^\prime_m(s, \boldsymbol{z}) \boldsymbol{w} +  \boldsymbol{b}^\prime_m(s, \boldsymbol{z}) \boldsymbol{x}(s) +  \boldsymbol{c}^\prime_m(s) \boldsymbol{y}(s, \boldsymbol{z}) + d_m(s, \boldsymbol{z})}   \triangleq  \boldsymbol{r}^\prime(s) \boldsymbol{G}_m(s) \boldsymbol{z} + h_m(s) ~~~\forall m \in [M] \cup \{0\}.
$$
其中，$ \boldsymbol{G}_m(s)  \in  \mathbb{R}^{J_r \times I_z}$和 $h_m(s) \in \mathbb{R}$为参数。这样的双线性函数在事件式分布模糊集下的最坏期望可以通过求解一个经典鲁棒优化模型得到。换句话说，RSO模型可以很方便地通过的配套建模工具包进行建模。目前，Chen et al.(2019)论文中所提到的建模工具包RSOME的MATLAB版本（https://sites.google.com/view/rsome/home）和Python版本（https://xiongpengnus.github.io/rsome/）都已发布。读者可以下载进行测试，并通过用户手册中的实例学习RSO的应用场景。在后续章节也将进行相关的介绍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定理5.3: 模型等价转换&lt;/strong&gt;
最坏期望
$$
\sup_{\mathbb{P} \in \mathcal{F}} \mathbb{E}_{\mathbb{P}}[ \boldsymbol{r}^\prime(\tilde s) \boldsymbol{G}_m(\tilde s) \tilde{z} + h_m(\tilde s) ]
$$
等于如下经典鲁棒优化模型的最优目标函数值
$$
\begin{array}{cll}
\inf &amp;amp; \gamma \\
{\rm s.t.} &amp;amp; \gamma \geq  \boldsymbol{\alpha}^\prime \boldsymbol{p} + \displaystyle \sum_{k \in [K]}  \boldsymbol{\beta}^\prime_k \boldsymbol{\mu}_k &amp;amp;~\forall  \boldsymbol{p} \in \mathcal{P}, ~\dfrac{ \boldsymbol{\mu}_k}{\sum_{s \in \mathcal{E}_k} p_s} \in \mathcal{Q}_k, ~k \in [K], \\
&amp;amp; \alpha_s + \displaystyle \sum_{k \in \mathcal{K}_s}  \boldsymbol{\beta}_k^\prime \boldsymbol{z}  \geq  \boldsymbol{r}^\prime(s) \boldsymbol{G}_m(s) \boldsymbol{z} + h_m(s) &amp;amp;~\forall  \boldsymbol{z} \in \mathcal{Z}_s, ~s \in [S], \\
&amp;amp; \gamma \in \mathbb{R}, ~ \boldsymbol{\alpha} \in \mathbb{R}^S, ~ \boldsymbol{\beta}_k \in \mathbb{R}^{I_z} &amp;amp;~\forall k \in [K],
\end{array}
$$
其中对每一个$s \in [S]$, $\mathcal{K}_s = \{k \in [K] \mid s \in \mathcal{E}_k\}$.&lt;/p&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ben-Tal, Aharon, Alexander Goryashko, Elana Guslitzer, and Arkadi Nemirovski&lt;/strong&gt;, “Adjustable robust
solutions of uncertain linear programs,” Mathematical Programming, 2004, 99 (2), 351–376.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__, Laurent El Ghaoui, and Arkadi Nemirovski&lt;/strong&gt;, Robust optimization, Vol. 28, Princeton University Press, 2009.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bertsimas, Dimitris and Vineet Goyal&lt;/strong&gt;, “On the power and limitations of affine policies in two-stage adaptive optimization,” Mathematical Programming, 2012, 134 (2), 491–531.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__, Dan A Iancu, and Pablo A Parrilo&lt;/strong&gt;, “Optimality of affine policies in multistage robust optimization,”
Mathematics of Operations Research, 2010, 35 (2), 363–394.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__, Dan Andrei Iancu, and Pablo A Parrilo&lt;/strong&gt;, “A hierarchy of near-optimal policies for multistage adaptive
optimization,” IEEE Transactions on Automatic Control, 2011, 56 (12), 2809–2824.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;__, Melvyn Sim, and Meilin Zhang&lt;/strong&gt;, “Adaptive distributionally robust optimization,” Management Science,
2019, 65 (2), 604–618.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chen, Xin, Melvyn Sim, Peng Sun, and Jiawei Zhang&lt;/strong&gt;, “A linear decision-based approximation approach to
stochastic programming,” Operations Research, 2008, 56 (2), 344–357.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chen, Zhi, Melvyn Sim, and Peng Xiong&lt;/strong&gt;, “Robust Stochastic Optimization: The Synergy of Robust Optimization and Stochastic Programming.,” 2019, p. Available at Optimization Online.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dantzig, George B&lt;/strong&gt;, “Linear programming under uncertainty,” Management Science, 1955, 1 (3-4), 197–206.
Delage, Erick and Dan A Iancu, “Robust multistage decision making,” in “The operations research revolution,” INFORMS, 2015, pp. 20–46.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dyer, Martin and Leen Stougie&lt;/strong&gt;, “Computational complexity of stochastic programming problems,” Mathe-
matical Programming, 2006, 106 (3), 423–432.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Garstka, Stanley J and Roger J-B Wets&lt;/strong&gt;, “On decision rules in stochastic programming,” Mathematical
Programming, 1974, 7 (1), 117–143.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Georghiou, Angelos, Daniel Kuhn, and Wolfram Wiesemann&lt;/strong&gt;, “The decision rule approach to optimization under uncertainty: methodology and applications,” Computational Management Science, 2019, 16 (4), 545–576.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Goh, Joel and Melvyn Sim&lt;/strong&gt;, “Distributionally robust optimization and its tractable approximations,” Operations Research, 2010, 58 (4-part-1), 902–917.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;He, Long, Zhenyu Hu, and Meilin Zhang&lt;/strong&gt;, “Robust repositioning for vehicle sharing,” Manufacturing &amp;amp;
Service Operations Management, 2020, 22 (2), 241–256.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Iancu, Dan A, Mayank Sharma, and Maxim Sviridenko&lt;/strong&gt;, “Supermodularity and affine policies in dynamic
robust optimization,” Operations Research, 2013, 61 (4), 941–956.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Perakis, Georgia, Melvyn Sim, Qinshen Tang, and Peng Xiong&lt;/strong&gt;, “Robust pricing and production with
information partitioning and adaptation,” 2020.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;See, Chuen-Teck and Melvyn Sim&lt;/strong&gt;, “Robust approximation to multiperiod inventory management,” Operations Research, 2010, 58 (3), 583–594.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wiesemann, Wolfram, Daniel Kuhn, and Melvyn Sim&lt;/strong&gt;, “Distributionally robust convex optimization,” Operations Research, 2014, 62 (6), 1358–1376.&lt;/p&gt;
</description>
      
    </item>
    
  </channel>
</rss>
